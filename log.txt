------------------------ arguments ------------------------
  abort_on_unmet_fused_kernel_constraints ......... False
  accumulate_allreduce_grads_in_fp32 .............. False
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.95
  adam_eps ........................................ 1e-08
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  bert_binary_head ................................ True
  bert_load ....................................... None
  bf16 ............................................ False
  bias_dropout_fusion ............................. True
  bias_gelu_fusion ................................ True
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  checkpoint_activations .......................... True
  checkpoint_in_cpu ............................... False
  checkpoint_num_layers ........................... 1
  clip_grad ....................................... 1.0
  codecarbon_dir .................................. None
  consumed_train_samples .......................... 0
  consumed_train_tokens ........................... 0
  consumed_valid_samples .......................... 0
  contigious_checkpointing ........................ False
  cpu_optimizer ................................... False
  cpu_torch_adam .................................. False
  curriculum_learning ............................. False
  data_impl ....................................... infer
  data_parallel_size .............................. 2
  data_path ....................................... ['1', '/home/hustcsuser/YuanData/processed_yuan/001.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/002.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/003.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/004.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/005.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/006.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/007.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/008.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/009.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/010.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/011.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/012.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/013.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/014.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/015.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/016.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/017.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/018.txt_sentence_context']
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_seq_length .............................. None
  deepscale ....................................... False
  deepscale_config ................................ None
  deepspeed ....................................... True
  deepspeed_activation_checkpointing .............. True
  deepspeed_config ................................ config.json
  deepspeed_mpi ................................... False
  distribute_checkpointed_activations ............. False
  distributed_backend ............................. nccl
  embed_layernorm ................................. False
  embedding_path .................................. None
  encoder_seq_length .............................. 2048
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... -1
  eval_only ....................................... None
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  ffn_hidden_size ................................. 12288
  finetune ........................................ False
  fp16 ............................................ True
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  gigaflos_no_embeds .............................. 0
  global_batch_size ............................... 400
  glu_activation .................................. None
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 3072
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_dim ......................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  init_method_std ................................. 0.002
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  kill_switch_path ................................ None
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ ./checkpoints/gpt2_encdec_4.7B_final_testdate_22-03-03_time_00-57-41/
  local_rank ...................................... 0
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 1
  log_learning_rate_to_tensorboard ................ True
  log_level ....................................... None
  log_level_replica ............................... None
  log_loss_scale_to_tensorboard ................... True
  log_num_zeros_in_grad ........................... True
  log_params_norm ................................. True
  log_path ........................................ log.txt
  log_path_detail ................................. detail.txt
  log_start_end_param ............................. None
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  loss_on_targets_only ............................ False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.0001
  lr_decay_iters .................................. None
  lr_decay_samples ................................ 430000
  lr_decay_style .................................. cosine
  lr_decay_tokens ................................. None
  lr_warmup_fraction .............................. None
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 7200
  make_vocab_size_divisible_by .................... 128
  mask_prob ....................................... 0.15
  masked_softmax_fusion ........................... True
  max_position_embeddings ......................... 2048
  memory_centric_tiled_linear ..................... False
  merge_file ...................................... None
  micro_batch_size ................................ 4
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 24
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 16
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  override_lr_scheduler ........................... False
  params_dtype .................................... torch.float16
  partition_activations ........................... False
  patch_dim ....................................... 16
  pipeline_model_parallel_size .................... 4
  position_embedding_type ......................... PositionEmbeddingType.absolute
  profile_backward ................................ False
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... ['8', '8', '39200']
  rank ............................................ 0
  remote_device ................................... none
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  reweight_loss_based_on_position_frequency ....... False
  sample_rate ..................................... 1.0
  save ............................................ ./checkpoints/gpt2_encdec_4.7B_final_testdate_22-03-03_time_00-57-41/
  save_interval ................................... 500
  scatter_gather_tensors_in_pipeline .............. True
  scattered_embeddings ............................ False
  seed ............................................ 1234
  seq_length ...................................... 2048
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  skip_train_iteration_range ...................... None
  split ........................................... 100,0,0
  split_transformers .............................. False
  synchronize_each_layer .......................... False
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. ./tensorboard/gpt2_encdec_4.7B_final_test/date_22-03-03_time_00-57-41
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_weighted_split_names ....................... None
  test_weighted_split_paths ....................... None
  test_weighted_split_splits ...................... None
  test_weighted_split_weights ..................... None
  tile_factor ..................................... 1
  titles_data_path ................................ None
  tokenizer_name_or_path .......................... None
  tokenizer_type .................................. EncDecTokenizer
  train_iters ..................................... None
  train_samples ................................... 488322
  train_tokens .................................... None
  train_weighted_split_paths ...................... None
  use_bnb_optimizer ............................... False
  use_checkpoint_lr_scheduler ..................... False
  use_contiguous_buffers_in_ddp ................... False
  use_cpu_initialization .......................... None
  use_one_sent_docs ............................... False
  use_pin_memory .................................. False
  valid_weighted_split_names ...................... None
  valid_weighted_split_paths ...................... None
  valid_weighted_split_splits ..................... None
  valid_weighted_split_weights .................... None
  virtual_pipeline_model_parallel_size ............ None
  vocab_extra_ids ................................. 0
  vocab_file ...................................... vocab.txt
  weight_decay .................................... 0.01
  world_size ...................................... 8
  zero_allgather_bucket_size ...................... 0.0
  zero_contigious_gradients ....................... False
  zero_reduce_bucket_size ......................... 0.0
  zero_reduce_scatter ............................. False
  zero_stage ...................................... 1.0
-------------------- end of arguments ---------------------
[before the start of training step] datetime: 2022-03-03 00:58:38
 iteration        1/    1571 | consumed samples:            8 | consumed tokens:        16384 | elapsed time per iteration (s): 13.87 | learning rate: 0.000E+00 | global batch size:     8 | lm loss: 1.088499E+01 | loss scale: 4294967296.0 | grad norm: 0.000 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.577 | TFLOPs: 6.09 |
 iteration        2/    1571 | consumed samples:           16 | consumed tokens:        32768 | elapsed time per iteration (s): 5.58 | learning rate: 0.000E+00 | global batch size:     8 | lm loss: 1.088647E+01 | loss scale: 2147483648.0 | grad norm: 0.000 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.434 | TFLOPs: 15.14 |
 iteration        3/    1571 | consumed samples:           24 | consumed tokens:        49152 | elapsed time per iteration (s): 5.64 | learning rate: 0.000E+00 | global batch size:     8 | lm loss: 1.088486E+01 | loss scale: 1073741824.0 | grad norm: 0.000 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.419 | TFLOPs: 14.98 |
 iteration        4/    1571 | consumed samples:           32 | consumed tokens:        65536 | elapsed time per iteration (s): 5.64 | learning rate: 0.000E+00 | global batch size:     8 | lm loss: 1.088353E+01 | loss scale: 536870912.0 | grad norm: 0.000 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.417 | TFLOPs: 14.97 |
 iteration        5/    1571 | consumed samples:           40 | consumed tokens:        81920 | elapsed time per iteration (s): 5.63 | learning rate: 0.000E+00 | global batch size:     8 | lm loss: 1.088496E+01 | loss scale: 268435456.0 | grad norm: 0.000 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.420 | TFLOPs: 14.99 |
 iteration        6/    1571 | consumed samples:           48 | consumed tokens:        98304 | elapsed time per iteration (s): 5.73 | learning rate: 0.000E+00 | global batch size:     8 | lm loss: 1.088464E+01 | loss scale: 134217728.0 | grad norm: 0.000 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.396 | TFLOPs: 14.74 |
 iteration        7/    1571 | consumed samples:           56 | consumed tokens:       114688 | elapsed time per iteration (s): 5.74 | learning rate: 0.000E+00 | global batch size:     8 | lm loss: 1.088809E+01 | loss scale: 67108864.0 | grad norm: 0.000 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.394 | TFLOPs: 14.72 |
 iteration        8/    1571 | consumed samples:           64 | consumed tokens:       131072 | elapsed time per iteration (s): 5.77 | learning rate: 0.000E+00 | global batch size:     8 | lm loss: 1.088134E+01 | loss scale: 33554432.0 | grad norm: 0.000 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.387 | TFLOPs: 14.64 |
 iteration        9/    1571 | consumed samples:           72 | consumed tokens:       147456 | elapsed time per iteration (s): 5.79 | learning rate: 0.000E+00 | global batch size:     8 | lm loss: 1.088502E+01 | loss scale: 16777216.0 | grad norm: 0.000 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.381 | TFLOPs: 14.58 |
 iteration       10/    1571 | consumed samples:           80 | consumed tokens:       163840 | elapsed time per iteration (s): 5.81 | learning rate: 0.000E+00 | global batch size:     8 | lm loss: 1.088977E+01 | loss scale: 8388608.0 | grad norm: 0.000 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.377 | TFLOPs: 14.54 |
 iteration       11/    1571 | consumed samples:           88 | consumed tokens:       180224 | elapsed time per iteration (s): 5.82 | learning rate: 0.000E+00 | global batch size:     8 | lm loss: 1.088650E+01 | loss scale: 4194304.0 | grad norm: 0.000 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.374 | TFLOPs: 14.51 |
 iteration       12/    1571 | consumed samples:           96 | consumed tokens:       196608 | elapsed time per iteration (s): 5.82 | learning rate: 0.000E+00 | global batch size:     8 | lm loss: 1.088377E+01 | loss scale: 2097152.0 | grad norm: 0.000 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.375 | TFLOPs: 14.52 |
 iteration       13/    1571 | consumed samples:          104 | consumed tokens:       212992 | elapsed time per iteration (s): 5.81 | learning rate: 0.000E+00 | global batch size:     8 | lm loss: 1.088486E+01 | loss scale: 1048576.0 | grad norm: 0.000 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.377 | TFLOPs: 14.54 |
 iteration       14/    1571 | consumed samples:          112 | consumed tokens:       229376 | elapsed time per iteration (s): 5.81 | learning rate: 0.000E+00 | global batch size:     8 | lm loss: 1.088368E+01 | loss scale: 524288.0 | grad norm: 0.000 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.377 | TFLOPs: 14.54 |
 iteration       15/    1571 | consumed samples:          120 | consumed tokens:       245760 | elapsed time per iteration (s): 5.81 | learning rate: 0.000E+00 | global batch size:     8 | lm loss: 1.088888E+01 | loss scale: 262144.0 | grad norm: 0.000 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.378 | TFLOPs: 14.55 |
 iteration       16/    1571 | consumed samples:          128 | consumed tokens:       262144 | elapsed time per iteration (s): 5.82 | learning rate: 0.000E+00 | global batch size:     8 | lm loss: 1.088551E+01 | loss scale: 131072.0 | grad norm: 0.000 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.373 | TFLOPs: 14.50 |
 iteration       17/    1571 | consumed samples:          136 | consumed tokens:       278528 | elapsed time per iteration (s): 6.09 | learning rate: 1.111E-07 | global batch size:     8 | lm loss: 1.088535E+01 | loss scale: 131072.0 | grad norm: 4242558.484 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.313 | TFLOPs: 13.86 |
 iteration       18/    1571 | consumed samples:          144 | consumed tokens:       294912 | elapsed time per iteration (s): 6.10 | learning rate: 2.222E-07 | global batch size:     8 | lm loss: 1.088562E+01 | loss scale: 131072.0 | grad norm: 3779487.383 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.311 | TFLOPs: 13.84 |
 iteration       19/    1571 | consumed samples:          152 | consumed tokens:       311296 | elapsed time per iteration (s): 5.82 | learning rate: 2.222E-07 | global batch size:     8 | lm loss: 1.084967E+01 | loss scale: 65536.0 | grad norm: 3779487.383 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.375 | TFLOPs: 14.52 |
 iteration       20/    1571 | consumed samples:          160 | consumed tokens:       327680 | elapsed time per iteration (s): 6.09 | learning rate: 3.333E-07 | global batch size:     8 | lm loss: 1.085410E+01 | loss scale: 65536.0 | grad norm: 1951899.864 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.313 | TFLOPs: 13.86 |
 iteration       21/    1571 | consumed samples:          168 | consumed tokens:       344064 | elapsed time per iteration (s): 6.10 | learning rate: 4.444E-07 | global batch size:     8 | lm loss: 1.077556E+01 | loss scale: 65536.0 | grad norm: 2209068.901 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.312 | TFLOPs: 13.86 |
 iteration       22/    1571 | consumed samples:          176 | consumed tokens:       360448 | elapsed time per iteration (s): 6.09 | learning rate: 5.556E-07 | global batch size:     8 | lm loss: 1.066559E+01 | loss scale: 65536.0 | grad norm: 1784830.054 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.314 | TFLOPs: 13.88 |
 iteration       23/    1571 | consumed samples:          184 | consumed tokens:       376832 | elapsed time per iteration (s): 6.09 | learning rate: 6.667E-07 | global batch size:     8 | lm loss: 1.053734E+01 | loss scale: 65536.0 | grad norm: 1027554.774 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.313 | TFLOPs: 13.86 |
 iteration       24/    1571 | consumed samples:          192 | consumed tokens:       393216 | elapsed time per iteration (s): 6.10 | learning rate: 7.778E-07 | global batch size:     8 | lm loss: 1.048376E+01 | loss scale: 65536.0 | grad norm: 743578.210 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.312 | TFLOPs: 13.86 |
 iteration       25/    1571 | consumed samples:          200 | consumed tokens:       409600 | elapsed time per iteration (s): 6.09 | learning rate: 8.889E-07 | global batch size:     8 | lm loss: 1.043115E+01 | loss scale: 65536.0 | grad norm: 589350.157 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.314 | TFLOPs: 13.87 |
 iteration       26/    1571 | consumed samples:          208 | consumed tokens:       425984 | elapsed time per iteration (s): 6.08 | learning rate: 1.000E-06 | global batch size:     8 | lm loss: 1.038496E+01 | loss scale: 65536.0 | grad norm: 476801.800 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.316 | TFLOPs: 13.90 |
 iteration       27/    1571 | consumed samples:          216 | consumed tokens:       442368 | elapsed time per iteration (s): 6.09 | learning rate: 1.111E-06 | global batch size:     8 | lm loss: 1.034750E+01 | loss scale: 65536.0 | grad norm: 458937.942 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.314 | TFLOPs: 13.87 |
 iteration       28/    1571 | consumed samples:          224 | consumed tokens:       458752 | elapsed time per iteration (s): 6.08 | learning rate: 1.222E-06 | global batch size:     8 | lm loss: 1.035052E+01 | loss scale: 65536.0 | grad norm: 400266.082 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.315 | TFLOPs: 13.88 |
 iteration       29/    1571 | consumed samples:          232 | consumed tokens:       475136 | elapsed time per iteration (s): 6.09 | learning rate: 1.333E-06 | global batch size:     8 | lm loss: 1.030572E+01 | loss scale: 65536.0 | grad norm: 393101.532 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.314 | TFLOPs: 13.88 |
 iteration       30/    1571 | consumed samples:          240 | consumed tokens:       491520 | elapsed time per iteration (s): 6.09 | learning rate: 1.444E-06 | global batch size:     8 | lm loss: 1.030240E+01 | loss scale: 65536.0 | grad norm: 363644.621 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.313 | TFLOPs: 13.87 |
 iteration       31/    1571 | consumed samples:          248 | consumed tokens:       507904 | elapsed time per iteration (s): 6.08 | learning rate: 1.556E-06 | global batch size:     8 | lm loss: 1.030022E+01 | loss scale: 65536.0 | grad norm: 355683.138 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.316 | TFLOPs: 13.89 |
 iteration       32/    1571 | consumed samples:          256 | consumed tokens:       524288 | elapsed time per iteration (s): 6.10 | learning rate: 1.667E-06 | global batch size:     8 | lm loss: 1.023160E+01 | loss scale: 65536.0 | grad norm: 407536.428 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.312 | TFLOPs: 13.85 |
 iteration       33/    1571 | consumed samples:          264 | consumed tokens:       540672 | elapsed time per iteration (s): 6.09 | learning rate: 1.778E-06 | global batch size:     8 | lm loss: 1.032630E+01 | loss scale: 65536.0 | grad norm: 320847.427 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.315 | TFLOPs: 13.88 |
 iteration       34/    1571 | consumed samples:          272 | consumed tokens:       557056 | elapsed time per iteration (s): 6.08 | learning rate: 1.889E-06 | global batch size:     8 | lm loss: 1.024241E+01 | loss scale: 65536.0 | grad norm: 361716.571 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.316 | TFLOPs: 13.90 |
 iteration       35/    1571 | consumed samples:          280 | consumed tokens:       573440 | elapsed time per iteration (s): 6.08 | learning rate: 2.000E-06 | global batch size:     8 | lm loss: 1.026830E+01 | loss scale: 65536.0 | grad norm: 323171.278 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.315 | TFLOPs: 13.88 |
 iteration       36/    1571 | consumed samples:          288 | consumed tokens:       589824 | elapsed time per iteration (s): 6.08 | learning rate: 2.111E-06 | global batch size:     8 | lm loss: 1.019161E+01 | loss scale: 65536.0 | grad norm: 340336.455 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.316 | TFLOPs: 13.90 |
 iteration       37/    1571 | consumed samples:          296 | consumed tokens:       606208 | elapsed time per iteration (s): 6.08 | learning rate: 2.222E-06 | global batch size:     8 | lm loss: 1.026748E+01 | loss scale: 65536.0 | grad norm: 325282.181 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.316 | TFLOPs: 13.89 |
 iteration       38/    1571 | consumed samples:          304 | consumed tokens:       622592 | elapsed time per iteration (s): 6.10 | learning rate: 2.333E-06 | global batch size:     8 | lm loss: 1.027248E+01 | loss scale: 65536.0 | grad norm: 393591.009 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.312 | TFLOPs: 13.85 |
 iteration       39/    1571 | consumed samples:          312 | consumed tokens:       638976 | elapsed time per iteration (s): 6.09 | learning rate: 2.444E-06 | global batch size:     8 | lm loss: 1.022944E+01 | loss scale: 65536.0 | grad norm: 494055.073 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.313 | TFLOPs: 13.86 |
 iteration       40/    1571 | consumed samples:          320 | consumed tokens:       655360 | elapsed time per iteration (s): 6.08 | learning rate: 2.556E-06 | global batch size:     8 | lm loss: 1.019125E+01 | loss scale: 65536.0 | grad norm: 463943.838 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.316 | TFLOPs: 13.89 |
 iteration       41/    1571 | consumed samples:          328 | consumed tokens:       671744 | elapsed time per iteration (s): 6.10 | learning rate: 2.667E-06 | global batch size:     8 | lm loss: 1.019708E+01 | loss scale: 65536.0 | grad norm: 336594.952 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.312 | TFLOPs: 13.86 |
 iteration       42/    1571 | consumed samples:          336 | consumed tokens:       688128 | elapsed time per iteration (s): 6.08 | learning rate: 2.778E-06 | global batch size:     8 | lm loss: 1.020797E+01 | loss scale: 65536.0 | grad norm: 334697.508 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.315 | TFLOPs: 13.89 |
 iteration       43/    1571 | consumed samples:          344 | consumed tokens:       704512 | elapsed time per iteration (s): 6.09 | learning rate: 2.889E-06 | global batch size:     8 | lm loss: 1.018433E+01 | loss scale: 65536.0 | grad norm: 323644.778 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.314 | TFLOPs: 13.87 |
 iteration       44/    1571 | consumed samples:          352 | consumed tokens:       720896 | elapsed time per iteration (s): 6.08 | learning rate: 3.000E-06 | global batch size:     8 | lm loss: 1.018468E+01 | loss scale: 65536.0 | grad norm: 332970.921 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.315 | TFLOPs: 13.89 |
 iteration       45/    1571 | consumed samples:          360 | consumed tokens:       737280 | elapsed time per iteration (s): 6.10 | learning rate: 3.111E-06 | global batch size:     8 | lm loss: 1.013563E+01 | loss scale: 65536.0 | grad norm: 330774.089 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.312 | TFLOPs: 13.86 |
 iteration       46/    1571 | consumed samples:          368 | consumed tokens:       753664 | elapsed time per iteration (s): 6.09 | learning rate: 3.222E-06 | global batch size:     8 | lm loss: 1.014772E+01 | loss scale: 65536.0 | grad norm: 310537.531 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.313 | TFLOPs: 13.87 |
 iteration       47/    1571 | consumed samples:          376 | consumed tokens:       770048 | elapsed time per iteration (s): 6.09 | learning rate: 3.333E-06 | global batch size:     8 | lm loss: 1.015792E+01 | loss scale: 65536.0 | grad norm: 309677.921 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.314 | TFLOPs: 13.88 |
 iteration       48/    1571 | consumed samples:          384 | consumed tokens:       786432 | elapsed time per iteration (s): 6.09 | learning rate: 3.444E-06 | global batch size:     8 | lm loss: 1.011337E+01 | loss scale: 65536.0 | grad norm: 310755.575 | num zeros: 0.0 | params norm: 510.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.313 | TFLOPs: 13.86 |
 iteration       49/    1571 | consumed samples:          392 | consumed tokens:       802816 | elapsed time per iteration (s): 6.10 | learning rate: 3.556E-06 | global batch size:     8 | lm loss: 1.011862E+01 | loss scale: 65536.0 | grad norm: 310027.373 | num zeros: 0.0 | params norm: 510.741 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.312 | TFLOPs: 13.85 |
 iteration       50/    1571 | consumed samples:          400 | consumed tokens:       819200 | elapsed time per iteration (s): 6.10 | learning rate: 3.667E-06 | global batch size:     8 | lm loss: 1.010819E+01 | loss scale: 65536.0 | grad norm: 317671.782 | num zeros: 0.0 | params norm: 510.741 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.313 | TFLOPs: 13.86 |
 iteration       51/    1571 | consumed samples:          408 | consumed tokens:       835584 | elapsed time per iteration (s): 6.08 | learning rate: 3.778E-06 | global batch size:     8 | lm loss: 1.008433E+01 | loss scale: 65536.0 | grad norm: 314540.963 | num zeros: 0.0 | params norm: 510.741 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.315 | TFLOPs: 13.89 |
 iteration       52/    1571 | consumed samples:          416 | consumed tokens:       851968 | elapsed time per iteration (s): 6.09 | learning rate: 3.889E-06 | global batch size:     8 | lm loss: 1.011904E+01 | loss scale: 65536.0 | grad norm: 296053.367 | num zeros: 0.0 | params norm: 510.741 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.313 | TFLOPs: 13.86 |
 iteration       53/    1571 | consumed samples:          424 | consumed tokens:       868352 | elapsed time per iteration (s): 6.09 | learning rate: 4.000E-06 | global batch size:     8 | lm loss: 1.005339E+01 | loss scale: 65536.0 | grad norm: 305441.370 | num zeros: 0.0 | params norm: 510.741 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.314 | TFLOPs: 13.88 |
 iteration       54/    1571 | consumed samples:          432 | consumed tokens:       884736 | elapsed time per iteration (s): 6.09 | learning rate: 4.111E-06 | global batch size:     8 | lm loss: 1.000107E+01 | loss scale: 65536.0 | grad norm: 327917.495 | num zeros: 0.0 | params norm: 510.741 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.313 | TFLOPs: 13.86 |
 iteration       55/    1571 | consumed samples:          440 | consumed tokens:       901120 | elapsed time per iteration (s): 6.07 | learning rate: 4.222E-06 | global batch size:     8 | lm loss: 1.005478E+01 | loss scale: 65536.0 | grad norm: 308198.707 | num zeros: 0.0 | params norm: 510.741 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.317 | TFLOPs: 13.91 |
 iteration       56/    1571 | consumed samples:          448 | consumed tokens:       917504 | elapsed time per iteration (s): 6.10 | learning rate: 4.333E-06 | global batch size:     8 | lm loss: 9.979398E+00 | loss scale: 65536.0 | grad norm: 320382.712 | num zeros: 0.0 | params norm: 510.742 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.312 | TFLOPs: 13.85 |
 iteration       57/    1571 | consumed samples:          456 | consumed tokens:       933888 | elapsed time per iteration (s): 6.09 | learning rate: 4.444E-06 | global batch size:     8 | lm loss: 1.002470E+01 | loss scale: 65536.0 | grad norm: 312439.741 | num zeros: 0.0 | params norm: 510.742 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.314 | TFLOPs: 13.87 |
 iteration       58/    1571 | consumed samples:          464 | consumed tokens:       950272 | elapsed time per iteration (s): 6.09 | learning rate: 4.556E-06 | global batch size:     8 | lm loss: 9.953815E+00 | loss scale: 65536.0 | grad norm: 331213.749 | num zeros: 0.0 | params norm: 510.742 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.314 | TFLOPs: 13.87 |
 iteration       59/    1571 | consumed samples:          472 | consumed tokens:       966656 | elapsed time per iteration (s): 6.10 | learning rate: 4.667E-06 | global batch size:     8 | lm loss: 1.004185E+01 | loss scale: 65536.0 | grad norm: 295703.583 | num zeros: 0.0 | params norm: 510.742 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.312 | TFLOPs: 13.86 |
 iteration       60/    1571 | consumed samples:          480 | consumed tokens:       983040 | elapsed time per iteration (s): 6.09 | learning rate: 4.778E-06 | global batch size:     8 | lm loss: 9.916858E+00 | loss scale: 65536.0 | grad norm: 319084.682 | num zeros: 0.0 | params norm: 510.742 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.315 | TFLOPs: 13.88 |
 iteration       61/    1571 | consumed samples:          488 | consumed tokens:       999424 | elapsed time per iteration (s): 6.09 | learning rate: 4.889E-06 | global batch size:     8 | lm loss: 9.939578E+00 | loss scale: 65536.0 | grad norm: 295646.525 | num zeros: 0.0 | params norm: 510.743 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.314 | TFLOPs: 13.88 |
 iteration       62/    1571 | consumed samples:          496 | consumed tokens:      1015808 | elapsed time per iteration (s): 6.10 | learning rate: 5.000E-06 | global batch size:     8 | lm loss: 9.972375E+00 | loss scale: 65536.0 | grad norm: 277134.222 | num zeros: 0.0 | params norm: 510.743 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.312 | TFLOPs: 13.85 |
 iteration       63/    1571 | consumed samples:          504 | consumed tokens:      1032192 | elapsed time per iteration (s): 6.10 | learning rate: 5.111E-06 | global batch size:     8 | lm loss: 9.907880E+00 | loss scale: 65536.0 | grad norm: 302166.220 | num zeros: 0.0 | params norm: 510.743 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.312 | TFLOPs: 13.85 |
 iteration       64/    1571 | consumed samples:          512 | consumed tokens:      1048576 | elapsed time per iteration (s): 6.10 | learning rate: 5.222E-06 | global batch size:     8 | lm loss: 9.868341E+00 | loss scale: 65536.0 | grad norm: 313624.824 | num zeros: 0.0 | params norm: 510.744 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.312 | TFLOPs: 13.85 |
 iteration       65/    1571 | consumed samples:          520 | consumed tokens:      1064960 | elapsed time per iteration (s): 6.08 | learning rate: 5.333E-06 | global batch size:     8 | lm loss: 9.879643E+00 | loss scale: 65536.0 | grad norm: 309168.689 | num zeros: 0.0 | params norm: 510.744 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.316 | TFLOPs: 13.89 |
 iteration       66/    1571 | consumed samples:          528 | consumed tokens:      1081344 | elapsed time per iteration (s): 6.09 | learning rate: 5.444E-06 | global batch size:     8 | lm loss: 9.819973E+00 | loss scale: 65536.0 | grad norm: 317980.008 | num zeros: 0.0 | params norm: 510.744 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.313 | TFLOPs: 13.87 |
 iteration       67/    1571 | consumed samples:          536 | consumed tokens:      1097728 | elapsed time per iteration (s): 6.09 | learning rate: 5.556E-06 | global batch size:     8 | lm loss: 9.883063E+00 | loss scale: 65536.0 | grad norm: 283254.483 | num zeros: 0.0 | params norm: 510.745 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.314 | TFLOPs: 13.87 |
 iteration       68/    1571 | consumed samples:          544 | consumed tokens:      1114112 | elapsed time per iteration (s): 6.08 | learning rate: 5.667E-06 | global batch size:     8 | lm loss: 9.821459E+00 | loss scale: 65536.0 | grad norm: 325217.049 | num zeros: 0.0 | params norm: 510.745 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.316 | TFLOPs: 13.89 |
 iteration       69/    1571 | consumed samples:          552 | consumed tokens:      1130496 | elapsed time per iteration (s): 6.08 | learning rate: 5.778E-06 | global batch size:     8 | lm loss: 9.790342E+00 | loss scale: 65536.0 | grad norm: 299624.560 | num zeros: 0.0 | params norm: 510.745 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.316 | TFLOPs: 13.90 |
 iteration       70/    1571 | consumed samples:          560 | consumed tokens:      1146880 | elapsed time per iteration (s): 6.09 | learning rate: 5.889E-06 | global batch size:     8 | lm loss: 9.758813E+00 | loss scale: 65536.0 | grad norm: 303357.625 | num zeros: 0.0 | params norm: 510.746 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.313 | TFLOPs: 13.86 |
 iteration       71/    1571 | consumed samples:          568 | consumed tokens:      1163264 | elapsed time per iteration (s): 6.09 | learning rate: 6.000E-06 | global batch size:     8 | lm loss: 9.707775E+00 | loss scale: 65536.0 | grad norm: 327751.882 | num zeros: 0.0 | params norm: 510.746 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.313 | TFLOPs: 13.86 |
 iteration       72/    1571 | consumed samples:          576 | consumed tokens:      1179648 | elapsed time per iteration (s): 6.09 | learning rate: 6.111E-06 | global batch size:     8 | lm loss: 9.725163E+00 | loss scale: 65536.0 | grad norm: 308203.282 | num zeros: 0.0 | params norm: 510.747 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.314 | TFLOPs: 13.87 |
 iteration       73/    1571 | consumed samples:          584 | consumed tokens:      1196032 | elapsed time per iteration (s): 6.08 | learning rate: 6.222E-06 | global batch size:     8 | lm loss: 9.668041E+00 | loss scale: 65536.0 | grad norm: 307491.732 | num zeros: 0.0 | params norm: 510.747 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.315 | TFLOPs: 13.89 |
 iteration       74/    1571 | consumed samples:          592 | consumed tokens:      1212416 | elapsed time per iteration (s): 6.09 | learning rate: 6.333E-06 | global batch size:     8 | lm loss: 9.732738E+00 | loss scale: 65536.0 | grad norm: 313299.614 | num zeros: 0.0 | params norm: 510.748 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.313 | TFLOPs: 13.86 |
 iteration       75/    1571 | consumed samples:          600 | consumed tokens:      1228800 | elapsed time per iteration (s): 6.09 | learning rate: 6.444E-06 | global batch size:     8 | lm loss: 9.624641E+00 | loss scale: 65536.0 | grad norm: 342668.473 | num zeros: 0.0 | params norm: 510.748 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.313 | TFLOPs: 13.86 |
 iteration       76/    1571 | consumed samples:          608 | consumed tokens:      1245184 | elapsed time per iteration (s): 6.09 | learning rate: 6.556E-06 | global batch size:     8 | lm loss: 9.718143E+00 | loss scale: 65536.0 | grad norm: 273097.989 | num zeros: 0.0 | params norm: 510.749 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.314 | TFLOPs: 13.87 |
 iteration       77/    1571 | consumed samples:          616 | consumed tokens:      1261568 | elapsed time per iteration (s): 6.09 | learning rate: 6.667E-06 | global batch size:     8 | lm loss: 9.533238E+00 | loss scale: 65536.0 | grad norm: 335901.371 | num zeros: 0.0 | params norm: 510.750 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.314 | TFLOPs: 13.87 |
 iteration       78/    1571 | consumed samples:          624 | consumed tokens:      1277952 | elapsed time per iteration (s): 6.09 | learning rate: 6.778E-06 | global batch size:     8 | lm loss: 9.563318E+00 | loss scale: 65536.0 | grad norm: 308604.785 | num zeros: 0.0 | params norm: 510.750 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.313 | TFLOPs: 13.86 |
 iteration       79/    1571 | consumed samples:          632 | consumed tokens:      1294336 | elapsed time per iteration (s): 6.07 | learning rate: 6.889E-06 | global batch size:     8 | lm loss: 9.552078E+00 | loss scale: 65536.0 | grad norm: 315431.287 | num zeros: 0.0 | params norm: 510.751 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.317 | TFLOPs: 13.91 |
 iteration       80/    1571 | consumed samples:          640 | consumed tokens:      1310720 | elapsed time per iteration (s): 6.10 | learning rate: 7.000E-06 | global batch size:     8 | lm loss: 9.620359E+00 | loss scale: 65536.0 | grad norm: 1052587.124 | num zeros: 0.0 | params norm: 510.752 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.312 | TFLOPs: 13.86 |
 iteration       81/    1571 | consumed samples:          648 | consumed tokens:      1327104 | elapsed time per iteration (s): 6.09 | learning rate: 7.111E-06 | global batch size:     8 | lm loss: 9.534250E+00 | loss scale: 65536.0 | grad norm: 296950.264 | num zeros: 0.0 | params norm: 510.752 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.314 | TFLOPs: 13.88 |
 iteration       82/    1571 | consumed samples:          656 | consumed tokens:      1343488 | elapsed time per iteration (s): 6.09 | learning rate: 7.222E-06 | global batch size:     8 | lm loss: 9.507788E+00 | loss scale: 65536.0 | grad norm: 292321.837 | num zeros: 0.0 | params norm: 510.753 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.314 | TFLOPs: 13.87 |
 iteration       83/    1571 | consumed samples:          664 | consumed tokens:      1359872 | elapsed time per iteration (s): 6.10 | learning rate: 7.333E-06 | global batch size:     8 | lm loss: 9.508221E+00 | loss scale: 65536.0 | grad norm: 287901.015 | num zeros: 0.0 | params norm: 510.754 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.312 | TFLOPs: 13.86 |
 iteration       84/    1571 | consumed samples:          672 | consumed tokens:      1376256 | elapsed time per iteration (s): 6.08 | learning rate: 7.444E-06 | global batch size:     8 | lm loss: 9.444404E+00 | loss scale: 65536.0 | grad norm: 299752.608 | num zeros: 0.0 | params norm: 510.755 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.315 | TFLOPs: 13.89 |
 iteration       85/    1571 | consumed samples:          680 | consumed tokens:      1392640 | elapsed time per iteration (s): 6.10 | learning rate: 7.556E-06 | global batch size:     8 | lm loss: 9.436318E+00 | loss scale: 65536.0 | grad norm: 350215.532 | num zeros: 0.0 | params norm: 510.756 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.312 | TFLOPs: 13.86 |
 iteration       86/    1571 | consumed samples:          688 | consumed tokens:      1409024 | elapsed time per iteration (s): 6.09 | learning rate: 7.667E-06 | global batch size:     8 | lm loss: 9.415414E+00 | loss scale: 65536.0 | grad norm: 299240.154 | num zeros: 0.0 | params norm: 510.757 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.313 | TFLOPs: 13.86 |
 iteration       87/    1571 | consumed samples:          696 | consumed tokens:      1425408 | elapsed time per iteration (s): 6.08 | learning rate: 7.778E-06 | global batch size:     8 | lm loss: 9.380394E+00 | loss scale: 65536.0 | grad norm: 298759.477 | num zeros: 0.0 | params norm: 510.758 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.316 | TFLOPs: 13.89 |
 iteration       88/    1571 | consumed samples:          704 | consumed tokens:      1441792 | elapsed time per iteration (s): 6.09 | learning rate: 7.889E-06 | global batch size:     8 | lm loss: 9.372456E+00 | loss scale: 65536.0 | grad norm: 290549.750 | num zeros: 0.0 | params norm: 510.759 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.315 | TFLOPs: 13.88 |
 iteration       89/    1571 | consumed samples:          712 | consumed tokens:      1458176 | elapsed time per iteration (s): 6.09 | learning rate: 8.000E-06 | global batch size:     8 | lm loss: 9.346161E+00 | loss scale: 65536.0 | grad norm: 289812.639 | num zeros: 0.0 | params norm: 510.760 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.313 | TFLOPs: 13.87 |
 iteration       90/    1571 | consumed samples:          720 | consumed tokens:      1474560 | elapsed time per iteration (s): 6.09 | learning rate: 8.111E-06 | global batch size:     8 | lm loss: 9.281202E+00 | loss scale: 65536.0 | grad norm: 303243.821 | num zeros: 0.0 | params norm: 510.761 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.314 | TFLOPs: 13.88 |
 iteration       91/    1571 | consumed samples:          728 | consumed tokens:      1490944 | elapsed time per iteration (s): 6.09 | learning rate: 8.222E-06 | global batch size:     8 | lm loss: 9.312223E+00 | loss scale: 65536.0 | grad norm: 273528.934 | num zeros: 0.0 | params norm: 510.762 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.314 | TFLOPs: 13.88 |
 iteration       92/    1571 | consumed samples:          736 | consumed tokens:      1507328 | elapsed time per iteration (s): 6.08 | learning rate: 8.333E-06 | global batch size:     8 | lm loss: 9.190328E+00 | loss scale: 65536.0 | grad norm: 325743.902 | num zeros: 0.0 | params norm: 510.763 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.315 | TFLOPs: 13.89 |
 iteration       93/    1571 | consumed samples:          744 | consumed tokens:      1523712 | elapsed time per iteration (s): 6.09 | learning rate: 8.444E-06 | global batch size:     8 | lm loss: 9.267294E+00 | loss scale: 65536.0 | grad norm: 274573.070 | num zeros: 0.0 | params norm: 510.765 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.314 | TFLOPs: 13.87 |
 iteration       94/    1571 | consumed samples:          752 | consumed tokens:      1540096 | elapsed time per iteration (s): 6.10 | learning rate: 8.556E-06 | global batch size:     8 | lm loss: 9.194983E+00 | loss scale: 65536.0 | grad norm: 282109.433 | num zeros: 0.0 | params norm: 510.766 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.311 | TFLOPs: 13.84 |
 iteration       95/    1571 | consumed samples:          760 | consumed tokens:      1556480 | elapsed time per iteration (s): 6.10 | learning rate: 8.667E-06 | global batch size:     8 | lm loss: 9.135749E+00 | loss scale: 65536.0 | grad norm: 303037.852 | num zeros: 0.0 | params norm: 510.767 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.312 | TFLOPs: 13.85 |
 iteration       96/    1571 | consumed samples:          768 | consumed tokens:      1572864 | elapsed time per iteration (s): 6.10 | learning rate: 8.778E-06 | global batch size:     8 | lm loss: 9.049091E+00 | loss scale: 65536.0 | grad norm: 331369.876 | num zeros: 0.0 | params norm: 510.769 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.312 | TFLOPs: 13.86 |
 iteration       97/    1571 | consumed samples:          776 | consumed tokens:      1589248 | elapsed time per iteration (s): 6.09 | learning rate: 8.889E-06 | global batch size:     8 | lm loss: 9.116298E+00 | loss scale: 65536.0 | grad norm: 298340.669 | num zeros: 0.0 | params norm: 510.770 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.315 | TFLOPs: 13.88 |
 iteration       98/    1571 | consumed samples:          784 | consumed tokens:      1605632 | elapsed time per iteration (s): 6.08 | learning rate: 9.000E-06 | global batch size:     8 | lm loss: 9.112059E+00 | loss scale: 65536.0 | grad norm: 268409.160 | num zeros: 0.0 | params norm: 510.772 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.317 | TFLOPs: 13.90 |
 iteration       99/    1571 | consumed samples:          792 | consumed tokens:      1622016 | elapsed time per iteration (s): 6.09 | learning rate: 9.111E-06 | global batch size:     8 | lm loss: 9.073126E+00 | loss scale: 65536.0 | grad norm: 291315.184 | num zeros: 0.0 | params norm: 510.773 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.314 | TFLOPs: 13.87 |
 iteration      100/    1571 | consumed samples:          800 | consumed tokens:      1638400 | elapsed time per iteration (s): 6.09 | learning rate: 9.222E-06 | global batch size:     8 | lm loss: 9.056009E+00 | loss scale: 65536.0 | grad norm: 316055.745 | num zeros: 0.0 | params norm: 510.775 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 1.314 | TFLOPs: 13.88 |
 iteration      101/    1571 | consumed samples:          816 | consumed tokens:      1671168 | elapsed time per iteration (s): 7.55 | learning rate: 9.444E-06 | global batch size:    16 | lm loss: 9.009814E+00 | loss scale: 65536.0 | grad norm: 283463.173 | num zeros: 0.0 | params norm: 510.776 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.121 | TFLOPs: 22.39 |
 iteration      102/    1571 | consumed samples:          832 | consumed tokens:      1703936 | elapsed time per iteration (s): 7.54 | learning rate: 9.667E-06 | global batch size:    16 | lm loss: 8.962362E+00 | loss scale: 65536.0 | grad norm: 289296.794 | num zeros: 0.0 | params norm: 510.778 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.121 | TFLOPs: 22.40 |
 iteration      103/    1571 | consumed samples:          848 | consumed tokens:      1736704 | elapsed time per iteration (s): 7.55 | learning rate: 9.889E-06 | global batch size:    16 | lm loss: 8.932453E+00 | loss scale: 65536.0 | grad norm: 277160.491 | num zeros: 0.0 | params norm: 510.780 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.120 | TFLOPs: 22.38 |
 iteration      104/    1571 | consumed samples:          864 | consumed tokens:      1769472 | elapsed time per iteration (s): 7.54 | learning rate: 1.011E-05 | global batch size:    16 | lm loss: 8.934656E+00 | loss scale: 65536.0 | grad norm: 288399.591 | num zeros: 0.0 | params norm: 510.782 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.121 | TFLOPs: 22.40 |
 iteration      105/    1571 | consumed samples:          880 | consumed tokens:      1802240 | elapsed time per iteration (s): 7.54 | learning rate: 1.033E-05 | global batch size:    16 | lm loss: 8.862770E+00 | loss scale: 65536.0 | grad norm: 291222.134 | num zeros: 0.0 | params norm: 510.784 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.122 | TFLOPs: 22.41 |
 iteration      106/    1571 | consumed samples:          896 | consumed tokens:      1835008 | elapsed time per iteration (s): 7.56 | learning rate: 1.056E-05 | global batch size:    16 | lm loss: 8.852577E+00 | loss scale: 65536.0 | grad norm: 290956.343 | num zeros: 0.0 | params norm: 510.786 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.117 | TFLOPs: 22.35 |
 iteration      107/    1571 | consumed samples:          912 | consumed tokens:      1867776 | elapsed time per iteration (s): 7.56 | learning rate: 1.078E-05 | global batch size:    16 | lm loss: 8.827924E+00 | loss scale: 65536.0 | grad norm: 279921.524 | num zeros: 0.0 | params norm: 510.788 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.117 | TFLOPs: 22.36 |
 iteration      108/    1571 | consumed samples:          928 | consumed tokens:      1900544 | elapsed time per iteration (s): 7.56 | learning rate: 1.100E-05 | global batch size:    16 | lm loss: 8.796785E+00 | loss scale: 65536.0 | grad norm: 287410.546 | num zeros: 0.0 | params norm: 510.793 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.118 | TFLOPs: 22.36 |
 iteration      109/    1571 | consumed samples:          944 | consumed tokens:      1933312 | elapsed time per iteration (s): 7.56 | learning rate: 1.122E-05 | global batch size:    16 | lm loss: 8.782442E+00 | loss scale: 65536.0 | grad norm: 270495.610 | num zeros: 0.0 | params norm: 510.798 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.118 | TFLOPs: 22.36 |
 iteration      110/    1571 | consumed samples:          960 | consumed tokens:      1966080 | elapsed time per iteration (s): 7.55 | learning rate: 1.144E-05 | global batch size:    16 | lm loss: 8.674932E+00 | loss scale: 65536.0 | grad norm: 290476.295 | num zeros: 0.0 | params norm: 510.801 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.119 | TFLOPs: 22.38 |
 iteration      111/    1571 | consumed samples:          976 | consumed tokens:      1998848 | elapsed time per iteration (s): 7.55 | learning rate: 1.167E-05 | global batch size:    16 | lm loss: 8.710068E+00 | loss scale: 65536.0 | grad norm: 265058.689 | num zeros: 0.0 | params norm: 510.803 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.118 | TFLOPs: 22.37 |
 iteration      112/    1571 | consumed samples:          992 | consumed tokens:      2031616 | elapsed time per iteration (s): 7.55 | learning rate: 1.189E-05 | global batch size:    16 | lm loss: 8.680470E+00 | loss scale: 65536.0 | grad norm: 281657.912 | num zeros: 0.0 | params norm: 510.806 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.118 | TFLOPs: 22.36 |
 iteration      113/    1571 | consumed samples:         1008 | consumed tokens:      2064384 | elapsed time per iteration (s): 7.56 | learning rate: 1.211E-05 | global batch size:    16 | lm loss: 8.615963E+00 | loss scale: 65536.0 | grad norm: 275364.043 | num zeros: 0.0 | params norm: 510.809 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.116 | TFLOPs: 22.35 |
 iteration      114/    1571 | consumed samples:         1024 | consumed tokens:      2097152 | elapsed time per iteration (s): 7.57 | learning rate: 1.233E-05 | global batch size:    16 | lm loss: 8.579528E+00 | loss scale: 65536.0 | grad norm: 277405.025 | num zeros: 0.0 | params norm: 510.812 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.115 | TFLOPs: 22.33 |
 iteration      115/    1571 | consumed samples:         1040 | consumed tokens:      2129920 | elapsed time per iteration (s): 7.56 | learning rate: 1.256E-05 | global batch size:    16 | lm loss: 8.532673E+00 | loss scale: 65536.0 | grad norm: 275428.005 | num zeros: 0.0 | params norm: 510.815 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.118 | TFLOPs: 22.36 |
 iteration      116/    1571 | consumed samples:         1056 | consumed tokens:      2162688 | elapsed time per iteration (s): 7.56 | learning rate: 1.278E-05 | global batch size:    16 | lm loss: 8.532942E+00 | loss scale: 65536.0 | grad norm: 277373.450 | num zeros: 0.0 | params norm: 510.818 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.117 | TFLOPs: 22.36 |
 iteration      117/    1571 | consumed samples:         1072 | consumed tokens:      2195456 | elapsed time per iteration (s): 7.56 | learning rate: 1.300E-05 | global batch size:    16 | lm loss: 8.446451E+00 | loss scale: 65536.0 | grad norm: 281642.660 | num zeros: 0.0 | params norm: 510.821 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.117 | TFLOPs: 22.36 |
 iteration      118/    1571 | consumed samples:         1088 | consumed tokens:      2228224 | elapsed time per iteration (s): 7.56 | learning rate: 1.322E-05 | global batch size:    16 | lm loss: 8.483829E+00 | loss scale: 65536.0 | grad norm: 262272.956 | num zeros: 0.0 | params norm: 510.824 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.118 | TFLOPs: 22.36 |
 iteration      119/    1571 | consumed samples:         1104 | consumed tokens:      2260992 | elapsed time per iteration (s): 7.57 | learning rate: 1.344E-05 | global batch size:    16 | lm loss: 8.415537E+00 | loss scale: 65536.0 | grad norm: 266351.343 | num zeros: 0.0 | params norm: 510.827 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.113 | TFLOPs: 22.31 |
 iteration      120/    1571 | consumed samples:         1120 | consumed tokens:      2293760 | elapsed time per iteration (s): 7.55 | learning rate: 1.367E-05 | global batch size:    16 | lm loss: 8.438717E+00 | loss scale: 65536.0 | grad norm: 301464.367 | num zeros: 0.0 | params norm: 510.831 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.118 | TFLOPs: 22.36 |
 iteration      121/    1571 | consumed samples:         1136 | consumed tokens:      2326528 | elapsed time per iteration (s): 7.56 | learning rate: 1.389E-05 | global batch size:    16 | lm loss: 8.387389E+00 | loss scale: 65536.0 | grad norm: 265443.932 | num zeros: 0.0 | params norm: 510.834 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.115 | TFLOPs: 22.34 |
 iteration      122/    1571 | consumed samples:         1152 | consumed tokens:      2359296 | elapsed time per iteration (s): 7.56 | learning rate: 1.411E-05 | global batch size:    16 | lm loss: 8.354806E+00 | loss scale: 65536.0 | grad norm: 284393.137 | num zeros: 0.0 | params norm: 510.838 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.116 | TFLOPs: 22.34 |
 iteration      123/    1571 | consumed samples:         1168 | consumed tokens:      2392064 | elapsed time per iteration (s): 7.56 | learning rate: 1.433E-05 | global batch size:    16 | lm loss: 8.276531E+00 | loss scale: 65536.0 | grad norm: 263732.183 | num zeros: 0.0 | params norm: 510.842 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.115 | TFLOPs: 22.34 |
 iteration      124/    1571 | consumed samples:         1184 | consumed tokens:      2424832 | elapsed time per iteration (s): 7.56 | learning rate: 1.456E-05 | global batch size:    16 | lm loss: 8.260607E+00 | loss scale: 65536.0 | grad norm: 412240.543 | num zeros: 0.0 | params norm: 510.846 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.115 | TFLOPs: 22.34 |
 iteration      125/    1571 | consumed samples:         1200 | consumed tokens:      2457600 | elapsed time per iteration (s): 7.55 | learning rate: 1.478E-05 | global batch size:    16 | lm loss: 8.355145E+00 | loss scale: 65536.0 | grad norm: 247553.565 | num zeros: 0.0 | params norm: 510.850 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.118 | TFLOPs: 22.36 |
 iteration      126/    1571 | consumed samples:         1216 | consumed tokens:      2490368 | elapsed time per iteration (s): 7.56 | learning rate: 1.500E-05 | global batch size:    16 | lm loss: 8.227474E+00 | loss scale: 65536.0 | grad norm: 245546.265 | num zeros: 0.0 | params norm: 510.854 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.116 | TFLOPs: 22.35 |
 iteration      127/    1571 | consumed samples:         1232 | consumed tokens:      2523136 | elapsed time per iteration (s): 7.29 | learning rate: 1.500E-05 | global batch size:    16 | lm loss: 8.561518E+00 | loss scale: 32768.0 | grad norm: 245546.265 | num zeros: 0.0 | params norm: 510.854 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.195 | TFLOPs: 23.18 |
 iteration      128/    1571 | consumed samples:         1248 | consumed tokens:      2555904 | elapsed time per iteration (s): 7.29 | learning rate: 1.500E-05 | global batch size:    16 | lm loss: 8.369086E+00 | loss scale: 16384.0 | grad norm: 245546.265 | num zeros: 0.0 | params norm: 510.854 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.194 | TFLOPs: 23.17 |
 iteration      129/    1571 | consumed samples:         1264 | consumed tokens:      2588672 | elapsed time per iteration (s): 7.30 | learning rate: 1.500E-05 | global batch size:    16 | lm loss: 8.296515E+00 | loss scale: 8192.0 | grad norm: 245546.265 | num zeros: 0.0 | params norm: 510.854 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.193 | TFLOPs: 23.15 |
 iteration      130/    1571 | consumed samples:         1280 | consumed tokens:      2621440 | elapsed time per iteration (s): 7.57 | learning rate: 1.522E-05 | global batch size:    16 | lm loss: 8.312473E+00 | loss scale: 8192.0 | grad norm: 600284.559 | num zeros: 0.0 | params norm: 510.858 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.114 | TFLOPs: 22.32 |
 iteration      131/    1571 | consumed samples:         1296 | consumed tokens:      2654208 | elapsed time per iteration (s): 7.56 | learning rate: 1.544E-05 | global batch size:    16 | lm loss: 8.147539E+00 | loss scale: 8192.0 | grad norm: 33140.129 | num zeros: 0.0 | params norm: 510.862 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.117 | TFLOPs: 22.35 |
 iteration      132/    1571 | consumed samples:         1312 | consumed tokens:      2686976 | elapsed time per iteration (s): 7.55 | learning rate: 1.567E-05 | global batch size:    16 | lm loss: 8.200749E+00 | loss scale: 8192.0 | grad norm: 29051.239 | num zeros: 0.0 | params norm: 510.866 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.119 | TFLOPs: 22.37 |
 iteration      133/    1571 | consumed samples:         1328 | consumed tokens:      2719744 | elapsed time per iteration (s): 7.55 | learning rate: 1.589E-05 | global batch size:    16 | lm loss: 8.076900E+00 | loss scale: 8192.0 | grad norm: 32716.356 | num zeros: 0.0 | params norm: 510.871 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.119 | TFLOPs: 22.38 |
 iteration      134/    1571 | consumed samples:         1344 | consumed tokens:      2752512 | elapsed time per iteration (s): 7.58 | learning rate: 1.611E-05 | global batch size:    16 | lm loss: 8.073407E+00 | loss scale: 8192.0 | grad norm: 42451.897 | num zeros: 0.0 | params norm: 510.875 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.112 | TFLOPs: 22.30 |
 iteration      135/    1571 | consumed samples:         1360 | consumed tokens:      2785280 | elapsed time per iteration (s): 7.55 | learning rate: 1.633E-05 | global batch size:    16 | lm loss: 8.110737E+00 | loss scale: 8192.0 | grad norm: 29447.626 | num zeros: 0.0 | params norm: 510.880 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.120 | TFLOPs: 22.39 |
 iteration      136/    1571 | consumed samples:         1376 | consumed tokens:      2818048 | elapsed time per iteration (s): 7.56 | learning rate: 1.656E-05 | global batch size:    16 | lm loss: 8.087128E+00 | loss scale: 8192.0 | grad norm: 29393.226 | num zeros: 0.0 | params norm: 510.885 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.118 | TFLOPs: 22.36 |
 iteration      137/    1571 | consumed samples:         1392 | consumed tokens:      2850816 | elapsed time per iteration (s): 7.55 | learning rate: 1.678E-05 | global batch size:    16 | lm loss: 8.032375E+00 | loss scale: 8192.0 | grad norm: 28572.433 | num zeros: 0.0 | params norm: 510.890 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.118 | TFLOPs: 22.36 |
 iteration      138/    1571 | consumed samples:         1408 | consumed tokens:      2883584 | elapsed time per iteration (s): 7.56 | learning rate: 1.700E-05 | global batch size:    16 | lm loss: 8.036757E+00 | loss scale: 8192.0 | grad norm: 26832.677 | num zeros: 0.0 | params norm: 510.895 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.117 | TFLOPs: 22.35 |
 iteration      139/    1571 | consumed samples:         1424 | consumed tokens:      2916352 | elapsed time per iteration (s): 7.56 | learning rate: 1.722E-05 | global batch size:    16 | lm loss: 7.904717E+00 | loss scale: 8192.0 | grad norm: 30331.759 | num zeros: 0.0 | params norm: 510.900 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.116 | TFLOPs: 22.34 |
 iteration      140/    1571 | consumed samples:         1440 | consumed tokens:      2949120 | elapsed time per iteration (s): 7.55 | learning rate: 1.744E-05 | global batch size:    16 | lm loss: 8.013383E+00 | loss scale: 8192.0 | grad norm: 24893.464 | num zeros: 0.0 | params norm: 510.906 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.118 | TFLOPs: 22.37 |
 iteration      141/    1571 | consumed samples:         1456 | consumed tokens:      2981888 | elapsed time per iteration (s): 7.56 | learning rate: 1.767E-05 | global batch size:    16 | lm loss: 7.874379E+00 | loss scale: 8192.0 | grad norm: 26854.812 | num zeros: 0.0 | params norm: 510.911 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.116 | TFLOPs: 22.35 |
 iteration      142/    1571 | consumed samples:         1472 | consumed tokens:      3014656 | elapsed time per iteration (s): 7.56 | learning rate: 1.789E-05 | global batch size:    16 | lm loss: 7.844928E+00 | loss scale: 8192.0 | grad norm: 25323.336 | num zeros: 0.0 | params norm: 510.917 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.116 | TFLOPs: 22.35 |
 iteration      143/    1571 | consumed samples:         1488 | consumed tokens:      3047424 | elapsed time per iteration (s): 7.56 | learning rate: 1.811E-05 | global batch size:    16 | lm loss: 7.884980E+00 | loss scale: 8192.0 | grad norm: 23659.216 | num zeros: 0.0 | params norm: 510.923 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.117 | TFLOPs: 22.36 |
 iteration      144/    1571 | consumed samples:         1504 | consumed tokens:      3080192 | elapsed time per iteration (s): 7.55 | learning rate: 1.833E-05 | global batch size:    16 | lm loss: 7.853069E+00 | loss scale: 8192.0 | grad norm: 24045.260 | num zeros: 0.0 | params norm: 510.929 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.119 | TFLOPs: 22.37 |
 iteration      145/    1571 | consumed samples:         1520 | consumed tokens:      3112960 | elapsed time per iteration (s): 7.55 | learning rate: 1.856E-05 | global batch size:    16 | lm loss: 7.825196E+00 | loss scale: 8192.0 | grad norm: 24391.486 | num zeros: 0.0 | params norm: 510.935 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.120 | TFLOPs: 22.39 |
 iteration      146/    1571 | consumed samples:         1536 | consumed tokens:      3145728 | elapsed time per iteration (s): 7.55 | learning rate: 1.878E-05 | global batch size:    16 | lm loss: 7.808974E+00 | loss scale: 8192.0 | grad norm: 24698.262 | num zeros: 0.0 | params norm: 510.942 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.119 | TFLOPs: 22.37 |
 iteration      147/    1571 | consumed samples:         1552 | consumed tokens:      3178496 | elapsed time per iteration (s): 7.57 | learning rate: 1.900E-05 | global batch size:    16 | lm loss: 7.790380E+00 | loss scale: 8192.0 | grad norm: 23396.108 | num zeros: 0.0 | params norm: 510.949 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.112 | TFLOPs: 22.30 |
 iteration      148/    1571 | consumed samples:         1568 | consumed tokens:      3211264 | elapsed time per iteration (s): 7.55 | learning rate: 1.922E-05 | global batch size:    16 | lm loss: 7.717967E+00 | loss scale: 8192.0 | grad norm: 23772.813 | num zeros: 0.0 | params norm: 510.955 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.119 | TFLOPs: 22.38 |
 iteration      149/    1571 | consumed samples:         1584 | consumed tokens:      3244032 | elapsed time per iteration (s): 7.56 | learning rate: 1.944E-05 | global batch size:    16 | lm loss: 7.734910E+00 | loss scale: 8192.0 | grad norm: 21249.120 | num zeros: 0.0 | params norm: 510.962 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.116 | TFLOPs: 22.35 |
 iteration      150/    1571 | consumed samples:         1600 | consumed tokens:      3276800 | elapsed time per iteration (s): 7.55 | learning rate: 1.967E-05 | global batch size:    16 | lm loss: 7.611983E+00 | loss scale: 8192.0 | grad norm: 24557.824 | num zeros: 0.0 | params norm: 510.969 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.118 | TFLOPs: 22.37 |
 iteration      151/    1571 | consumed samples:         1624 | consumed tokens:      3325952 | elapsed time per iteration (s): 9.01 | learning rate: 2.000E-05 | global batch size:    24 | lm loss: 7.695198E+00 | loss scale: 8192.0 | grad norm: 24764.440 | num zeros: 0.0 | params norm: 510.977 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.664 | TFLOPs: 28.13 |
 iteration      152/    1571 | consumed samples:         1648 | consumed tokens:      3375104 | elapsed time per iteration (s): 9.01 | learning rate: 2.033E-05 | global batch size:    24 | lm loss: 7.694012E+00 | loss scale: 8192.0 | grad norm: 23448.502 | num zeros: 0.0 | params norm: 510.984 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.665 | TFLOPs: 28.14 |
 iteration      153/    1571 | consumed samples:         1672 | consumed tokens:      3424256 | elapsed time per iteration (s): 9.01 | learning rate: 2.067E-05 | global batch size:    24 | lm loss: 7.651975E+00 | loss scale: 8192.0 | grad norm: 94269.040 | num zeros: 0.0 | params norm: 510.991 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.664 | TFLOPs: 28.13 |
 iteration      154/    1571 | consumed samples:         1696 | consumed tokens:      3473408 | elapsed time per iteration (s): 9.01 | learning rate: 2.100E-05 | global batch size:    24 | lm loss: 7.659517E+00 | loss scale: 8192.0 | grad norm: 23437.727 | num zeros: 0.0 | params norm: 510.998 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.663 | TFLOPs: 28.11 |
 iteration      155/    1571 | consumed samples:         1720 | consumed tokens:      3522560 | elapsed time per iteration (s): 9.02 | learning rate: 2.133E-05 | global batch size:    24 | lm loss: 7.649824E+00 | loss scale: 8192.0 | grad norm: 16998.857 | num zeros: 0.0 | params norm: 511.006 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.662 | TFLOPs: 28.11 |
 iteration      156/    1571 | consumed samples:         1744 | consumed tokens:      3571712 | elapsed time per iteration (s): 9.02 | learning rate: 2.167E-05 | global batch size:    24 | lm loss: 7.679895E+00 | loss scale: 8192.0 | grad norm: 27179.426 | num zeros: 0.0 | params norm: 511.014 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.662 | TFLOPs: 28.10 |
 iteration      157/    1571 | consumed samples:         1768 | consumed tokens:      3620864 | elapsed time per iteration (s): 8.76 | learning rate: 2.167E-05 | global batch size:    24 | lm loss: 7.746372E+00 | loss scale: 4096.0 | grad norm: 27179.426 | num zeros: 0.0 | params norm: 511.014 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.738 | TFLOPs: 28.92 |
 iteration      158/    1571 | consumed samples:         1792 | consumed tokens:      3670016 | elapsed time per iteration (s): 9.03 | learning rate: 2.200E-05 | global batch size:    24 | lm loss: 7.759065E+00 | loss scale: 4096.0 | grad norm: 364577.677 | num zeros: 0.0 | params norm: 511.021 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.657 | TFLOPs: 28.06 |
 iteration      159/    1571 | consumed samples:         1816 | consumed tokens:      3719168 | elapsed time per iteration (s): 9.01 | learning rate: 2.233E-05 | global batch size:    24 | lm loss: 7.603968E+00 | loss scale: 4096.0 | grad norm: 8962.619 | num zeros: 0.0 | params norm: 511.029 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.663 | TFLOPs: 28.12 |
 iteration      160/    1571 | consumed samples:         1840 | consumed tokens:      3768320 | elapsed time per iteration (s): 9.01 | learning rate: 2.267E-05 | global batch size:    24 | lm loss: 7.601894E+00 | loss scale: 4096.0 | grad norm: 7536.168 | num zeros: 0.0 | params norm: 511.037 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.665 | TFLOPs: 28.14 |
 iteration      161/    1571 | consumed samples:         1864 | consumed tokens:      3817472 | elapsed time per iteration (s): 9.02 | learning rate: 2.300E-05 | global batch size:    24 | lm loss: 7.662894E+00 | loss scale: 4096.0 | grad norm: 18249.155 | num zeros: 0.0 | params norm: 511.045 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.661 | TFLOPs: 28.09 |
 iteration      162/    1571 | consumed samples:         1888 | consumed tokens:      3866624 | elapsed time per iteration (s): 9.02 | learning rate: 2.333E-05 | global batch size:    24 | lm loss: 7.479089E+00 | loss scale: 4096.0 | grad norm: 8925.642 | num zeros: 0.0 | params norm: 511.054 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.660 | TFLOPs: 28.09 |
 iteration      163/    1571 | consumed samples:         1912 | consumed tokens:      3915776 | elapsed time per iteration (s): 9.03 | learning rate: 2.367E-05 | global batch size:    24 | lm loss: 7.553000E+00 | loss scale: 4096.0 | grad norm: 30347.779 | num zeros: 0.0 | params norm: 511.062 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.659 | TFLOPs: 28.08 |
 iteration      164/    1571 | consumed samples:         1936 | consumed tokens:      3964928 | elapsed time per iteration (s): 9.03 | learning rate: 2.400E-05 | global batch size:    24 | lm loss: 7.537072E+00 | loss scale: 4096.0 | grad norm: 6792.739 | num zeros: 0.0 | params norm: 511.071 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.658 | TFLOPs: 28.06 |
 iteration      165/    1571 | consumed samples:         1960 | consumed tokens:      4014080 | elapsed time per iteration (s): 9.02 | learning rate: 2.433E-05 | global batch size:    24 | lm loss: 7.473956E+00 | loss scale: 4096.0 | grad norm: 6896.243 | num zeros: 0.0 | params norm: 511.080 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.660 | TFLOPs: 28.09 |
 iteration      166/    1571 | consumed samples:         1984 | consumed tokens:      4063232 | elapsed time per iteration (s): 9.03 | learning rate: 2.467E-05 | global batch size:    24 | lm loss: 7.523069E+00 | loss scale: 4096.0 | grad norm: 6011.108 | num zeros: 0.0 | params norm: 511.090 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.659 | TFLOPs: 28.07 |
 iteration      167/    1571 | consumed samples:         2008 | consumed tokens:      4112384 | elapsed time per iteration (s): 9.03 | learning rate: 2.500E-05 | global batch size:    24 | lm loss: 7.531996E+00 | loss scale: 4096.0 | grad norm: 11508.105 | num zeros: 0.0 | params norm: 511.101 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.658 | TFLOPs: 28.07 |
 iteration      168/    1571 | consumed samples:         2032 | consumed tokens:      4161536 | elapsed time per iteration (s): 9.02 | learning rate: 2.533E-05 | global batch size:    24 | lm loss: 7.506451E+00 | loss scale: 4096.0 | grad norm: 9366.391 | num zeros: 0.0 | params norm: 511.112 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.662 | TFLOPs: 28.10 |
 iteration      169/    1571 | consumed samples:         2056 | consumed tokens:      4210688 | elapsed time per iteration (s): 9.02 | learning rate: 2.567E-05 | global batch size:    24 | lm loss: 7.461761E+00 | loss scale: 4096.0 | grad norm: 6590.478 | num zeros: 0.0 | params norm: 511.124 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.661 | TFLOPs: 28.10 |
 iteration      170/    1571 | consumed samples:         2080 | consumed tokens:      4259840 | elapsed time per iteration (s): 9.02 | learning rate: 2.600E-05 | global batch size:    24 | lm loss: 7.511352E+00 | loss scale: 4096.0 | grad norm: 7071.363 | num zeros: 0.0 | params norm: 511.135 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.661 | TFLOPs: 28.09 |
 iteration      171/    1571 | consumed samples:         2104 | consumed tokens:      4308992 | elapsed time per iteration (s): 9.02 | learning rate: 2.633E-05 | global batch size:    24 | lm loss: 7.447291E+00 | loss scale: 4096.0 | grad norm: 9042.697 | num zeros: 0.0 | params norm: 511.145 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.660 | TFLOPs: 28.09 |
 iteration      172/    1571 | consumed samples:         2128 | consumed tokens:      4358144 | elapsed time per iteration (s): 9.03 | learning rate: 2.667E-05 | global batch size:    24 | lm loss: 7.536935E+00 | loss scale: 4096.0 | grad norm: 9629.570 | num zeros: 0.0 | params norm: 511.156 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.657 | TFLOPs: 28.06 |
 iteration      173/    1571 | consumed samples:         2152 | consumed tokens:      4407296 | elapsed time per iteration (s): 9.03 | learning rate: 2.700E-05 | global batch size:    24 | lm loss: 7.508332E+00 | loss scale: 4096.0 | grad norm: 6429.975 | num zeros: 0.0 | params norm: 511.167 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.659 | TFLOPs: 28.08 |
 iteration      174/    1571 | consumed samples:         2176 | consumed tokens:      4456448 | elapsed time per iteration (s): 9.02 | learning rate: 2.733E-05 | global batch size:    24 | lm loss: 7.434974E+00 | loss scale: 4096.0 | grad norm: 7687.655 | num zeros: 0.0 | params norm: 511.178 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.659 | TFLOPs: 28.08 |
 iteration      175/    1571 | consumed samples:         2200 | consumed tokens:      4505600 | elapsed time per iteration (s): 9.02 | learning rate: 2.767E-05 | global batch size:    24 | lm loss: 7.419573E+00 | loss scale: 4096.0 | grad norm: 6411.611 | num zeros: 0.0 | params norm: 511.190 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.660 | TFLOPs: 28.08 |
 iteration      176/    1571 | consumed samples:         2224 | consumed tokens:      4554752 | elapsed time per iteration (s): 9.03 | learning rate: 2.800E-05 | global batch size:    24 | lm loss: 7.400186E+00 | loss scale: 4096.0 | grad norm: 5449.468 | num zeros: 0.0 | params norm: 511.202 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.656 | TFLOPs: 28.05 |
 iteration      177/    1571 | consumed samples:         2248 | consumed tokens:      4603904 | elapsed time per iteration (s): 9.02 | learning rate: 2.833E-05 | global batch size:    24 | lm loss: 7.339108E+00 | loss scale: 4096.0 | grad norm: 4525.188 | num zeros: 0.0 | params norm: 511.214 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.660 | TFLOPs: 28.09 |
 iteration      178/    1571 | consumed samples:         2272 | consumed tokens:      4653056 | elapsed time per iteration (s): 9.02 | learning rate: 2.867E-05 | global batch size:    24 | lm loss: 7.441478E+00 | loss scale: 4096.0 | grad norm: 13025.435 | num zeros: 0.0 | params norm: 511.227 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.662 | TFLOPs: 28.11 |
 iteration      179/    1571 | consumed samples:         2296 | consumed tokens:      4702208 | elapsed time per iteration (s): 9.03 | learning rate: 2.900E-05 | global batch size:    24 | lm loss: 7.429283E+00 | loss scale: 4096.0 | grad norm: 6759.368 | num zeros: 0.0 | params norm: 511.239 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.659 | TFLOPs: 28.08 |
 iteration      180/    1571 | consumed samples:         2320 | consumed tokens:      4751360 | elapsed time per iteration (s): 9.04 | learning rate: 2.933E-05 | global batch size:    24 | lm loss: 7.442425E+00 | loss scale: 4096.0 | grad norm: 27861.333 | num zeros: 0.0 | params norm: 511.251 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.656 | TFLOPs: 28.05 |
 iteration      181/    1571 | consumed samples:         2344 | consumed tokens:      4800512 | elapsed time per iteration (s): 9.03 | learning rate: 2.967E-05 | global batch size:    24 | lm loss: 7.322698E+00 | loss scale: 4096.0 | grad norm: 7743.452 | num zeros: 0.0 | params norm: 511.263 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.658 | TFLOPs: 28.06 |
 iteration      182/    1571 | consumed samples:         2368 | consumed tokens:      4849664 | elapsed time per iteration (s): 9.02 | learning rate: 3.000E-05 | global batch size:    24 | lm loss: 7.466360E+00 | loss scale: 4096.0 | grad norm: 16829.225 | num zeros: 0.0 | params norm: 511.275 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.660 | TFLOPs: 28.09 |
 iteration      183/    1571 | consumed samples:         2392 | consumed tokens:      4898816 | elapsed time per iteration (s): 9.03 | learning rate: 3.033E-05 | global batch size:    24 | lm loss: 7.382146E+00 | loss scale: 4096.0 | grad norm: 10984.703 | num zeros: 0.0 | params norm: 511.287 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.657 | TFLOPs: 28.06 |
 iteration      184/    1571 | consumed samples:         2416 | consumed tokens:      4947968 | elapsed time per iteration (s): 9.03 | learning rate: 3.067E-05 | global batch size:    24 | lm loss: 7.382064E+00 | loss scale: 4096.0 | grad norm: 48929.177 | num zeros: 0.0 | params norm: 511.299 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 2.657 | TFLOPs: 28.06 |
 iteration      185/    1571 | consumed samples:         2448 | consumed tokens:      5013504 | elapsed time per iteration (s): 10.49 | learning rate: 3.111E-05 | global batch size:    32 | lm loss: 7.424858E+00 | loss scale: 4096.0 | grad norm: 8747.011 | num zeros: 0.0 | params norm: 511.310 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.051 | TFLOPs: 32.21 |
 iteration      186/    1571 | consumed samples:         2480 | consumed tokens:      5079040 | elapsed time per iteration (s): 10.52 | learning rate: 3.156E-05 | global batch size:    32 | lm loss: 7.422849E+00 | loss scale: 4096.0 | grad norm: 14920.570 | num zeros: 0.0 | params norm: 511.321 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.042 | TFLOPs: 32.12 |
 iteration      187/    1571 | consumed samples:         2512 | consumed tokens:      5144576 | elapsed time per iteration (s): 10.51 | learning rate: 3.200E-05 | global batch size:    32 | lm loss: 7.428652E+00 | loss scale: 4096.0 | grad norm: 9954.140 | num zeros: 0.0 | params norm: 511.332 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.044 | TFLOPs: 32.15 |
 iteration      188/    1571 | consumed samples:         2544 | consumed tokens:      5210112 | elapsed time per iteration (s): 10.52 | learning rate: 3.244E-05 | global batch size:    32 | lm loss: 7.471079E+00 | loss scale: 4096.0 | grad norm: 11454.514 | num zeros: 0.0 | params norm: 511.344 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.042 | TFLOPs: 32.12 |
 iteration      189/    1571 | consumed samples:         2576 | consumed tokens:      5275648 | elapsed time per iteration (s): 10.51 | learning rate: 3.289E-05 | global batch size:    32 | lm loss: 7.346683E+00 | loss scale: 4096.0 | grad norm: 9349.908 | num zeros: 0.0 | params norm: 511.355 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.045 | TFLOPs: 32.15 |
 iteration      190/    1571 | consumed samples:         2608 | consumed tokens:      5341184 | elapsed time per iteration (s): 10.52 | learning rate: 3.333E-05 | global batch size:    32 | lm loss: 7.410258E+00 | loss scale: 4096.0 | grad norm: 6678.052 | num zeros: 0.0 | params norm: 511.367 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.042 | TFLOPs: 32.12 |
 iteration      191/    1571 | consumed samples:         2640 | consumed tokens:      5406720 | elapsed time per iteration (s): 10.53 | learning rate: 3.378E-05 | global batch size:    32 | lm loss: 7.361648E+00 | loss scale: 4096.0 | grad norm: 9348.646 | num zeros: 0.0 | params norm: 511.379 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.040 | TFLOPs: 32.10 |
 iteration      192/    1571 | consumed samples:         2672 | consumed tokens:      5472256 | elapsed time per iteration (s): 10.53 | learning rate: 3.422E-05 | global batch size:    32 | lm loss: 7.367609E+00 | loss scale: 4096.0 | grad norm: 9032.537 | num zeros: 0.0 | params norm: 511.390 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.038 | TFLOPs: 32.08 |
 iteration      193/    1571 | consumed samples:         2704 | consumed tokens:      5537792 | elapsed time per iteration (s): 10.52 | learning rate: 3.467E-05 | global batch size:    32 | lm loss: 7.319866E+00 | loss scale: 4096.0 | grad norm: 5444.827 | num zeros: 0.0 | params norm: 511.402 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.041 | TFLOPs: 32.11 |
 iteration      194/    1571 | consumed samples:         2736 | consumed tokens:      5603328 | elapsed time per iteration (s): 10.54 | learning rate: 3.511E-05 | global batch size:    32 | lm loss: 7.462703E+00 | loss scale: 4096.0 | grad norm: 41487.155 | num zeros: 0.0 | params norm: 511.414 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.037 | TFLOPs: 32.07 |
 iteration      195/    1571 | consumed samples:         2768 | consumed tokens:      5668864 | elapsed time per iteration (s): 10.53 | learning rate: 3.556E-05 | global batch size:    32 | lm loss: 7.371313E+00 | loss scale: 4096.0 | grad norm: 12568.811 | num zeros: 0.0 | params norm: 511.426 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.040 | TFLOPs: 32.10 |
 iteration      196/    1571 | consumed samples:         2800 | consumed tokens:      5734400 | elapsed time per iteration (s): 10.51 | learning rate: 3.600E-05 | global batch size:    32 | lm loss: 7.389075E+00 | loss scale: 4096.0 | grad norm: 16226.731 | num zeros: 0.0 | params norm: 511.438 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.044 | TFLOPs: 32.14 |
 iteration      197/    1571 | consumed samples:         2832 | consumed tokens:      5799936 | elapsed time per iteration (s): 10.52 | learning rate: 3.644E-05 | global batch size:    32 | lm loss: 7.384642E+00 | loss scale: 4096.0 | grad norm: 8216.427 | num zeros: 0.0 | params norm: 511.449 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.042 | TFLOPs: 32.12 |
 iteration      198/    1571 | consumed samples:         2864 | consumed tokens:      5865472 | elapsed time per iteration (s): 10.54 | learning rate: 3.689E-05 | global batch size:    32 | lm loss: 7.326413E+00 | loss scale: 4096.0 | grad norm: 8402.903 | num zeros: 0.0 | params norm: 511.461 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.037 | TFLOPs: 32.07 |
 iteration      199/    1571 | consumed samples:         2896 | consumed tokens:      5931008 | elapsed time per iteration (s): 10.54 | learning rate: 3.733E-05 | global batch size:    32 | lm loss: 7.270999E+00 | loss scale: 4096.0 | grad norm: 6864.623 | num zeros: 0.0 | params norm: 511.473 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.035 | TFLOPs: 32.05 |
 iteration      200/    1571 | consumed samples:         2928 | consumed tokens:      5996544 | elapsed time per iteration (s): 10.54 | learning rate: 3.778E-05 | global batch size:    32 | lm loss: 7.328688E+00 | loss scale: 4096.0 | grad norm: 30230.366 | num zeros: 0.0 | params norm: 511.485 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.035 | TFLOPs: 32.05 |
 iteration      201/    1571 | consumed samples:         2960 | consumed tokens:      6062080 | elapsed time per iteration (s): 10.52 | learning rate: 3.822E-05 | global batch size:    32 | lm loss: 7.378051E+00 | loss scale: 4096.0 | grad norm: 7130.005 | num zeros: 0.0 | params norm: 511.497 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.042 | TFLOPs: 32.12 |
 iteration      202/    1571 | consumed samples:         2992 | consumed tokens:      6127616 | elapsed time per iteration (s): 10.54 | learning rate: 3.867E-05 | global batch size:    32 | lm loss: 7.365363E+00 | loss scale: 4096.0 | grad norm: 8430.257 | num zeros: 0.0 | params norm: 511.511 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.037 | TFLOPs: 32.07 |
 iteration      203/    1571 | consumed samples:         3024 | consumed tokens:      6193152 | elapsed time per iteration (s): 10.53 | learning rate: 3.911E-05 | global batch size:    32 | lm loss: 7.238389E+00 | loss scale: 4096.0 | grad norm: 4688.873 | num zeros: 0.0 | params norm: 511.525 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.038 | TFLOPs: 32.08 |
 iteration      204/    1571 | consumed samples:         3056 | consumed tokens:      6258688 | elapsed time per iteration (s): 10.56 | learning rate: 3.956E-05 | global batch size:    32 | lm loss: 7.213309E+00 | loss scale: 4096.0 | grad norm: 4906.365 | num zeros: 0.0 | params norm: 511.539 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.032 | TFLOPs: 32.01 |
 iteration      205/    1571 | consumed samples:         3088 | consumed tokens:      6324224 | elapsed time per iteration (s): 10.53 | learning rate: 4.000E-05 | global batch size:    32 | lm loss: 7.337200E+00 | loss scale: 4096.0 | grad norm: 9118.711 | num zeros: 0.0 | params norm: 511.554 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.038 | TFLOPs: 32.08 |
 iteration      206/    1571 | consumed samples:         3120 | consumed tokens:      6389760 | elapsed time per iteration (s): 10.54 | learning rate: 4.044E-05 | global batch size:    32 | lm loss: 7.263081E+00 | loss scale: 4096.0 | grad norm: 5531.133 | num zeros: 0.0 | params norm: 511.571 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.036 | TFLOPs: 32.05 |
 iteration      207/    1571 | consumed samples:         3152 | consumed tokens:      6455296 | elapsed time per iteration (s): 10.52 | learning rate: 4.089E-05 | global batch size:    32 | lm loss: 7.270547E+00 | loss scale: 4096.0 | grad norm: 17333.429 | num zeros: 0.0 | params norm: 511.586 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.041 | TFLOPs: 32.11 |
 iteration      208/    1571 | consumed samples:         3184 | consumed tokens:      6520832 | elapsed time per iteration (s): 10.52 | learning rate: 4.133E-05 | global batch size:    32 | lm loss: 7.283916E+00 | loss scale: 4096.0 | grad norm: 7087.288 | num zeros: 0.0 | params norm: 511.601 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.041 | TFLOPs: 32.11 |
 iteration      209/    1571 | consumed samples:         3216 | consumed tokens:      6586368 | elapsed time per iteration (s): 10.53 | learning rate: 4.178E-05 | global batch size:    32 | lm loss: 7.313272E+00 | loss scale: 4096.0 | grad norm: 33071.781 | num zeros: 0.0 | params norm: 511.616 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.040 | TFLOPs: 32.10 |
 iteration      210/    1571 | consumed samples:         3256 | consumed tokens:      6668288 | elapsed time per iteration (s): 12.00 | learning rate: 4.233E-05 | global batch size:    40 | lm loss: 7.277585E+00 | loss scale: 4096.0 | grad norm: 7973.632 | num zeros: 0.0 | params norm: 511.633 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.335 | TFLOPs: 35.21 |
 iteration      211/    1571 | consumed samples:         3296 | consumed tokens:      6750208 | elapsed time per iteration (s): 12.00 | learning rate: 4.289E-05 | global batch size:    40 | lm loss: 7.318088E+00 | loss scale: 4096.0 | grad norm: 21918.640 | num zeros: 0.0 | params norm: 511.648 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.333 | TFLOPs: 35.19 |
 iteration      212/    1571 | consumed samples:         3336 | consumed tokens:      6832128 | elapsed time per iteration (s): 12.00 | learning rate: 4.344E-05 | global batch size:    40 | lm loss: 7.334003E+00 | loss scale: 4096.0 | grad norm: 13783.626 | num zeros: 0.0 | params norm: 511.663 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.332 | TFLOPs: 35.19 |
 iteration      213/    1571 | consumed samples:         3376 | consumed tokens:      6914048 | elapsed time per iteration (s): 12.03 | learning rate: 4.400E-05 | global batch size:    40 | lm loss: 7.397338E+00 | loss scale: 4096.0 | grad norm: 125963.351 | num zeros: 0.0 | params norm: 511.678 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.325 | TFLOPs: 35.11 |
 iteration      214/    1571 | consumed samples:         3416 | consumed tokens:      6995968 | elapsed time per iteration (s): 12.00 | learning rate: 4.456E-05 | global batch size:    40 | lm loss: 7.298188E+00 | loss scale: 4096.0 | grad norm: 10632.126 | num zeros: 0.0 | params norm: 511.692 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.333 | TFLOPs: 35.20 |
 iteration      215/    1571 | consumed samples:         3456 | consumed tokens:      7077888 | elapsed time per iteration (s): 12.01 | learning rate: 4.511E-05 | global batch size:    40 | lm loss: 7.242214E+00 | loss scale: 4096.0 | grad norm: 11816.273 | num zeros: 0.0 | params norm: 511.706 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.331 | TFLOPs: 35.18 |
 iteration      216/    1571 | consumed samples:         3496 | consumed tokens:      7159808 | elapsed time per iteration (s): 12.00 | learning rate: 4.567E-05 | global batch size:    40 | lm loss: 7.314483E+00 | loss scale: 4096.0 | grad norm: 9195.723 | num zeros: 0.0 | params norm: 511.720 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.332 | TFLOPs: 35.18 |
 iteration      217/    1571 | consumed samples:         3536 | consumed tokens:      7241728 | elapsed time per iteration (s): 12.01 | learning rate: 4.622E-05 | global batch size:    40 | lm loss: 7.246594E+00 | loss scale: 4096.0 | grad norm: 10554.367 | num zeros: 0.0 | params norm: 511.735 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.330 | TFLOPs: 35.16 |
 iteration      218/    1571 | consumed samples:         3576 | consumed tokens:      7323648 | elapsed time per iteration (s): 12.02 | learning rate: 4.678E-05 | global batch size:    40 | lm loss: 7.263927E+00 | loss scale: 4096.0 | grad norm: 6912.114 | num zeros: 0.0 | params norm: 511.749 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.329 | TFLOPs: 35.15 |
 iteration      219/    1571 | consumed samples:         3616 | consumed tokens:      7405568 | elapsed time per iteration (s): 12.01 | learning rate: 4.733E-05 | global batch size:    40 | lm loss: 7.211603E+00 | loss scale: 4096.0 | grad norm: 5809.887 | num zeros: 0.0 | params norm: 511.764 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.331 | TFLOPs: 35.18 |
 iteration      220/    1571 | consumed samples:         3656 | consumed tokens:      7487488 | elapsed time per iteration (s): 12.02 | learning rate: 4.789E-05 | global batch size:    40 | lm loss: 7.161739E+00 | loss scale: 4096.0 | grad norm: 6507.796 | num zeros: 0.0 | params norm: 511.780 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.329 | TFLOPs: 35.15 |
 iteration      221/    1571 | consumed samples:         3696 | consumed tokens:      7569408 | elapsed time per iteration (s): 12.01 | learning rate: 4.844E-05 | global batch size:    40 | lm loss: 7.237614E+00 | loss scale: 4096.0 | grad norm: 5637.309 | num zeros: 0.0 | params norm: 511.797 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.330 | TFLOPs: 35.17 |
 iteration      222/    1571 | consumed samples:         3736 | consumed tokens:      7651328 | elapsed time per iteration (s): 12.01 | learning rate: 4.900E-05 | global batch size:    40 | lm loss: 7.173421E+00 | loss scale: 4096.0 | grad norm: 4562.743 | num zeros: 0.0 | params norm: 511.814 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.332 | TFLOPs: 35.18 |
 iteration      223/    1571 | consumed samples:         3776 | consumed tokens:      7733248 | elapsed time per iteration (s): 12.01 | learning rate: 4.956E-05 | global batch size:    40 | lm loss: 7.188513E+00 | loss scale: 4096.0 | grad norm: 6788.092 | num zeros: 0.0 | params norm: 511.832 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.329 | TFLOPs: 35.16 |
 iteration      224/    1571 | consumed samples:         3816 | consumed tokens:      7815168 | elapsed time per iteration (s): 12.01 | learning rate: 5.011E-05 | global batch size:    40 | lm loss: 7.245280E+00 | loss scale: 4096.0 | grad norm: 28874.932 | num zeros: 0.0 | params norm: 511.850 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.330 | TFLOPs: 35.16 |
 iteration      225/    1571 | consumed samples:         3856 | consumed tokens:      7897088 | elapsed time per iteration (s): 12.02 | learning rate: 5.067E-05 | global batch size:    40 | lm loss: 7.206573E+00 | loss scale: 4096.0 | grad norm: 13451.593 | num zeros: 0.0 | params norm: 511.867 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.328 | TFLOPs: 35.15 |
 iteration      226/    1571 | consumed samples:         3896 | consumed tokens:      7979008 | elapsed time per iteration (s): 12.00 | learning rate: 5.122E-05 | global batch size:    40 | lm loss: 7.131927E+00 | loss scale: 4096.0 | grad norm: 10666.001 | num zeros: 0.0 | params norm: 511.885 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.334 | TFLOPs: 35.20 |
 iteration      227/    1571 | consumed samples:         3936 | consumed tokens:      8060928 | elapsed time per iteration (s): 12.02 | learning rate: 5.178E-05 | global batch size:    40 | lm loss: 7.192443E+00 | loss scale: 4096.0 | grad norm: 6552.916 | num zeros: 0.0 | params norm: 511.903 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.327 | TFLOPs: 35.13 |
 iteration      228/    1571 | consumed samples:         3976 | consumed tokens:      8142848 | elapsed time per iteration (s): 12.02 | learning rate: 5.233E-05 | global batch size:    40 | lm loss: 7.238014E+00 | loss scale: 4096.0 | grad norm: 9727.449 | num zeros: 0.0 | params norm: 511.920 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.327 | TFLOPs: 35.13 |
 iteration      229/    1571 | consumed samples:         4016 | consumed tokens:      8224768 | elapsed time per iteration (s): 12.03 | learning rate: 5.289E-05 | global batch size:    40 | lm loss: 7.152481E+00 | loss scale: 4096.0 | grad norm: 21037.323 | num zeros: 0.0 | params norm: 511.937 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.324 | TFLOPs: 35.10 |
 iteration      230/    1571 | consumed samples:         4064 | consumed tokens:      8323072 | elapsed time per iteration (s): 13.48 | learning rate: 5.356E-05 | global batch size:    48 | lm loss: 7.154206E+00 | loss scale: 4096.0 | grad norm: 8407.268 | num zeros: 0.0 | params norm: 511.955 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.560 | TFLOPs: 37.59 |
 iteration      231/    1571 | consumed samples:         4112 | consumed tokens:      8421376 | elapsed time per iteration (s): 13.49 | learning rate: 5.422E-05 | global batch size:    48 | lm loss: 7.202665E+00 | loss scale: 4096.0 | grad norm: 5821.341 | num zeros: 0.0 | params norm: 511.972 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.557 | TFLOPs: 37.56 |
 iteration      232/    1571 | consumed samples:         4160 | consumed tokens:      8519680 | elapsed time per iteration (s): 13.51 | learning rate: 5.489E-05 | global batch size:    48 | lm loss: 7.149976E+00 | loss scale: 4096.0 | grad norm: 12666.005 | num zeros: 0.0 | params norm: 511.990 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.553 | TFLOPs: 37.52 |
 iteration      233/    1571 | consumed samples:         4208 | consumed tokens:      8617984 | elapsed time per iteration (s): 13.51 | learning rate: 5.556E-05 | global batch size:    48 | lm loss: 7.160798E+00 | loss scale: 4096.0 | grad norm: 29840.619 | num zeros: 0.0 | params norm: 512.007 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.552 | TFLOPs: 37.51 |
 iteration      234/    1571 | consumed samples:         4256 | consumed tokens:      8716288 | elapsed time per iteration (s): 13.50 | learning rate: 5.622E-05 | global batch size:    48 | lm loss: 7.209011E+00 | loss scale: 4096.0 | grad norm: 10742.057 | num zeros: 0.0 | params norm: 512.024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.555 | TFLOPs: 37.54 |
 iteration      235/    1571 | consumed samples:         4304 | consumed tokens:      8814592 | elapsed time per iteration (s): 13.49 | learning rate: 5.689E-05 | global batch size:    48 | lm loss: 7.109432E+00 | loss scale: 4096.0 | grad norm: 10693.139 | num zeros: 0.0 | params norm: 512.041 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.558 | TFLOPs: 37.57 |
 iteration      236/    1571 | consumed samples:         4352 | consumed tokens:      8912896 | elapsed time per iteration (s): 13.48 | learning rate: 5.756E-05 | global batch size:    48 | lm loss: 7.142526E+00 | loss scale: 4096.0 | grad norm: 4745.099 | num zeros: 0.0 | params norm: 512.059 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.560 | TFLOPs: 37.60 |
 iteration      237/    1571 | consumed samples:         4400 | consumed tokens:      9011200 | elapsed time per iteration (s): 13.50 | learning rate: 5.822E-05 | global batch size:    48 | lm loss: 7.143230E+00 | loss scale: 4096.0 | grad norm: 5936.153 | num zeros: 0.0 | params norm: 512.077 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.557 | TFLOPs: 37.56 |
 iteration      238/    1571 | consumed samples:         4448 | consumed tokens:      9109504 | elapsed time per iteration (s): 13.50 | learning rate: 5.889E-05 | global batch size:    48 | lm loss: 7.089676E+00 | loss scale: 4096.0 | grad norm: 4525.652 | num zeros: 0.0 | params norm: 512.096 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.554 | TFLOPs: 37.53 |
 iteration      239/    1571 | consumed samples:         4496 | consumed tokens:      9207808 | elapsed time per iteration (s): 13.54 | learning rate: 5.956E-05 | global batch size:    48 | lm loss: 7.094375E+00 | loss scale: 4096.0 | grad norm: 3620.883 | num zeros: 0.0 | params norm: 512.117 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.546 | TFLOPs: 37.44 |
 iteration      240/    1571 | consumed samples:         4544 | consumed tokens:      9306112 | elapsed time per iteration (s): 13.51 | learning rate: 6.022E-05 | global batch size:    48 | lm loss: 7.101862E+00 | loss scale: 4096.0 | grad norm: 5731.843 | num zeros: 0.0 | params norm: 512.140 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.554 | TFLOPs: 37.53 |
 iteration      241/    1571 | consumed samples:         4592 | consumed tokens:      9404416 | elapsed time per iteration (s): 13.52 | learning rate: 6.089E-05 | global batch size:    48 | lm loss: 7.087489E+00 | loss scale: 4096.0 | grad norm: 9081.128 | num zeros: 0.0 | params norm: 512.162 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.551 | TFLOPs: 37.50 |
 iteration      242/    1571 | consumed samples:         4640 | consumed tokens:      9502720 | elapsed time per iteration (s): 13.51 | learning rate: 6.156E-05 | global batch size:    48 | lm loss: 7.073411E+00 | loss scale: 4096.0 | grad norm: 13924.124 | num zeros: 0.0 | params norm: 512.184 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.552 | TFLOPs: 37.51 |
 iteration      243/    1571 | consumed samples:         4688 | consumed tokens:      9601024 | elapsed time per iteration (s): 13.52 | learning rate: 6.222E-05 | global batch size:    48 | lm loss: 7.098330E+00 | loss scale: 4096.0 | grad norm: 4891.264 | num zeros: 0.0 | params norm: 512.206 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.550 | TFLOPs: 37.48 |
 iteration      244/    1571 | consumed samples:         4736 | consumed tokens:      9699328 | elapsed time per iteration (s): 13.53 | learning rate: 6.289E-05 | global batch size:    48 | lm loss: 7.085108E+00 | loss scale: 4096.0 | grad norm: 5016.703 | num zeros: 0.0 | params norm: 512.227 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.549 | TFLOPs: 37.47 |
 iteration      245/    1571 | consumed samples:         4784 | consumed tokens:      9797632 | elapsed time per iteration (s): 13.52 | learning rate: 6.356E-05 | global batch size:    48 | lm loss: 7.164910E+00 | loss scale: 4096.0 | grad norm: 14044.197 | num zeros: 0.0 | params norm: 512.250 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.550 | TFLOPs: 37.48 |
 iteration      246/    1571 | consumed samples:         4832 | consumed tokens:      9895936 | elapsed time per iteration (s): 13.52 | learning rate: 6.422E-05 | global batch size:    48 | lm loss: 7.127419E+00 | loss scale: 4096.0 | grad norm: 10711.979 | num zeros: 0.0 | params norm: 512.273 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.549 | TFLOPs: 37.48 |
 iteration      247/    1571 | consumed samples:         4888 | consumed tokens:     10010624 | elapsed time per iteration (s): 15.01 | learning rate: 6.500E-05 | global batch size:    56 | lm loss: 7.103561E+00 | loss scale: 4096.0 | grad norm: 5719.393 | num zeros: 0.0 | params norm: 512.295 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.731 | TFLOPs: 39.40 |
 iteration      248/    1571 | consumed samples:         4944 | consumed tokens:     10125312 | elapsed time per iteration (s): 15.00 | learning rate: 6.578E-05 | global batch size:    56 | lm loss: 7.059635E+00 | loss scale: 4096.0 | grad norm: 4210.569 | num zeros: 0.0 | params norm: 512.319 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.733 | TFLOPs: 39.42 |
 iteration      249/    1571 | consumed samples:         5000 | consumed tokens:     10240000 | elapsed time per iteration (s): 15.00 | learning rate: 6.656E-05 | global batch size:    56 | lm loss: 7.100297E+00 | loss scale: 4096.0 | grad norm: 7277.902 | num zeros: 0.0 | params norm: 512.342 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.733 | TFLOPs: 39.42 |
 iteration      250/    1571 | consumed samples:         5056 | consumed tokens:     10354688 | elapsed time per iteration (s): 15.00 | learning rate: 6.733E-05 | global batch size:    56 | lm loss: 7.078259E+00 | loss scale: 4096.0 | grad norm: 9528.798 | num zeros: 0.0 | params norm: 512.366 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.734 | TFLOPs: 39.43 |
 iteration      251/    1571 | consumed samples:         5112 | consumed tokens:     10469376 | elapsed time per iteration (s): 14.99 | learning rate: 6.811E-05 | global batch size:    56 | lm loss: 7.042283E+00 | loss scale: 4096.0 | grad norm: 5881.710 | num zeros: 0.0 | params norm: 512.389 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.736 | TFLOPs: 39.45 |
 iteration      252/    1571 | consumed samples:         5168 | consumed tokens:     10584064 | elapsed time per iteration (s): 15.00 | learning rate: 6.889E-05 | global batch size:    56 | lm loss: 7.064313E+00 | loss scale: 4096.0 | grad norm: 4217.497 | num zeros: 0.0 | params norm: 512.413 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.733 | TFLOPs: 39.41 |
 iteration      253/    1571 | consumed samples:         5224 | consumed tokens:     10698752 | elapsed time per iteration (s): 15.02 | learning rate: 6.967E-05 | global batch size:    56 | lm loss: 7.049310E+00 | loss scale: 4096.0 | grad norm: 10045.215 | num zeros: 0.0 | params norm: 512.438 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.728 | TFLOPs: 39.37 |
 iteration      254/    1571 | consumed samples:         5280 | consumed tokens:     10813440 | elapsed time per iteration (s): 15.01 | learning rate: 7.044E-05 | global batch size:    56 | lm loss: 7.105215E+00 | loss scale: 4096.0 | grad norm: 7288.762 | num zeros: 0.0 | params norm: 512.461 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.730 | TFLOPs: 39.39 |
 iteration      255/    1571 | consumed samples:         5336 | consumed tokens:     10928128 | elapsed time per iteration (s): 15.01 | learning rate: 7.122E-05 | global batch size:    56 | lm loss: 7.024012E+00 | loss scale: 4096.0 | grad norm: 6524.831 | num zeros: 0.0 | params norm: 512.484 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.731 | TFLOPs: 39.40 |
 iteration      256/    1571 | consumed samples:         5392 | consumed tokens:     11042816 | elapsed time per iteration (s): 15.01 | learning rate: 7.200E-05 | global batch size:    56 | lm loss: 7.074872E+00 | loss scale: 4096.0 | grad norm: 4416.183 | num zeros: 0.0 | params norm: 512.507 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.732 | TFLOPs: 39.40 |
 iteration      257/    1571 | consumed samples:         5448 | consumed tokens:     11157504 | elapsed time per iteration (s): 15.01 | learning rate: 7.278E-05 | global batch size:    56 | lm loss: 7.036180E+00 | loss scale: 4096.0 | grad norm: 5257.668 | num zeros: 0.0 | params norm: 512.530 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.731 | TFLOPs: 39.40 |
 iteration      258/    1571 | consumed samples:         5504 | consumed tokens:     11272192 | elapsed time per iteration (s): 15.03 | learning rate: 7.356E-05 | global batch size:    56 | lm loss: 7.027635E+00 | loss scale: 4096.0 | grad norm: 7104.001 | num zeros: 0.0 | params norm: 512.555 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.726 | TFLOPs: 39.35 |
 iteration      259/    1571 | consumed samples:         5560 | consumed tokens:     11386880 | elapsed time per iteration (s): 15.00 | learning rate: 7.433E-05 | global batch size:    56 | lm loss: 6.985243E+00 | loss scale: 4096.0 | grad norm: 9249.443 | num zeros: 0.0 | params norm: 512.579 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.734 | TFLOPs: 39.43 |
 iteration      260/    1571 | consumed samples:         5616 | consumed tokens:     11501568 | elapsed time per iteration (s): 14.99 | learning rate: 7.511E-05 | global batch size:    56 | lm loss: 6.982987E+00 | loss scale: 4096.0 | grad norm: 9707.922 | num zeros: 0.0 | params norm: 512.603 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.735 | TFLOPs: 39.44 |
 iteration      261/    1571 | consumed samples:         5680 | consumed tokens:     11632640 | elapsed time per iteration (s): 16.49 | learning rate: 7.600E-05 | global batch size:    64 | lm loss: 6.945674E+00 | loss scale: 4096.0 | grad norm: 12297.392 | num zeros: 0.0 | params norm: 512.626 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.881 | TFLOPs: 40.98 |
 iteration      262/    1571 | consumed samples:         5744 | consumed tokens:     11763712 | elapsed time per iteration (s): 16.49 | learning rate: 7.689E-05 | global batch size:    64 | lm loss: 6.978471E+00 | loss scale: 4096.0 | grad norm: 4654.529 | num zeros: 0.0 | params norm: 512.650 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.881 | TFLOPs: 40.98 |
 iteration      263/    1571 | consumed samples:         5808 | consumed tokens:     11894784 | elapsed time per iteration (s): 16.48 | learning rate: 7.778E-05 | global batch size:    64 | lm loss: 7.002664E+00 | loss scale: 4096.0 | grad norm: 6573.045 | num zeros: 0.0 | params norm: 512.673 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.883 | TFLOPs: 41.00 |
 iteration      264/    1571 | consumed samples:         5872 | consumed tokens:     12025856 | elapsed time per iteration (s): 16.47 | learning rate: 7.867E-05 | global batch size:    64 | lm loss: 6.955747E+00 | loss scale: 4096.0 | grad norm: 8239.167 | num zeros: 0.0 | params norm: 512.696 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.887 | TFLOPs: 41.04 |
 iteration      265/    1571 | consumed samples:         5936 | consumed tokens:     12156928 | elapsed time per iteration (s): 16.49 | learning rate: 7.956E-05 | global batch size:    64 | lm loss: 6.957146E+00 | loss scale: 4096.0 | grad norm: 6464.569 | num zeros: 0.0 | params norm: 512.719 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.881 | TFLOPs: 40.98 |
 iteration      266/    1571 | consumed samples:         6000 | consumed tokens:     12288000 | elapsed time per iteration (s): 16.48 | learning rate: 8.044E-05 | global batch size:    64 | lm loss: 6.966850E+00 | loss scale: 4096.0 | grad norm: 6759.501 | num zeros: 0.0 | params norm: 512.742 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.883 | TFLOPs: 41.00 |
 iteration      267/    1571 | consumed samples:         6064 | consumed tokens:     12419072 | elapsed time per iteration (s): 16.48 | learning rate: 8.133E-05 | global batch size:    64 | lm loss: 6.970763E+00 | loss scale: 4096.0 | grad norm: 9737.180 | num zeros: 0.0 | params norm: 512.765 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.882 | TFLOPs: 40.99 |
 iteration      268/    1571 | consumed samples:         6128 | consumed tokens:     12550144 | elapsed time per iteration (s): 16.48 | learning rate: 8.222E-05 | global batch size:    64 | lm loss: 6.915460E+00 | loss scale: 4096.0 | grad norm: 6343.593 | num zeros: 0.0 | params norm: 512.787 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.884 | TFLOPs: 41.01 |
 iteration      269/    1571 | consumed samples:         6192 | consumed tokens:     12681216 | elapsed time per iteration (s): 16.49 | learning rate: 8.311E-05 | global batch size:    64 | lm loss: 6.966945E+00 | loss scale: 4096.0 | grad norm: 5547.252 | num zeros: 0.0 | params norm: 512.809 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.881 | TFLOPs: 40.98 |
 iteration      270/    1571 | consumed samples:         6256 | consumed tokens:     12812288 | elapsed time per iteration (s): 16.50 | learning rate: 8.400E-05 | global batch size:    64 | lm loss: 6.943448E+00 | loss scale: 4096.0 | grad norm: 10099.733 | num zeros: 0.0 | params norm: 512.831 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.880 | TFLOPs: 40.97 |
 iteration      271/    1571 | consumed samples:         6320 | consumed tokens:     12943360 | elapsed time per iteration (s): 16.48 | learning rate: 8.489E-05 | global batch size:    64 | lm loss: 6.909293E+00 | loss scale: 4096.0 | grad norm: 8649.563 | num zeros: 0.0 | params norm: 512.852 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.885 | TFLOPs: 41.02 |
 iteration      272/    1571 | consumed samples:         6384 | consumed tokens:     13074432 | elapsed time per iteration (s): 16.47 | learning rate: 8.578E-05 | global batch size:    64 | lm loss: 6.918431E+00 | loss scale: 4096.0 | grad norm: 11558.714 | num zeros: 0.0 | params norm: 512.874 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.887 | TFLOPs: 41.04 |
 iteration      273/    1571 | consumed samples:         6448 | consumed tokens:     13205504 | elapsed time per iteration (s): 16.46 | learning rate: 8.667E-05 | global batch size:    64 | lm loss: 6.938234E+00 | loss scale: 4096.0 | grad norm: 5847.548 | num zeros: 0.0 | params norm: 512.897 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 3.889 | TFLOPs: 41.06 |
 iteration      274/    1571 | consumed samples:         6520 | consumed tokens:     13352960 | elapsed time per iteration (s): 17.94 | learning rate: 8.767E-05 | global batch size:    72 | lm loss: 6.971975E+00 | loss scale: 4096.0 | grad norm: 4888.514 | num zeros: 0.0 | params norm: 512.919 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.013 | TFLOPs: 42.37 |
 iteration      275/    1571 | consumed samples:         6592 | consumed tokens:     13500416 | elapsed time per iteration (s): 17.97 | learning rate: 8.867E-05 | global batch size:    72 | lm loss: 6.994005E+00 | loss scale: 4096.0 | grad norm: 12509.649 | num zeros: 0.0 | params norm: 512.941 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.008 | TFLOPs: 42.32 |
 iteration      276/    1571 | consumed samples:         6664 | consumed tokens:     13647872 | elapsed time per iteration (s): 17.95 | learning rate: 8.967E-05 | global batch size:    72 | lm loss: 6.927751E+00 | loss scale: 4096.0 | grad norm: 5138.993 | num zeros: 0.0 | params norm: 512.966 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.011 | TFLOPs: 42.35 |
 iteration      277/    1571 | consumed samples:         6736 | consumed tokens:     13795328 | elapsed time per iteration (s): 17.96 | learning rate: 9.067E-05 | global batch size:    72 | lm loss: 6.909401E+00 | loss scale: 4096.0 | grad norm: 11560.479 | num zeros: 0.0 | params norm: 512.990 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.010 | TFLOPs: 42.34 |
 iteration      278/    1571 | consumed samples:         6808 | consumed tokens:     13942784 | elapsed time per iteration (s): 17.95 | learning rate: 9.167E-05 | global batch size:    72 | lm loss: 6.966033E+00 | loss scale: 4096.0 | grad norm: 6374.877 | num zeros: 0.0 | params norm: 513.012 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.012 | TFLOPs: 42.36 |
 iteration      279/    1571 | consumed samples:         6880 | consumed tokens:     14090240 | elapsed time per iteration (s): 17.94 | learning rate: 9.267E-05 | global batch size:    72 | lm loss: 6.962584E+00 | loss scale: 4096.0 | grad norm: 9566.406 | num zeros: 0.0 | params norm: 513.035 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.014 | TFLOPs: 42.38 |
 iteration      280/    1571 | consumed samples:         6952 | consumed tokens:     14237696 | elapsed time per iteration (s): 17.94 | learning rate: 9.367E-05 | global batch size:    72 | lm loss: 6.925274E+00 | loss scale: 4096.0 | grad norm: 11061.659 | num zeros: 0.0 | params norm: 513.057 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.014 | TFLOPs: 42.38 |
 iteration      281/    1571 | consumed samples:         7024 | consumed tokens:     14385152 | elapsed time per iteration (s): 17.93 | learning rate: 9.467E-05 | global batch size:    72 | lm loss: 6.930485E+00 | loss scale: 4096.0 | grad norm: 13784.487 | num zeros: 0.0 | params norm: 513.079 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.015 | TFLOPs: 42.40 |
 iteration      282/    1571 | consumed samples:         7096 | consumed tokens:     14532608 | elapsed time per iteration (s): 17.94 | learning rate: 9.567E-05 | global batch size:    72 | lm loss: 6.950569E+00 | loss scale: 4096.0 | grad norm: 9514.018 | num zeros: 0.0 | params norm: 513.101 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.014 | TFLOPs: 42.38 |
 iteration      283/    1571 | consumed samples:         7168 | consumed tokens:     14680064 | elapsed time per iteration (s): 17.93 | learning rate: 9.667E-05 | global batch size:    72 | lm loss: 6.900592E+00 | loss scale: 4096.0 | grad norm: 18443.235 | num zeros: 0.0 | params norm: 513.124 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.015 | TFLOPs: 42.39 |
 iteration      284/    1571 | consumed samples:         7240 | consumed tokens:     14827520 | elapsed time per iteration (s): 17.93 | learning rate: 9.767E-05 | global batch size:    72 | lm loss: 6.954247E+00 | loss scale: 4096.0 | grad norm: 9957.333 | num zeros: 0.0 | params norm: 513.146 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.016 | TFLOPs: 42.40 |
 iteration      285/    1571 | consumed samples:         7320 | consumed tokens:     14991360 | elapsed time per iteration (s): 19.43 | learning rate: 9.878E-05 | global batch size:    80 | lm loss: 6.936738E+00 | loss scale: 4096.0 | grad norm: 13823.817 | num zeros: 0.0 | params norm: 513.167 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.116 | TFLOPs: 43.47 |
 iteration      286/    1571 | consumed samples:         7400 | consumed tokens:     15155200 | elapsed time per iteration (s): 19.45 | learning rate: 9.989E-05 | global batch size:    80 | lm loss: 6.933739E+00 | loss scale: 4096.0 | grad norm: 11218.423 | num zeros: 0.0 | params norm: 513.187 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.113 | TFLOPs: 43.43 |
 iteration      287/    1571 | consumed samples:         7480 | consumed tokens:     15319040 | elapsed time per iteration (s): 19.43 | learning rate: 1.000E-04 | global batch size:    80 | lm loss: 6.860271E+00 | loss scale: 4096.0 | grad norm: 6825.352 | num zeros: 0.0 | params norm: 513.206 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.118 | TFLOPs: 43.49 |
 iteration      288/    1571 | consumed samples:         7560 | consumed tokens:     15482880 | elapsed time per iteration (s): 19.44 | learning rate: 1.000E-04 | global batch size:    80 | lm loss: 6.851528E+00 | loss scale: 4096.0 | grad norm: 8020.249 | num zeros: 0.0 | params norm: 513.225 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.115 | TFLOPs: 43.45 |
 iteration      289/    1571 | consumed samples:         7640 | consumed tokens:     15646720 | elapsed time per iteration (s): 19.42 | learning rate: 1.000E-04 | global batch size:    80 | lm loss: 6.863835E+00 | loss scale: 4096.0 | grad norm: 3804.618 | num zeros: 0.0 | params norm: 513.243 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.119 | TFLOPs: 43.49 |
 iteration      290/    1571 | consumed samples:         7720 | consumed tokens:     15810560 | elapsed time per iteration (s): 19.40 | learning rate: 1.000E-04 | global batch size:    80 | lm loss: 6.870595E+00 | loss scale: 4096.0 | grad norm: 6679.037 | num zeros: 0.0 | params norm: 513.263 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.123 | TFLOPs: 43.54 |
 iteration      291/    1571 | consumed samples:         7800 | consumed tokens:     15974400 | elapsed time per iteration (s): 19.41 | learning rate: 1.000E-04 | global batch size:    80 | lm loss: 6.892918E+00 | loss scale: 4096.0 | grad norm: 10920.061 | num zeros: 0.0 | params norm: 513.281 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.122 | TFLOPs: 43.53 |
 iteration      292/    1571 | consumed samples:         7880 | consumed tokens:     16138240 | elapsed time per iteration (s): 19.42 | learning rate: 1.000E-04 | global batch size:    80 | lm loss: 6.824040E+00 | loss scale: 4096.0 | grad norm: 5218.185 | num zeros: 0.0 | params norm: 513.298 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.119 | TFLOPs: 43.49 |
 iteration      293/    1571 | consumed samples:         7960 | consumed tokens:     16302080 | elapsed time per iteration (s): 19.44 | learning rate: 1.000E-04 | global batch size:    80 | lm loss: 6.880014E+00 | loss scale: 4096.0 | grad norm: 14217.801 | num zeros: 0.0 | params norm: 513.316 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.116 | TFLOPs: 43.46 |
 iteration      294/    1571 | consumed samples:         8040 | consumed tokens:     16465920 | elapsed time per iteration (s): 19.44 | learning rate: 1.000E-04 | global batch size:    80 | lm loss: 6.832916E+00 | loss scale: 4096.0 | grad norm: 5898.764 | num zeros: 0.0 | params norm: 513.333 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.115 | TFLOPs: 43.45 |
 iteration      295/    1571 | consumed samples:         8128 | consumed tokens:     16646144 | elapsed time per iteration (s): 20.92 | learning rate: 1.000E-04 | global batch size:    88 | lm loss: 6.849489E+00 | loss scale: 4096.0 | grad norm: 4758.799 | num zeros: 0.0 | params norm: 513.351 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.207 | TFLOPs: 44.42 |
 iteration      296/    1571 | consumed samples:         8216 | consumed tokens:     16826368 | elapsed time per iteration (s): 20.93 | learning rate: 1.000E-04 | global batch size:    88 | lm loss: 6.884062E+00 | loss scale: 4096.0 | grad norm: 6805.498 | num zeros: 0.0 | params norm: 513.370 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.205 | TFLOPs: 44.40 |
 iteration      297/    1571 | consumed samples:         8304 | consumed tokens:     17006592 | elapsed time per iteration (s): 20.87 | learning rate: 1.000E-04 | global batch size:    88 | lm loss: 6.818507E+00 | loss scale: 4096.0 | grad norm: 7070.910 | num zeros: 0.0 | params norm: 513.388 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.216 | TFLOPs: 44.52 |
 iteration      298/    1571 | consumed samples:         8392 | consumed tokens:     17186816 | elapsed time per iteration (s): 20.89 | learning rate: 1.000E-04 | global batch size:    88 | lm loss: 6.860703E+00 | loss scale: 4096.0 | grad norm: 4893.698 | num zeros: 0.0 | params norm: 513.405 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.212 | TFLOPs: 44.48 |
 iteration      299/    1571 | consumed samples:         8480 | consumed tokens:     17367040 | elapsed time per iteration (s): 20.85 | learning rate: 1.000E-04 | global batch size:    88 | lm loss: 6.805177E+00 | loss scale: 4096.0 | grad norm: 5288.373 | num zeros: 0.0 | params norm: 513.421 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.220 | TFLOPs: 44.56 |
 iteration      300/    1571 | consumed samples:         8568 | consumed tokens:     17547264 | elapsed time per iteration (s): 20.86 | learning rate: 1.000E-04 | global batch size:    88 | lm loss: 6.778754E+00 | loss scale: 4096.0 | grad norm: 4803.789 | num zeros: 0.0 | params norm: 513.437 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.218 | TFLOPs: 44.54 |
 iteration      301/    1571 | consumed samples:         8656 | consumed tokens:     17727488 | elapsed time per iteration (s): 20.87 | learning rate: 1.000E-04 | global batch size:    88 | lm loss: 6.793795E+00 | loss scale: 4096.0 | grad norm: 4794.569 | num zeros: 0.0 | params norm: 513.455 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.217 | TFLOPs: 44.52 |
 iteration      302/    1571 | consumed samples:         8744 | consumed tokens:     17907712 | elapsed time per iteration (s): 20.90 | learning rate: 1.000E-04 | global batch size:    88 | lm loss: 6.799277E+00 | loss scale: 4096.0 | grad norm: 5191.690 | num zeros: 0.0 | params norm: 513.472 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.211 | TFLOPs: 44.47 |
 iteration      303/    1571 | consumed samples:         8832 | consumed tokens:     18087936 | elapsed time per iteration (s): 20.88 | learning rate: 1.000E-04 | global batch size:    88 | lm loss: 6.820765E+00 | loss scale: 4096.0 | grad norm: 6291.529 | num zeros: 0.0 | params norm: 513.490 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.214 | TFLOPs: 44.50 |
 iteration      304/    1571 | consumed samples:         8928 | consumed tokens:     18284544 | elapsed time per iteration (s): 22.38 | learning rate: 1.000E-04 | global batch size:    96 | lm loss: 6.837916E+00 | loss scale: 4096.0 | grad norm: 5802.217 | num zeros: 0.0 | params norm: 513.508 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.290 | TFLOPs: 45.30 |
 iteration      305/    1571 | consumed samples:         9024 | consumed tokens:     18481152 | elapsed time per iteration (s): 22.39 | learning rate: 1.000E-04 | global batch size:    96 | lm loss: 6.831736E+00 | loss scale: 4096.0 | grad norm: 4577.115 | num zeros: 0.0 | params norm: 513.525 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.288 | TFLOPs: 45.28 |
 iteration      306/    1571 | consumed samples:         9120 | consumed tokens:     18677760 | elapsed time per iteration (s): 22.38 | learning rate: 1.000E-04 | global batch size:    96 | lm loss: 6.778626E+00 | loss scale: 4096.0 | grad norm: 6153.015 | num zeros: 0.0 | params norm: 513.542 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.289 | TFLOPs: 45.29 |
 iteration      307/    1571 | consumed samples:         9216 | consumed tokens:     18874368 | elapsed time per iteration (s): 22.37 | learning rate: 1.000E-04 | global batch size:    96 | lm loss: 6.748675E+00 | loss scale: 4096.0 | grad norm: 4008.658 | num zeros: 0.0 | params norm: 513.560 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.291 | TFLOPs: 45.31 |
 iteration      308/    1571 | consumed samples:         9312 | consumed tokens:     19070976 | elapsed time per iteration (s): 22.39 | learning rate: 1.000E-04 | global batch size:    96 | lm loss: 6.794834E+00 | loss scale: 4096.0 | grad norm: 5405.975 | num zeros: 0.0 | params norm: 513.578 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.287 | TFLOPs: 45.27 |
 iteration      309/    1571 | consumed samples:         9408 | consumed tokens:     19267584 | elapsed time per iteration (s): 22.37 | learning rate: 1.000E-04 | global batch size:    96 | lm loss: 6.793037E+00 | loss scale: 4096.0 | grad norm: 4328.536 | num zeros: 0.0 | params norm: 513.594 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.292 | TFLOPs: 45.32 |
 iteration      310/    1571 | consumed samples:         9504 | consumed tokens:     19464192 | elapsed time per iteration (s): 22.35 | learning rate: 9.999E-05 | global batch size:    96 | lm loss: 6.757093E+00 | loss scale: 4096.0 | grad norm: 3293.596 | num zeros: 0.0 | params norm: 513.612 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.296 | TFLOPs: 45.36 |
 iteration      311/    1571 | consumed samples:         9600 | consumed tokens:     19660800 | elapsed time per iteration (s): 22.36 | learning rate: 9.999E-05 | global batch size:    96 | lm loss: 6.821596E+00 | loss scale: 4096.0 | grad norm: 4246.035 | num zeros: 0.0 | params norm: 513.630 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.294 | TFLOPs: 45.34 |
 iteration      312/    1571 | consumed samples:         9704 | consumed tokens:     19873792 | elapsed time per iteration (s): 23.82 | learning rate: 9.999E-05 | global batch size:   104 | lm loss: 6.792529E+00 | loss scale: 4096.0 | grad norm: 5392.524 | num zeros: 0.0 | params norm: 513.648 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.367 | TFLOPs: 46.11 |
 iteration      313/    1571 | consumed samples:         9808 | consumed tokens:     20086784 | elapsed time per iteration (s): 23.82 | learning rate: 9.999E-05 | global batch size:   104 | lm loss: 6.736403E+00 | loss scale: 4096.0 | grad norm: 4313.232 | num zeros: 0.0 | params norm: 513.666 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.366 | TFLOPs: 46.10 |
 iteration      314/    1571 | consumed samples:         9912 | consumed tokens:     20299776 | elapsed time per iteration (s): 23.80 | learning rate: 9.999E-05 | global batch size:   104 | lm loss: 6.766057E+00 | loss scale: 4096.0 | grad norm: 4229.556 | num zeros: 0.0 | params norm: 513.684 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.369 | TFLOPs: 46.13 |
 iteration      315/    1571 | consumed samples:        10016 | consumed tokens:     20512768 | elapsed time per iteration (s): 23.83 | learning rate: 9.999E-05 | global batch size:   104 | lm loss: 6.772723E+00 | loss scale: 4096.0 | grad norm: 3803.873 | num zeros: 0.0 | params norm: 513.703 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.364 | TFLOPs: 46.08 |
 iteration      316/    1571 | consumed samples:        10120 | consumed tokens:     20725760 | elapsed time per iteration (s): 23.88 | learning rate: 9.999E-05 | global batch size:   104 | lm loss: 6.706306E+00 | loss scale: 4096.0 | grad norm: 3299.126 | num zeros: 0.0 | params norm: 513.722 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.355 | TFLOPs: 45.98 |
 iteration      317/    1571 | consumed samples:        10224 | consumed tokens:     20938752 | elapsed time per iteration (s): 23.86 | learning rate: 9.999E-05 | global batch size:   104 | lm loss: 6.764233E+00 | loss scale: 4096.0 | grad norm: 3274.180 | num zeros: 0.0 | params norm: 513.741 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.358 | TFLOPs: 46.02 |
 iteration      318/    1571 | consumed samples:        10328 | consumed tokens:     21151744 | elapsed time per iteration (s): 23.85 | learning rate: 9.999E-05 | global batch size:   104 | lm loss: 6.735416E+00 | loss scale: 4096.0 | grad norm: 3588.811 | num zeros: 0.0 | params norm: 513.761 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.360 | TFLOPs: 46.04 |
 iteration      319/    1571 | consumed samples:        10432 | consumed tokens:     21364736 | elapsed time per iteration (s): 23.84 | learning rate: 9.999E-05 | global batch size:   104 | lm loss: 6.741795E+00 | loss scale: 4096.0 | grad norm: 4320.243 | num zeros: 0.0 | params norm: 513.781 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.362 | TFLOPs: 46.06 |
 iteration      320/    1571 | consumed samples:        10544 | consumed tokens:     21594112 | elapsed time per iteration (s): 25.29 | learning rate: 9.999E-05 | global batch size:   112 | lm loss: 6.733380E+00 | loss scale: 4096.0 | grad norm: 3290.169 | num zeros: 0.0 | params norm: 513.801 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.429 | TFLOPs: 46.76 |
 iteration      321/    1571 | consumed samples:        10656 | consumed tokens:     21823488 | elapsed time per iteration (s): 25.27 | learning rate: 9.999E-05 | global batch size:   112 | lm loss: 6.732215E+00 | loss scale: 4096.0 | grad norm: 3170.834 | num zeros: 0.0 | params norm: 513.822 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.433 | TFLOPs: 46.80 |
 iteration      322/    1571 | consumed samples:        10768 | consumed tokens:     22052864 | elapsed time per iteration (s): 25.29 | learning rate: 9.999E-05 | global batch size:   112 | lm loss: 6.719881E+00 | loss scale: 4096.0 | grad norm: 2178.317 | num zeros: 0.0 | params norm: 513.843 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.428 | TFLOPs: 46.75 |
 iteration      323/    1571 | consumed samples:        10880 | consumed tokens:     22282240 | elapsed time per iteration (s): 25.34 | learning rate: 9.999E-05 | global batch size:   112 | lm loss: 6.734753E+00 | loss scale: 4096.0 | grad norm: 2885.161 | num zeros: 0.0 | params norm: 513.865 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.420 | TFLOPs: 46.67 |
 iteration      324/    1571 | consumed samples:        10992 | consumed tokens:     22511616 | elapsed time per iteration (s): 25.35 | learning rate: 9.998E-05 | global batch size:   112 | lm loss: 6.690561E+00 | loss scale: 4096.0 | grad norm: 2524.551 | num zeros: 0.0 | params norm: 513.887 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.417 | TFLOPs: 46.64 |
 iteration      325/    1571 | consumed samples:        11104 | consumed tokens:     22740992 | elapsed time per iteration (s): 25.34 | learning rate: 9.998E-05 | global batch size:   112 | lm loss: 6.703938E+00 | loss scale: 4096.0 | grad norm: 5048.584 | num zeros: 0.0 | params norm: 513.910 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.419 | TFLOPs: 46.66 |
 iteration      326/    1571 | consumed samples:        11216 | consumed tokens:     22970368 | elapsed time per iteration (s): 25.31 | learning rate: 9.998E-05 | global batch size:   112 | lm loss: 6.670090E+00 | loss scale: 4096.0 | grad norm: 4729.490 | num zeros: 0.0 | params norm: 513.933 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.426 | TFLOPs: 46.73 |
 iteration      327/    1571 | consumed samples:        11336 | consumed tokens:     23216128 | elapsed time per iteration (s): 26.78 | learning rate: 9.998E-05 | global batch size:   120 | lm loss: 6.702357E+00 | loss scale: 4096.0 | grad norm: 3270.028 | num zeros: 0.0 | params norm: 513.956 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.481 | TFLOPs: 47.32 |
 iteration      328/    1571 | consumed samples:        11456 | consumed tokens:     23461888 | elapsed time per iteration (s): 26.75 | learning rate: 9.998E-05 | global batch size:   120 | lm loss: 6.704939E+00 | loss scale: 4096.0 | grad norm: 3790.476 | num zeros: 0.0 | params norm: 513.979 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.486 | TFLOPs: 47.37 |
 iteration      329/    1571 | consumed samples:        11576 | consumed tokens:     23707648 | elapsed time per iteration (s): 26.73 | learning rate: 9.998E-05 | global batch size:   120 | lm loss: 6.711527E+00 | loss scale: 4096.0 | grad norm: 2551.528 | num zeros: 0.0 | params norm: 514.001 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.489 | TFLOPs: 47.40 |
 iteration      330/    1571 | consumed samples:        11696 | consumed tokens:     23953408 | elapsed time per iteration (s): 26.75 | learning rate: 9.998E-05 | global batch size:   120 | lm loss: 6.677845E+00 | loss scale: 4096.0 | grad norm: 3336.707 | num zeros: 0.0 | params norm: 514.024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.486 | TFLOPs: 47.37 |
 iteration      331/    1571 | consumed samples:        11816 | consumed tokens:     24199168 | elapsed time per iteration (s): 26.74 | learning rate: 9.998E-05 | global batch size:   120 | lm loss: 6.678256E+00 | loss scale: 4096.0 | grad norm: 4479.115 | num zeros: 0.0 | params norm: 514.046 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.488 | TFLOPs: 47.39 |
 iteration      332/    1571 | consumed samples:        11936 | consumed tokens:     24444928 | elapsed time per iteration (s): 26.76 | learning rate: 9.997E-05 | global batch size:   120 | lm loss: 6.709330E+00 | loss scale: 4096.0 | grad norm: 4912.796 | num zeros: 0.0 | params norm: 514.069 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.484 | TFLOPs: 47.35 |
 iteration      333/    1571 | consumed samples:        12056 | consumed tokens:     24690688 | elapsed time per iteration (s): 26.83 | learning rate: 9.997E-05 | global batch size:   120 | lm loss: 6.663298E+00 | loss scale: 4096.0 | grad norm: 3364.848 | num zeros: 0.0 | params norm: 514.091 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.473 | TFLOPs: 47.23 |
 iteration      334/    1571 | consumed samples:        12184 | consumed tokens:     24952832 | elapsed time per iteration (s): 28.27 | learning rate: 9.997E-05 | global batch size:   128 | lm loss: 6.679104E+00 | loss scale: 4096.0 | grad norm: 5475.809 | num zeros: 0.0 | params norm: 514.112 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.528 | TFLOPs: 47.81 |
 iteration      335/    1571 | consumed samples:        12312 | consumed tokens:     25214976 | elapsed time per iteration (s): 28.31 | learning rate: 9.997E-05 | global batch size:   128 | lm loss: 6.643129E+00 | loss scale: 4096.0 | grad norm: 3276.526 | num zeros: 0.0 | params norm: 514.133 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.522 | TFLOPs: 47.74 |
 iteration      336/    1571 | consumed samples:        12440 | consumed tokens:     25477120 | elapsed time per iteration (s): 28.24 | learning rate: 9.997E-05 | global batch size:   128 | lm loss: 6.664989E+00 | loss scale: 4096.0 | grad norm: 2324.142 | num zeros: 0.0 | params norm: 514.156 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.533 | TFLOPs: 47.86 |
 iteration      337/    1571 | consumed samples:        12568 | consumed tokens:     25739264 | elapsed time per iteration (s): 28.27 | learning rate: 9.997E-05 | global batch size:   128 | lm loss: 6.693294E+00 | loss scale: 4096.0 | grad norm: 3378.879 | num zeros: 0.0 | params norm: 514.178 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.527 | TFLOPs: 47.81 |
 iteration      338/    1571 | consumed samples:        12696 | consumed tokens:     26001408 | elapsed time per iteration (s): 28.25 | learning rate: 9.997E-05 | global batch size:   128 | lm loss: 6.655607E+00 | loss scale: 4096.0 | grad norm: 4075.032 | num zeros: 0.0 | params norm: 514.199 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.532 | TFLOPs: 47.85 |
 iteration      339/    1571 | consumed samples:        12824 | consumed tokens:     26263552 | elapsed time per iteration (s): 28.26 | learning rate: 9.996E-05 | global batch size:   128 | lm loss: 6.645448E+00 | loss scale: 4096.0 | grad norm: 3236.100 | num zeros: 0.0 | params norm: 514.222 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.529 | TFLOPs: 47.83 |
 iteration      340/    1571 | consumed samples:        12960 | consumed tokens:     26542080 | elapsed time per iteration (s): 29.75 | learning rate: 9.996E-05 | global batch size:   136 | lm loss: 6.632469E+00 | loss scale: 4096.0 | grad norm: 4179.676 | num zeros: 0.0 | params norm: 514.243 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.571 | TFLOPs: 48.27 |
 iteration      341/    1571 | consumed samples:        13096 | consumed tokens:     26820608 | elapsed time per iteration (s): 29.73 | learning rate: 9.996E-05 | global batch size:   136 | lm loss: 6.653979E+00 | loss scale: 4096.0 | grad norm: 4787.806 | num zeros: 0.0 | params norm: 514.265 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.575 | TFLOPs: 48.30 |
 iteration      342/    1571 | consumed samples:        13232 | consumed tokens:     27099136 | elapsed time per iteration (s): 29.76 | learning rate: 9.996E-05 | global batch size:   136 | lm loss: 6.646189E+00 | loss scale: 4096.0 | grad norm: 2947.194 | num zeros: 0.0 | params norm: 514.286 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.570 | TFLOPs: 48.26 |
 iteration      343/    1571 | consumed samples:        13368 | consumed tokens:     27377664 | elapsed time per iteration (s): 29.72 | learning rate: 9.996E-05 | global batch size:   136 | lm loss: 6.608055E+00 | loss scale: 4096.0 | grad norm: 3915.081 | num zeros: 0.0 | params norm: 514.307 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.576 | TFLOPs: 48.31 |
 iteration      344/    1571 | consumed samples:        13504 | consumed tokens:     27656192 | elapsed time per iteration (s): 29.72 | learning rate: 9.995E-05 | global batch size:   136 | lm loss: 6.654382E+00 | loss scale: 4096.0 | grad norm: 2727.081 | num zeros: 0.0 | params norm: 514.328 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.575 | TFLOPs: 48.31 |
 iteration      345/    1571 | consumed samples:        13640 | consumed tokens:     27934720 | elapsed time per iteration (s): 29.76 | learning rate: 9.995E-05 | global batch size:   136 | lm loss: 6.623768E+00 | loss scale: 4096.0 | grad norm: 3865.426 | num zeros: 0.0 | params norm: 514.349 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.570 | TFLOPs: 48.26 |
 iteration      346/    1571 | consumed samples:        13784 | consumed tokens:     28229632 | elapsed time per iteration (s): 31.21 | learning rate: 9.995E-05 | global batch size:   144 | lm loss: 6.656624E+00 | loss scale: 4096.0 | grad norm: 3557.283 | num zeros: 0.0 | params norm: 514.370 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.614 | TFLOPs: 48.72 |
 iteration      347/    1571 | consumed samples:        13928 | consumed tokens:     28524544 | elapsed time per iteration (s): 31.24 | learning rate: 9.995E-05 | global batch size:   144 | lm loss: 6.617036E+00 | loss scale: 4096.0 | grad norm: 4077.927 | num zeros: 0.0 | params norm: 514.391 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.609 | TFLOPs: 48.67 |
 iteration      348/    1571 | consumed samples:        14072 | consumed tokens:     28819456 | elapsed time per iteration (s): 31.19 | learning rate: 9.994E-05 | global batch size:   144 | lm loss: 6.605959E+00 | loss scale: 4096.0 | grad norm: 2887.697 | num zeros: 0.0 | params norm: 514.412 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.617 | TFLOPs: 48.75 |
 iteration      349/    1571 | consumed samples:        14216 | consumed tokens:     29114368 | elapsed time per iteration (s): 31.22 | learning rate: 9.994E-05 | global batch size:   144 | lm loss: 6.570012E+00 | loss scale: 4096.0 | grad norm: 2678.251 | num zeros: 0.0 | params norm: 514.434 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.613 | TFLOPs: 48.70 |
 iteration      350/    1571 | consumed samples:        14360 | consumed tokens:     29409280 | elapsed time per iteration (s): 31.17 | learning rate: 9.994E-05 | global batch size:   144 | lm loss: 6.615400E+00 | loss scale: 4096.0 | grad norm: 2380.934 | num zeros: 0.0 | params norm: 514.456 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.620 | TFLOPs: 48.79 |
 iteration      351/    1571 | consumed samples:        14504 | consumed tokens:     29704192 | elapsed time per iteration (s): 31.18 | learning rate: 9.994E-05 | global batch size:   144 | lm loss: 6.628143E+00 | loss scale: 4096.0 | grad norm: 2641.806 | num zeros: 0.0 | params norm: 514.478 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.619 | TFLOPs: 48.77 |
 iteration      352/    1571 | consumed samples:        14656 | consumed tokens:     30015488 | elapsed time per iteration (s): 32.66 | learning rate: 9.993E-05 | global batch size:   152 | lm loss: 6.613728E+00 | loss scale: 4096.0 | grad norm: 2391.728 | num zeros: 0.0 | params norm: 514.501 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.654 | TFLOPs: 49.14 |
 iteration      353/    1571 | consumed samples:        14808 | consumed tokens:     30326784 | elapsed time per iteration (s): 32.69 | learning rate: 9.993E-05 | global batch size:   152 | lm loss: 6.617587E+00 | loss scale: 4096.0 | grad norm: 2520.938 | num zeros: 0.0 | params norm: 514.524 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.650 | TFLOPs: 49.10 |
 iteration      354/    1571 | consumed samples:        14960 | consumed tokens:     30638080 | elapsed time per iteration (s): 32.73 | learning rate: 9.993E-05 | global batch size:   152 | lm loss: 6.612074E+00 | loss scale: 4096.0 | grad norm: 2571.372 | num zeros: 0.0 | params norm: 514.546 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.645 | TFLOPs: 49.04 |
 iteration      355/    1571 | consumed samples:        15112 | consumed tokens:     30949376 | elapsed time per iteration (s): 32.71 | learning rate: 9.993E-05 | global batch size:   152 | lm loss: 6.594035E+00 | loss scale: 4096.0 | grad norm: 2659.118 | num zeros: 0.0 | params norm: 514.570 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.647 | TFLOPs: 49.06 |
 iteration      356/    1571 | consumed samples:        15264 | consumed tokens:     31260672 | elapsed time per iteration (s): 32.69 | learning rate: 9.992E-05 | global batch size:   152 | lm loss: 6.582968E+00 | loss scale: 4096.0 | grad norm: 4559.034 | num zeros: 0.0 | params norm: 514.594 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.650 | TFLOPs: 49.10 |
 iteration      357/    1571 | consumed samples:        15424 | consumed tokens:     31588352 | elapsed time per iteration (s): 34.14 | learning rate: 9.992E-05 | global batch size:   160 | lm loss: 6.609118E+00 | loss scale: 4096.0 | grad norm: 5680.613 | num zeros: 0.0 | params norm: 514.618 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.687 | TFLOPs: 49.49 |
 iteration      358/    1571 | consumed samples:        15584 | consumed tokens:     31916032 | elapsed time per iteration (s): 34.13 | learning rate: 9.992E-05 | global batch size:   160 | lm loss: 6.605474E+00 | loss scale: 4096.0 | grad norm: 2911.350 | num zeros: 0.0 | params norm: 514.643 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.688 | TFLOPs: 49.50 |
 iteration      359/    1571 | consumed samples:        15744 | consumed tokens:     32243712 | elapsed time per iteration (s): 34.21 | learning rate: 9.991E-05 | global batch size:   160 | lm loss: 6.633218E+00 | loss scale: 4096.0 | grad norm: 4193.325 | num zeros: 0.0 | params norm: 514.665 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.678 | TFLOPs: 49.39 |
 iteration      360/    1571 | consumed samples:        15904 | consumed tokens:     32571392 | elapsed time per iteration (s): 34.17 | learning rate: 9.991E-05 | global batch size:   160 | lm loss: 6.605846E+00 | loss scale: 4096.0 | grad norm: 5090.054 | num zeros: 0.0 | params norm: 514.688 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.682 | TFLOPs: 49.44 |
 iteration      361/    1571 | consumed samples:        16064 | consumed tokens:     32899072 | elapsed time per iteration (s): 34.23 | learning rate: 9.991E-05 | global batch size:   160 | lm loss: 6.563662E+00 | loss scale: 4096.0 | grad norm: 5237.386 | num zeros: 0.0 | params norm: 514.709 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.674 | TFLOPs: 49.36 |
 iteration      362/    1571 | consumed samples:        16232 | consumed tokens:     33243136 | elapsed time per iteration (s): 35.65 | learning rate: 9.990E-05 | global batch size:   168 | lm loss: 6.576489E+00 | loss scale: 4096.0 | grad norm: 3048.640 | num zeros: 0.0 | params norm: 514.732 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.712 | TFLOPs: 49.75 |
 iteration      363/    1571 | consumed samples:        16400 | consumed tokens:     33587200 | elapsed time per iteration (s): 35.68 | learning rate: 9.990E-05 | global batch size:   168 | lm loss: 6.574075E+00 | loss scale: 4096.0 | grad norm: 3166.765 | num zeros: 0.0 | params norm: 514.753 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.708 | TFLOPs: 49.71 |
 iteration      364/    1571 | consumed samples:        16568 | consumed tokens:     33931264 | elapsed time per iteration (s): 35.63 | learning rate: 9.990E-05 | global batch size:   168 | lm loss: 6.589695E+00 | loss scale: 4096.0 | grad norm: 3732.320 | num zeros: 0.0 | params norm: 514.777 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.716 | TFLOPs: 49.79 |
 iteration      365/    1571 | consumed samples:        16736 | consumed tokens:     34275328 | elapsed time per iteration (s): 35.67 | learning rate: 9.989E-05 | global batch size:   168 | lm loss: 6.590730E+00 | loss scale: 4096.0 | grad norm: 4685.965 | num zeros: 0.0 | params norm: 514.797 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.710 | TFLOPs: 49.73 |
 iteration      366/    1571 | consumed samples:        16904 | consumed tokens:     34619392 | elapsed time per iteration (s): 35.60 | learning rate: 9.989E-05 | global batch size:   168 | lm loss: 6.598441E+00 | loss scale: 4096.0 | grad norm: 3829.751 | num zeros: 0.0 | params norm: 514.818 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.719 | TFLOPs: 49.83 |
 iteration      367/    1571 | consumed samples:        17080 | consumed tokens:     34979840 | elapsed time per iteration (s): 37.13 | learning rate: 9.988E-05 | global batch size:   176 | lm loss: 6.583924E+00 | loss scale: 4096.0 | grad norm: 4116.087 | num zeros: 0.0 | params norm: 514.840 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.740 | TFLOPs: 50.05 |
 iteration      368/    1571 | consumed samples:        17256 | consumed tokens:     35340288 | elapsed time per iteration (s): 37.10 | learning rate: 9.988E-05 | global batch size:   176 | lm loss: 6.550869E+00 | loss scale: 4096.0 | grad norm: 3394.833 | num zeros: 0.0 | params norm: 514.864 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.744 | TFLOPs: 50.10 |
 iteration      369/    1571 | consumed samples:        17432 | consumed tokens:     35700736 | elapsed time per iteration (s): 37.06 | learning rate: 9.988E-05 | global batch size:   176 | lm loss: 6.534196E+00 | loss scale: 4096.0 | grad norm: 3307.576 | num zeros: 0.0 | params norm: 514.885 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.749 | TFLOPs: 50.14 |
 iteration      370/    1571 | consumed samples:        17608 | consumed tokens:     36061184 | elapsed time per iteration (s): 37.10 | learning rate: 9.987E-05 | global batch size:   176 | lm loss: 6.536531E+00 | loss scale: 4096.0 | grad norm: 2866.884 | num zeros: 0.0 | params norm: 514.907 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.744 | TFLOPs: 50.10 |
 iteration      371/    1571 | consumed samples:        17792 | consumed tokens:     36438016 | elapsed time per iteration (s): 38.54 | learning rate: 9.987E-05 | global batch size:   184 | lm loss: 6.564713E+00 | loss scale: 4096.0 | grad norm: 2251.747 | num zeros: 0.0 | params norm: 514.931 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.774 | TFLOPs: 50.41 |
 iteration      372/    1571 | consumed samples:        17976 | consumed tokens:     36814848 | elapsed time per iteration (s): 38.61 | learning rate: 9.986E-05 | global batch size:   184 | lm loss: 6.506044E+00 | loss scale: 4096.0 | grad norm: 2634.053 | num zeros: 0.0 | params norm: 514.954 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.766 | TFLOPs: 50.33 |
 iteration      373/    1571 | consumed samples:        18160 | consumed tokens:     37191680 | elapsed time per iteration (s): 38.58 | learning rate: 9.986E-05 | global batch size:   184 | lm loss: 6.509387E+00 | loss scale: 4096.0 | grad norm: 3040.052 | num zeros: 0.0 | params norm: 514.978 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.769 | TFLOPs: 50.36 |
 iteration      374/    1571 | consumed samples:        18344 | consumed tokens:     37568512 | elapsed time per iteration (s): 38.64 | learning rate: 9.985E-05 | global batch size:   184 | lm loss: 6.517899E+00 | loss scale: 4096.0 | grad norm: 3842.192 | num zeros: 0.0 | params norm: 515.000 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.762 | TFLOPs: 50.28 |
 iteration      375/    1571 | consumed samples:        18528 | consumed tokens:     37945344 | elapsed time per iteration (s): 38.54 | learning rate: 9.985E-05 | global batch size:   184 | lm loss: 6.515065E+00 | loss scale: 4096.0 | grad norm: 3718.291 | num zeros: 0.0 | params norm: 515.025 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.774 | TFLOPs: 50.41 |
 iteration      376/    1571 | consumed samples:        18720 | consumed tokens:     38338560 | elapsed time per iteration (s): 40.04 | learning rate: 9.984E-05 | global batch size:   192 | lm loss: 6.540546E+00 | loss scale: 4096.0 | grad norm: 2557.670 | num zeros: 0.0 | params norm: 515.047 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.795 | TFLOPs: 50.63 |
 iteration      377/    1571 | consumed samples:        18912 | consumed tokens:     38731776 | elapsed time per iteration (s): 40.03 | learning rate: 9.984E-05 | global batch size:   192 | lm loss: 6.501945E+00 | loss scale: 4096.0 | grad norm: 2718.826 | num zeros: 0.0 | params norm: 515.070 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.796 | TFLOPs: 50.64 |
 iteration      378/    1571 | consumed samples:        19104 | consumed tokens:     39124992 | elapsed time per iteration (s): 40.08 | learning rate: 9.983E-05 | global batch size:   192 | lm loss: 6.538005E+00 | loss scale: 4096.0 | grad norm: 2540.565 | num zeros: 0.0 | params norm: 515.093 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.791 | TFLOPs: 50.59 |
 iteration      379/    1571 | consumed samples:        19296 | consumed tokens:     39518208 | elapsed time per iteration (s): 40.07 | learning rate: 9.982E-05 | global batch size:   192 | lm loss: 6.498638E+00 | loss scale: 4096.0 | grad norm: 2367.520 | num zeros: 0.0 | params norm: 515.115 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.791 | TFLOPs: 50.59 |
 iteration      380/    1571 | consumed samples:        19496 | consumed tokens:     39927808 | elapsed time per iteration (s): 41.52 | learning rate: 9.982E-05 | global batch size:   200 | lm loss: 6.525748E+00 | loss scale: 4096.0 | grad norm: 3089.783 | num zeros: 0.0 | params norm: 515.139 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.817 | TFLOPs: 50.86 |
 iteration      381/    1571 | consumed samples:        19696 | consumed tokens:     40337408 | elapsed time per iteration (s): 41.53 | learning rate: 9.981E-05 | global batch size:   200 | lm loss: 6.535323E+00 | loss scale: 4096.0 | grad norm: 3971.708 | num zeros: 0.0 | params norm: 515.158 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.816 | TFLOPs: 50.85 |
 iteration      382/    1571 | consumed samples:        19896 | consumed tokens:     40747008 | elapsed time per iteration (s): 41.54 | learning rate: 9.981E-05 | global batch size:   200 | lm loss: 6.496111E+00 | loss scale: 4096.0 | grad norm: 4845.817 | num zeros: 0.0 | params norm: 515.179 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.814 | TFLOPs: 50.83 |
 iteration      383/    1571 | consumed samples:        20096 | consumed tokens:     41156608 | elapsed time per iteration (s): 41.56 | learning rate: 9.980E-05 | global batch size:   200 | lm loss: 6.527623E+00 | loss scale: 4096.0 | grad norm: 5029.502 | num zeros: 0.0 | params norm: 515.201 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.812 | TFLOPs: 50.81 |
 iteration      384/    1571 | consumed samples:        20304 | consumed tokens:     41582592 | elapsed time per iteration (s): 43.03 | learning rate: 9.979E-05 | global batch size:   208 | lm loss: 6.502966E+00 | loss scale: 4096.0 | grad norm: 2255.202 | num zeros: 0.0 | params norm: 515.222 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.834 | TFLOPs: 51.04 |
 iteration      385/    1571 | consumed samples:        20512 | consumed tokens:     42008576 | elapsed time per iteration (s): 43.01 | learning rate: 9.979E-05 | global batch size:   208 | lm loss: 6.478561E+00 | loss scale: 4096.0 | grad norm: 3500.487 | num zeros: 0.0 | params norm: 515.242 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.836 | TFLOPs: 51.07 |
 iteration      386/    1571 | consumed samples:        20720 | consumed tokens:     42434560 | elapsed time per iteration (s): 42.99 | learning rate: 9.978E-05 | global batch size:   208 | lm loss: 6.465479E+00 | loss scale: 4096.0 | grad norm: 2720.531 | num zeros: 0.0 | params norm: 515.263 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.838 | TFLOPs: 51.08 |
 iteration      387/    1571 | consumed samples:        20928 | consumed tokens:     42860544 | elapsed time per iteration (s): 43.00 | learning rate: 9.977E-05 | global batch size:   208 | lm loss: 6.487240E+00 | loss scale: 4096.0 | grad norm: 3179.872 | num zeros: 0.0 | params norm: 515.285 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.837 | TFLOPs: 51.08 |
 iteration      388/    1571 | consumed samples:        21144 | consumed tokens:     43302912 | elapsed time per iteration (s): 44.53 | learning rate: 9.977E-05 | global batch size:   216 | lm loss: 6.471494E+00 | loss scale: 4096.0 | grad norm: 4835.885 | num zeros: 0.0 | params norm: 515.305 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.850 | TFLOPs: 51.22 |
 iteration      389/    1571 | consumed samples:        21360 | consumed tokens:     43745280 | elapsed time per iteration (s): 44.46 | learning rate: 9.976E-05 | global batch size:   216 | lm loss: 6.514547E+00 | loss scale: 4096.0 | grad norm: 5782.590 | num zeros: 0.0 | params norm: 515.327 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.858 | TFLOPs: 51.30 |
 iteration      390/    1571 | consumed samples:        21576 | consumed tokens:     44187648 | elapsed time per iteration (s): 44.47 | learning rate: 9.975E-05 | global batch size:   216 | lm loss: 6.493423E+00 | loss scale: 4096.0 | grad norm: 4537.931 | num zeros: 0.0 | params norm: 515.346 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.857 | TFLOPs: 51.28 |
 iteration      391/    1571 | consumed samples:        21792 | consumed tokens:     44630016 | elapsed time per iteration (s): 44.51 | learning rate: 9.974E-05 | global batch size:   216 | lm loss: 6.523863E+00 | loss scale: 4096.0 | grad norm: 3713.129 | num zeros: 0.0 | params norm: 515.365 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.853 | TFLOPs: 51.24 |
 iteration      392/    1571 | consumed samples:        22016 | consumed tokens:     45088768 | elapsed time per iteration (s): 45.98 | learning rate: 9.974E-05 | global batch size:   224 | lm loss: 6.455388E+00 | loss scale: 4096.0 | grad norm: 3253.977 | num zeros: 0.0 | params norm: 515.387 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.872 | TFLOPs: 51.44 |
 iteration      393/    1571 | consumed samples:        22240 | consumed tokens:     45547520 | elapsed time per iteration (s): 46.01 | learning rate: 9.973E-05 | global batch size:   224 | lm loss: 6.452305E+00 | loss scale: 4096.0 | grad norm: 3381.734 | num zeros: 0.0 | params norm: 515.408 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.869 | TFLOPs: 51.41 |
 iteration      394/    1571 | consumed samples:        22464 | consumed tokens:     46006272 | elapsed time per iteration (s): 45.94 | learning rate: 9.972E-05 | global batch size:   224 | lm loss: 6.466692E+00 | loss scale: 4096.0 | grad norm: 2507.500 | num zeros: 0.0 | params norm: 515.429 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.876 | TFLOPs: 51.49 |
 iteration      395/    1571 | consumed samples:        22696 | consumed tokens:     46481408 | elapsed time per iteration (s): 47.46 | learning rate: 9.971E-05 | global batch size:   232 | lm loss: 6.465260E+00 | loss scale: 4096.0 | grad norm: 2432.268 | num zeros: 0.0 | params norm: 515.450 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.888 | TFLOPs: 51.61 |
 iteration      396/    1571 | consumed samples:        22928 | consumed tokens:     46956544 | elapsed time per iteration (s): 47.47 | learning rate: 9.970E-05 | global batch size:   232 | lm loss: 6.453250E+00 | loss scale: 4096.0 | grad norm: 3285.904 | num zeros: 0.0 | params norm: 515.473 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.888 | TFLOPs: 51.61 |
 iteration      397/    1571 | consumed samples:        23160 | consumed tokens:     47431680 | elapsed time per iteration (s): 47.41 | learning rate: 9.969E-05 | global batch size:   232 | lm loss: 6.443675E+00 | loss scale: 4096.0 | grad norm: 2662.680 | num zeros: 0.0 | params norm: 515.495 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.894 | TFLOPs: 51.67 |
 iteration      398/    1571 | consumed samples:        23392 | consumed tokens:     47906816 | elapsed time per iteration (s): 47.49 | learning rate: 9.968E-05 | global batch size:   232 | lm loss: 6.438517E+00 | loss scale: 4096.0 | grad norm: 2799.495 | num zeros: 0.0 | params norm: 515.516 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.885 | TFLOPs: 51.58 |
 iteration      399/    1571 | consumed samples:        23632 | consumed tokens:     48398336 | elapsed time per iteration (s): 48.96 | learning rate: 9.967E-05 | global batch size:   240 | lm loss: 6.448061E+00 | loss scale: 4096.0 | grad norm: 3944.249 | num zeros: 0.0 | params norm: 515.540 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.902 | TFLOPs: 51.76 |
 iteration      400/    1571 | consumed samples:        23872 | consumed tokens:     48889856 | elapsed time per iteration (s): 48.96 | learning rate: 9.966E-05 | global batch size:   240 | lm loss: 6.448098E+00 | loss scale: 4096.0 | grad norm: 6399.091 | num zeros: 0.0 | params norm: 515.560 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.902 | TFLOPs: 51.77 |
 iteration      401/    1571 | consumed samples:        24112 | consumed tokens:     49381376 | elapsed time per iteration (s): 48.87 | learning rate: 9.965E-05 | global batch size:   240 | lm loss: 6.407106E+00 | loss scale: 4096.0 | grad norm: 4524.881 | num zeros: 0.0 | params norm: 515.578 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.911 | TFLOPs: 51.86 |
 iteration      402/    1571 | consumed samples:        24360 | consumed tokens:     49889280 | elapsed time per iteration (s): 50.40 | learning rate: 9.964E-05 | global batch size:   248 | lm loss: 6.448800E+00 | loss scale: 4096.0 | grad norm: 4770.002 | num zeros: 0.0 | params norm: 515.599 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.921 | TFLOPs: 51.96 |
 iteration      403/    1571 | consumed samples:        24608 | consumed tokens:     50397184 | elapsed time per iteration (s): 50.42 | learning rate: 9.963E-05 | global batch size:   248 | lm loss: 6.433904E+00 | loss scale: 4096.0 | grad norm: 3998.112 | num zeros: 0.0 | params norm: 515.616 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.919 | TFLOPs: 51.94 |
 iteration      404/    1571 | consumed samples:        24856 | consumed tokens:     50905088 | elapsed time per iteration (s): 50.40 | learning rate: 9.962E-05 | global batch size:   248 | lm loss: 6.437738E+00 | loss scale: 4096.0 | grad norm: 3253.900 | num zeros: 0.0 | params norm: 515.635 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.920 | TFLOPs: 51.96 |
 iteration      405/    1571 | consumed samples:        25112 | consumed tokens:     51429376 | elapsed time per iteration (s): 51.86 | learning rate: 9.961E-05 | global batch size:   256 | lm loss: 6.447320E+00 | loss scale: 4096.0 | grad norm: 4055.069 | num zeros: 0.0 | params norm: 515.652 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.936 | TFLOPs: 52.12 |
 iteration      406/    1571 | consumed samples:        25368 | consumed tokens:     51953664 | elapsed time per iteration (s): 51.87 | learning rate: 9.960E-05 | global batch size:   256 | lm loss: 6.404652E+00 | loss scale: 4096.0 | grad norm: 3116.252 | num zeros: 0.0 | params norm: 515.670 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.935 | TFLOPs: 52.11 |
 iteration      407/    1571 | consumed samples:        25624 | consumed tokens:     52477952 | elapsed time per iteration (s): 51.96 | learning rate: 9.959E-05 | global batch size:   256 | lm loss: 6.405195E+00 | loss scale: 4096.0 | grad norm: 3635.977 | num zeros: 0.0 | params norm: 515.689 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.927 | TFLOPs: 52.03 |
 iteration      408/    1571 | consumed samples:        25888 | consumed tokens:     53018624 | elapsed time per iteration (s): 53.35 | learning rate: 9.958E-05 | global batch size:   264 | lm loss: 6.426109E+00 | loss scale: 4096.0 | grad norm: 4590.327 | num zeros: 0.0 | params norm: 515.707 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.949 | TFLOPs: 52.25 |
 iteration      409/    1571 | consumed samples:        26152 | consumed tokens:     53559296 | elapsed time per iteration (s): 53.35 | learning rate: 9.956E-05 | global batch size:   264 | lm loss: 6.406630E+00 | loss scale: 4096.0 | grad norm: 3180.310 | num zeros: 0.0 | params norm: 515.727 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.949 | TFLOPs: 52.25 |
 iteration      410/    1571 | consumed samples:        26416 | consumed tokens:     54099968 | elapsed time per iteration (s): 53.32 | learning rate: 9.955E-05 | global batch size:   264 | lm loss: 6.392486E+00 | loss scale: 4096.0 | grad norm: 2591.911 | num zeros: 0.0 | params norm: 515.747 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.951 | TFLOPs: 52.28 |
 iteration      411/    1571 | consumed samples:        26688 | consumed tokens:     54657024 | elapsed time per iteration (s): 54.76 | learning rate: 9.954E-05 | global batch size:   272 | lm loss: 6.382722E+00 | loss scale: 4096.0 | grad norm: 3947.760 | num zeros: 0.0 | params norm: 515.767 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.967 | TFLOPs: 52.45 |
 iteration      412/    1571 | consumed samples:        26960 | consumed tokens:     55214080 | elapsed time per iteration (s): 54.81 | learning rate: 9.953E-05 | global batch size:   272 | lm loss: 6.370817E+00 | loss scale: 4096.0 | grad norm: 2860.074 | num zeros: 0.0 | params norm: 515.786 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.963 | TFLOPs: 52.40 |
 iteration      413/    1571 | consumed samples:        27232 | consumed tokens:     55771136 | elapsed time per iteration (s): 54.80 | learning rate: 9.951E-05 | global batch size:   272 | lm loss: 6.360779E+00 | loss scale: 4096.0 | grad norm: 2257.426 | num zeros: 0.0 | params norm: 515.807 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.963 | TFLOPs: 52.41 |
 iteration      414/    1571 | consumed samples:        27512 | consumed tokens:     56344576 | elapsed time per iteration (s): 56.35 | learning rate: 9.950E-05 | global batch size:   280 | lm loss: 6.352179E+00 | loss scale: 4096.0 | grad norm: 3330.054 | num zeros: 0.0 | params norm: 515.826 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.969 | TFLOPs: 52.47 |
 iteration      415/    1571 | consumed samples:        27792 | consumed tokens:     56918016 | elapsed time per iteration (s): 56.32 | learning rate: 9.948E-05 | global batch size:   280 | lm loss: 6.399785E+00 | loss scale: 4096.0 | grad norm: 4025.248 | num zeros: 0.0 | params norm: 515.848 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.972 | TFLOPs: 52.50 |
 iteration      416/    1571 | consumed samples:        28072 | consumed tokens:     57491456 | elapsed time per iteration (s): 56.34 | learning rate: 9.947E-05 | global batch size:   280 | lm loss: 6.375957E+00 | loss scale: 4096.0 | grad norm: 3290.209 | num zeros: 0.0 | params norm: 515.867 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.970 | TFLOPs: 52.48 |
 iteration      417/    1571 | consumed samples:        28360 | consumed tokens:     58081280 | elapsed time per iteration (s): 57.74 | learning rate: 9.946E-05 | global batch size:   288 | lm loss: 6.376792E+00 | loss scale: 4096.0 | grad norm: 3064.106 | num zeros: 0.0 | params norm: 515.887 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.988 | TFLOPs: 52.67 |
 iteration      418/    1571 | consumed samples:        28648 | consumed tokens:     58671104 | elapsed time per iteration (s): 57.79 | learning rate: 9.944E-05 | global batch size:   288 | lm loss: 6.364439E+00 | loss scale: 4096.0 | grad norm: 2219.424 | num zeros: 0.0 | params norm: 515.907 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.984 | TFLOPs: 52.62 |
 iteration      419/    1571 | consumed samples:        28936 | consumed tokens:     59260928 | elapsed time per iteration (s): 57.75 | learning rate: 9.943E-05 | global batch size:   288 | lm loss: 6.390691E+00 | loss scale: 4096.0 | grad norm: 3293.376 | num zeros: 0.0 | params norm: 515.927 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.987 | TFLOPs: 52.66 |
 iteration      420/    1571 | consumed samples:        29232 | consumed tokens:     59867136 | elapsed time per iteration (s): 59.30 | learning rate: 9.941E-05 | global batch size:   296 | lm loss: 6.380611E+00 | loss scale: 4096.0 | grad norm: 3076.215 | num zeros: 0.0 | params norm: 515.947 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.991 | TFLOPs: 52.71 |
 iteration      421/    1571 | consumed samples:        29528 | consumed tokens:     60473344 | elapsed time per iteration (s): 59.22 | learning rate: 9.939E-05 | global batch size:   296 | lm loss: 6.348042E+00 | loss scale: 4096.0 | grad norm: 2660.104 | num zeros: 0.0 | params norm: 515.967 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 4.998 | TFLOPs: 52.77 |
 iteration      422/    1571 | consumed samples:        29824 | consumed tokens:     61079552 | elapsed time per iteration (s): 59.20 | learning rate: 9.938E-05 | global batch size:   296 | lm loss: 6.354022E+00 | loss scale: 4096.0 | grad norm: 3347.379 | num zeros: 0.0 | params norm: 515.986 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.000 | TFLOPs: 52.80 |
 iteration      423/    1571 | consumed samples:        30128 | consumed tokens:     61702144 | elapsed time per iteration (s): 60.71 | learning rate: 9.936E-05 | global batch size:   304 | lm loss: 6.357587E+00 | loss scale: 4096.0 | grad norm: 3573.988 | num zeros: 0.0 | params norm: 516.007 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.007 | TFLOPs: 52.87 |
 iteration      424/    1571 | consumed samples:        30432 | consumed tokens:     62324736 | elapsed time per iteration (s): 60.73 | learning rate: 9.934E-05 | global batch size:   304 | lm loss: 6.371494E+00 | loss scale: 4096.0 | grad norm: 3291.468 | num zeros: 0.0 | params norm: 516.028 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.005 | TFLOPs: 52.85 |
 iteration      425/    1571 | consumed samples:        30744 | consumed tokens:     62963712 | elapsed time per iteration (s): 62.24 | learning rate: 9.933E-05 | global batch size:   312 | lm loss: 6.364567E+00 | loss scale: 4096.0 | grad norm: 3839.902 | num zeros: 0.0 | params norm: 516.046 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.013 | TFLOPs: 52.93 |
 iteration      426/    1571 | consumed samples:        31056 | consumed tokens:     63602688 | elapsed time per iteration (s): 62.18 | learning rate: 9.931E-05 | global batch size:   312 | lm loss: 6.348152E+00 | loss scale: 4096.0 | grad norm: 5495.644 | num zeros: 0.0 | params norm: 516.067 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.018 | TFLOPs: 52.98 |
 iteration      427/    1571 | consumed samples:        31368 | consumed tokens:     64241664 | elapsed time per iteration (s): 62.23 | learning rate: 9.929E-05 | global batch size:   312 | lm loss: 6.369714E+00 | loss scale: 4096.0 | grad norm: 4358.560 | num zeros: 0.0 | params norm: 516.085 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.014 | TFLOPs: 52.94 |
 iteration      428/    1571 | consumed samples:        31688 | consumed tokens:     64897024 | elapsed time per iteration (s): 63.70 | learning rate: 9.927E-05 | global batch size:   320 | lm loss: 6.336036E+00 | loss scale: 4096.0 | grad norm: 2683.495 | num zeros: 0.0 | params norm: 516.105 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.024 | TFLOPs: 53.04 |
 iteration      429/    1571 | consumed samples:        32008 | consumed tokens:     65552384 | elapsed time per iteration (s): 63.70 | learning rate: 9.925E-05 | global batch size:   320 | lm loss: 6.351357E+00 | loss scale: 4096.0 | grad norm: 3331.343 | num zeros: 0.0 | params norm: 516.125 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.024 | TFLOPs: 53.04 |
 iteration      430/    1571 | consumed samples:        32336 | consumed tokens:     66224128 | elapsed time per iteration (s): 65.15 | learning rate: 9.923E-05 | global batch size:   328 | lm loss: 6.319960E+00 | loss scale: 4096.0 | grad norm: 2370.058 | num zeros: 0.0 | params norm: 516.145 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.034 | TFLOPs: 53.16 |
 iteration      431/    1571 | consumed samples:        32664 | consumed tokens:     66895872 | elapsed time per iteration (s): 65.17 | learning rate: 9.921E-05 | global batch size:   328 | lm loss: 6.318825E+00 | loss scale: 4096.0 | grad norm: 2381.916 | num zeros: 0.0 | params norm: 516.166 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.033 | TFLOPs: 53.15 |
 iteration      432/    1571 | consumed samples:        32992 | consumed tokens:     67567616 | elapsed time per iteration (s): 65.11 | learning rate: 9.919E-05 | global batch size:   328 | lm loss: 6.322414E+00 | loss scale: 4096.0 | grad norm: 2511.117 | num zeros: 0.0 | params norm: 516.186 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.038 | TFLOPs: 53.19 |
 iteration      433/    1571 | consumed samples:        33328 | consumed tokens:     68255744 | elapsed time per iteration (s): 66.72 | learning rate: 9.917E-05 | global batch size:   336 | lm loss: 6.326458E+00 | loss scale: 4096.0 | grad norm: 2519.831 | num zeros: 0.0 | params norm: 516.208 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.036 | TFLOPs: 53.18 |
 iteration      434/    1571 | consumed samples:        33664 | consumed tokens:     68943872 | elapsed time per iteration (s): 66.62 | learning rate: 9.915E-05 | global batch size:   336 | lm loss: 6.298413E+00 | loss scale: 4096.0 | grad norm: 3296.374 | num zeros: 0.0 | params norm: 516.228 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.044 | TFLOPs: 53.26 |
 iteration      435/    1571 | consumed samples:        34008 | consumed tokens:     69648384 | elapsed time per iteration (s): 68.13 | learning rate: 9.912E-05 | global batch size:   344 | lm loss: 6.317402E+00 | loss scale: 4096.0 | grad norm: 4276.332 | num zeros: 0.0 | params norm: 516.250 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.049 | TFLOPs: 53.32 |
 iteration      436/    1571 | consumed samples:        34352 | consumed tokens:     70352896 | elapsed time per iteration (s): 68.07 | learning rate: 9.910E-05 | global batch size:   344 | lm loss: 6.299200E+00 | loss scale: 4096.0 | grad norm: 4184.509 | num zeros: 0.0 | params norm: 516.270 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.054 | TFLOPs: 53.36 |
 iteration      437/    1571 | consumed samples:        34696 | consumed tokens:     71057408 | elapsed time per iteration (s): 68.11 | learning rate: 9.908E-05 | global batch size:   344 | lm loss: 6.317298E+00 | loss scale: 4096.0 | grad norm: 5670.980 | num zeros: 0.0 | params norm: 516.290 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.050 | TFLOPs: 53.33 |
 iteration      438/    1571 | consumed samples:        35048 | consumed tokens:     71778304 | elapsed time per iteration (s): 69.61 | learning rate: 9.905E-05 | global batch size:   352 | lm loss: 6.272973E+00 | loss scale: 4096.0 | grad norm: 4160.633 | num zeros: 0.0 | params norm: 516.310 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.057 | TFLOPs: 53.40 |
 iteration      439/    1571 | consumed samples:        35400 | consumed tokens:     72499200 | elapsed time per iteration (s): 69.56 | learning rate: 9.903E-05 | global batch size:   352 | lm loss: 6.324347E+00 | loss scale: 4096.0 | grad norm: 6645.177 | num zeros: 0.0 | params norm: 516.328 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.060 | TFLOPs: 53.43 |
 iteration      440/    1571 | consumed samples:        35760 | consumed tokens:     73236480 | elapsed time per iteration (s): 71.03 | learning rate: 9.901E-05 | global batch size:   360 | lm loss: 6.311580E+00 | loss scale: 4096.0 | grad norm: 4713.178 | num zeros: 0.0 | params norm: 516.348 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration      441/    1571 | consumed samples:        36120 | consumed tokens:     73973760 | elapsed time per iteration (s): 71.04 | learning rate: 9.898E-05 | global batch size:   360 | lm loss: 6.286783E+00 | loss scale: 4096.0 | grad norm: 3533.624 | num zeros: 0.0 | params norm: 516.367 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.51 |
 iteration      442/    1571 | consumed samples:        36488 | consumed tokens:     74727424 | elapsed time per iteration (s): 72.52 | learning rate: 9.895E-05 | global batch size:   368 | lm loss: 6.276991E+00 | loss scale: 4096.0 | grad norm: 3015.129 | num zeros: 0.0 | params norm: 516.388 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration      443/    1571 | consumed samples:        36856 | consumed tokens:     75481088 | elapsed time per iteration (s): 72.56 | learning rate: 9.893E-05 | global batch size:   368 | lm loss: 6.280344E+00 | loss scale: 4096.0 | grad norm: 3123.969 | num zeros: 0.0 | params norm: 516.410 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration      444/    1571 | consumed samples:        37232 | consumed tokens:     76251136 | elapsed time per iteration (s): 74.03 | learning rate: 9.890E-05 | global batch size:   376 | lm loss: 6.267353E+00 | loss scale: 4096.0 | grad norm: 3738.692 | num zeros: 0.0 | params norm: 516.429 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      445/    1571 | consumed samples:        37608 | consumed tokens:     77021184 | elapsed time per iteration (s): 74.10 | learning rate: 9.887E-05 | global batch size:   376 | lm loss: 6.286762E+00 | loss scale: 4096.0 | grad norm: 3432.502 | num zeros: 0.0 | params norm: 516.450 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration      446/    1571 | consumed samples:        37992 | consumed tokens:     77807616 | elapsed time per iteration (s): 75.42 | learning rate: 9.884E-05 | global batch size:   384 | lm loss: 6.275953E+00 | loss scale: 4096.0 | grad norm: 3597.999 | num zeros: 0.0 | params norm: 516.470 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.092 | TFLOPs: 53.76 |
 iteration      447/    1571 | consumed samples:        38376 | consumed tokens:     78594048 | elapsed time per iteration (s): 75.47 | learning rate: 9.881E-05 | global batch size:   384 | lm loss: 6.256148E+00 | loss scale: 4096.0 | grad norm: 3759.124 | num zeros: 0.0 | params norm: 516.492 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.088 | TFLOPs: 53.73 |
 iteration      448/    1571 | consumed samples:        38760 | consumed tokens:     79380480 | elapsed time per iteration (s): 75.47 | learning rate: 9.878E-05 | global batch size:   384 | lm loss: 6.235909E+00 | loss scale: 4096.0 | grad norm: 3576.784 | num zeros: 0.0 | params norm: 516.512 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.088 | TFLOPs: 53.73 |
 iteration      449/    1571 | consumed samples:        39152 | consumed tokens:     80183296 | elapsed time per iteration (s): 76.99 | learning rate: 9.875E-05 | global batch size:   392 | lm loss: 6.262891E+00 | loss scale: 4096.0 | grad norm: 4244.728 | num zeros: 0.0 | params norm: 516.534 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.091 | TFLOPs: 53.76 |
 iteration      450/    1571 | consumed samples:        39544 | consumed tokens:     80986112 | elapsed time per iteration (s): 76.89 | learning rate: 9.872E-05 | global batch size:   392 | lm loss: 6.255577E+00 | loss scale: 4096.0 | grad norm: 4385.587 | num zeros: 0.0 | params norm: 516.555 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.098 | TFLOPs: 53.84 |
 iteration      451/    1571 | consumed samples:        39944 | consumed tokens:     81805312 | elapsed time per iteration (s): 78.35 | learning rate: 9.869E-05 | global batch size:   400 | lm loss: 6.235404E+00 | loss scale: 4096.0 | grad norm: 3616.036 | num zeros: 0.0 | params norm: 516.575 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.105 | TFLOPs: 53.91 |
 iteration      452/    1571 | consumed samples:        40344 | consumed tokens:     82624512 | elapsed time per iteration (s): 78.35 | learning rate: 9.866E-05 | global batch size:   400 | lm loss: 6.266890E+00 | loss scale: 4096.0 | grad norm: 5306.714 | num zeros: 0.0 | params norm: 516.596 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.106 | TFLOPs: 53.91 |
 iteration      453/    1571 | consumed samples:        40744 | consumed tokens:     83443712 | elapsed time per iteration (s): 78.37 | learning rate: 9.863E-05 | global batch size:   400 | lm loss: 6.265399E+00 | loss scale: 4096.0 | grad norm: 3719.697 | num zeros: 0.0 | params norm: 516.618 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.104 | TFLOPs: 53.89 |
 iteration      454/    1571 | consumed samples:        41144 | consumed tokens:     84262912 | elapsed time per iteration (s): 78.36 | learning rate: 9.859E-05 | global batch size:   400 | lm loss: 6.236722E+00 | loss scale: 4096.0 | grad norm: 4200.539 | num zeros: 0.0 | params norm: 516.638 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.104 | TFLOPs: 53.90 |
 iteration      455/    1571 | consumed samples:        41544 | consumed tokens:     85082112 | elapsed time per iteration (s): 78.37 | learning rate: 9.856E-05 | global batch size:   400 | lm loss: 6.240368E+00 | loss scale: 4096.0 | grad norm: 3230.690 | num zeros: 0.0 | params norm: 516.659 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.104 | TFLOPs: 53.89 |
 iteration      456/    1571 | consumed samples:        41944 | consumed tokens:     85901312 | elapsed time per iteration (s): 78.37 | learning rate: 9.853E-05 | global batch size:   400 | lm loss: 6.225771E+00 | loss scale: 4096.0 | grad norm: 3071.197 | num zeros: 0.0 | params norm: 516.682 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.104 | TFLOPs: 53.90 |
 iteration      457/    1571 | consumed samples:        42344 | consumed tokens:     86720512 | elapsed time per iteration (s): 78.39 | learning rate: 9.849E-05 | global batch size:   400 | lm loss: 6.235517E+00 | loss scale: 4096.0 | grad norm: 3163.995 | num zeros: 0.0 | params norm: 516.704 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.103 | TFLOPs: 53.88 |
 iteration      458/    1571 | consumed samples:        42744 | consumed tokens:     87539712 | elapsed time per iteration (s): 78.35 | learning rate: 9.846E-05 | global batch size:   400 | lm loss: 6.236668E+00 | loss scale: 4096.0 | grad norm: 3804.178 | num zeros: 0.0 | params norm: 516.726 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.105 | TFLOPs: 53.91 |
 iteration      459/    1571 | consumed samples:        43144 | consumed tokens:     88358912 | elapsed time per iteration (s): 78.38 | learning rate: 9.842E-05 | global batch size:   400 | lm loss: 6.232293E+00 | loss scale: 4096.0 | grad norm: 5628.439 | num zeros: 0.0 | params norm: 516.749 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.103 | TFLOPs: 53.89 |
 iteration      460/    1571 | consumed samples:        43544 | consumed tokens:     89178112 | elapsed time per iteration (s): 78.41 | learning rate: 9.839E-05 | global batch size:   400 | lm loss: 6.212144E+00 | loss scale: 4096.0 | grad norm: 3791.143 | num zeros: 0.0 | params norm: 516.771 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.101 | TFLOPs: 53.86 |
 iteration      461/    1571 | consumed samples:        43944 | consumed tokens:     89997312 | elapsed time per iteration (s): 78.40 | learning rate: 9.835E-05 | global batch size:   400 | lm loss: 6.178672E+00 | loss scale: 4096.0 | grad norm: 2722.181 | num zeros: 0.0 | params norm: 516.794 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.102 | TFLOPs: 53.87 |
 iteration      462/    1571 | consumed samples:        44344 | consumed tokens:     90816512 | elapsed time per iteration (s): 78.46 | learning rate: 9.832E-05 | global batch size:   400 | lm loss: 6.208814E+00 | loss scale: 4096.0 | grad norm: 3228.675 | num zeros: 0.0 | params norm: 516.816 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.098 | TFLOPs: 53.83 |
 iteration      463/    1571 | consumed samples:        44744 | consumed tokens:     91635712 | elapsed time per iteration (s): 78.41 | learning rate: 9.828E-05 | global batch size:   400 | lm loss: 6.206543E+00 | loss scale: 4096.0 | grad norm: 4101.789 | num zeros: 0.0 | params norm: 516.839 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.101 | TFLOPs: 53.87 |
 iteration      464/    1571 | consumed samples:        45144 | consumed tokens:     92454912 | elapsed time per iteration (s): 78.44 | learning rate: 9.824E-05 | global batch size:   400 | lm loss: 6.200077E+00 | loss scale: 4096.0 | grad norm: 5186.047 | num zeros: 0.0 | params norm: 516.860 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.100 | TFLOPs: 53.85 |
 iteration      465/    1571 | consumed samples:        45544 | consumed tokens:     93274112 | elapsed time per iteration (s): 78.37 | learning rate: 9.821E-05 | global batch size:   400 | lm loss: 6.170756E+00 | loss scale: 4096.0 | grad norm: 3722.244 | num zeros: 0.0 | params norm: 516.882 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.104 | TFLOPs: 53.90 |
 iteration      466/    1571 | consumed samples:        45944 | consumed tokens:     94093312 | elapsed time per iteration (s): 78.42 | learning rate: 9.817E-05 | global batch size:   400 | lm loss: 6.193755E+00 | loss scale: 4096.0 | grad norm: 4042.763 | num zeros: 0.0 | params norm: 516.905 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.101 | TFLOPs: 53.86 |
 iteration      467/    1571 | consumed samples:        46344 | consumed tokens:     94912512 | elapsed time per iteration (s): 78.45 | learning rate: 9.813E-05 | global batch size:   400 | lm loss: 6.212330E+00 | loss scale: 4096.0 | grad norm: 5799.474 | num zeros: 0.0 | params norm: 516.927 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.099 | TFLOPs: 53.84 |
 iteration      468/    1571 | consumed samples:        46744 | consumed tokens:     95731712 | elapsed time per iteration (s): 78.48 | learning rate: 9.809E-05 | global batch size:   400 | lm loss: 6.170509E+00 | loss scale: 4096.0 | grad norm: 4101.130 | num zeros: 0.0 | params norm: 516.949 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.097 | TFLOPs: 53.82 |
 iteration      469/    1571 | consumed samples:        47144 | consumed tokens:     96550912 | elapsed time per iteration (s): 78.41 | learning rate: 9.805E-05 | global batch size:   400 | lm loss: 6.190221E+00 | loss scale: 4096.0 | grad norm: 5121.202 | num zeros: 0.0 | params norm: 516.971 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.101 | TFLOPs: 53.86 |
 iteration      470/    1571 | consumed samples:        47544 | consumed tokens:     97370112 | elapsed time per iteration (s): 78.45 | learning rate: 9.801E-05 | global batch size:   400 | lm loss: 6.188053E+00 | loss scale: 4096.0 | grad norm: 6669.492 | num zeros: 0.0 | params norm: 516.994 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.099 | TFLOPs: 53.84 |
 iteration      471/    1571 | consumed samples:        47944 | consumed tokens:     98189312 | elapsed time per iteration (s): 78.45 | learning rate: 9.797E-05 | global batch size:   400 | lm loss: 6.184442E+00 | loss scale: 4096.0 | grad norm: 2883.219 | num zeros: 0.0 | params norm: 517.015 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.099 | TFLOPs: 53.84 |
 iteration      472/    1571 | consumed samples:        48344 | consumed tokens:     99008512 | elapsed time per iteration (s): 78.46 | learning rate: 9.793E-05 | global batch size:   400 | lm loss: 6.157413E+00 | loss scale: 4096.0 | grad norm: 3834.233 | num zeros: 0.0 | params norm: 517.037 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.098 | TFLOPs: 53.83 |
 iteration      473/    1571 | consumed samples:        48744 | consumed tokens:     99827712 | elapsed time per iteration (s): 78.48 | learning rate: 9.789E-05 | global batch size:   400 | lm loss: 6.153706E+00 | loss scale: 4096.0 | grad norm: 3076.101 | num zeros: 0.0 | params norm: 517.060 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.097 | TFLOPs: 53.82 |
 iteration      474/    1571 | consumed samples:        49144 | consumed tokens:    100646912 | elapsed time per iteration (s): 78.50 | learning rate: 9.785E-05 | global batch size:   400 | lm loss: 6.151543E+00 | loss scale: 4096.0 | grad norm: 2724.966 | num zeros: 0.0 | params norm: 517.082 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.095 | TFLOPs: 53.80 |
 iteration      475/    1571 | consumed samples:        49544 | consumed tokens:    101466112 | elapsed time per iteration (s): 78.43 | learning rate: 9.781E-05 | global batch size:   400 | lm loss: 6.167495E+00 | loss scale: 4096.0 | grad norm: 3909.570 | num zeros: 0.0 | params norm: 517.105 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.100 | TFLOPs: 53.85 |
 iteration      476/    1571 | consumed samples:        49944 | consumed tokens:    102285312 | elapsed time per iteration (s): 78.48 | learning rate: 9.777E-05 | global batch size:   400 | lm loss: 6.145135E+00 | loss scale: 4096.0 | grad norm: 5017.766 | num zeros: 0.0 | params norm: 517.126 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.097 | TFLOPs: 53.82 |
 iteration      477/    1571 | consumed samples:        50344 | consumed tokens:    103104512 | elapsed time per iteration (s): 78.44 | learning rate: 9.773E-05 | global batch size:   400 | lm loss: 6.142975E+00 | loss scale: 4096.0 | grad norm: 4440.480 | num zeros: 0.0 | params norm: 517.149 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.099 | TFLOPs: 53.84 |
 iteration      478/    1571 | consumed samples:        50744 | consumed tokens:    103923712 | elapsed time per iteration (s): 78.48 | learning rate: 9.769E-05 | global batch size:   400 | lm loss: 6.133702E+00 | loss scale: 4096.0 | grad norm: 3636.001 | num zeros: 0.0 | params norm: 517.170 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.097 | TFLOPs: 53.82 |
 iteration      479/    1571 | consumed samples:        51144 | consumed tokens:    104742912 | elapsed time per iteration (s): 78.47 | learning rate: 9.764E-05 | global batch size:   400 | lm loss: 6.128880E+00 | loss scale: 4096.0 | grad norm: 3843.427 | num zeros: 0.0 | params norm: 517.192 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.097 | TFLOPs: 53.83 |
 iteration      480/    1571 | consumed samples:        51544 | consumed tokens:    105562112 | elapsed time per iteration (s): 78.49 | learning rate: 9.760E-05 | global batch size:   400 | lm loss: 6.138993E+00 | loss scale: 4096.0 | grad norm: 4352.840 | num zeros: 0.0 | params norm: 517.214 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.096 | TFLOPs: 53.81 |
 iteration      481/    1571 | consumed samples:        51944 | consumed tokens:    106381312 | elapsed time per iteration (s): 78.42 | learning rate: 9.756E-05 | global batch size:   400 | lm loss: 6.145379E+00 | loss scale: 4096.0 | grad norm: 5168.394 | num zeros: 0.0 | params norm: 517.235 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.101 | TFLOPs: 53.86 |
 iteration      482/    1571 | consumed samples:        52344 | consumed tokens:    107200512 | elapsed time per iteration (s): 78.48 | learning rate: 9.751E-05 | global batch size:   400 | lm loss: 6.122213E+00 | loss scale: 4096.0 | grad norm: 4597.416 | num zeros: 0.0 | params norm: 517.257 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.097 | TFLOPs: 53.82 |
 iteration      483/    1571 | consumed samples:        52744 | consumed tokens:    108019712 | elapsed time per iteration (s): 78.38 | learning rate: 9.747E-05 | global batch size:   400 | lm loss: 6.130404E+00 | loss scale: 4096.0 | grad norm: 3201.721 | num zeros: 0.0 | params norm: 517.278 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.103 | TFLOPs: 53.89 |
 iteration      484/    1571 | consumed samples:        53144 | consumed tokens:    108838912 | elapsed time per iteration (s): 78.46 | learning rate: 9.743E-05 | global batch size:   400 | lm loss: 6.077468E+00 | loss scale: 4096.0 | grad norm: 3297.038 | num zeros: 0.0 | params norm: 517.300 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.098 | TFLOPs: 53.83 |
 iteration      485/    1571 | consumed samples:        53544 | consumed tokens:    109658112 | elapsed time per iteration (s): 78.41 | learning rate: 9.738E-05 | global batch size:   400 | lm loss: 6.089755E+00 | loss scale: 4096.0 | grad norm: 4513.125 | num zeros: 0.0 | params norm: 517.321 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.101 | TFLOPs: 53.87 |
 iteration      486/    1571 | consumed samples:        53944 | consumed tokens:    110477312 | elapsed time per iteration (s): 78.51 | learning rate: 9.734E-05 | global batch size:   400 | lm loss: 6.141086E+00 | loss scale: 4096.0 | grad norm: 5551.801 | num zeros: 0.0 | params norm: 517.342 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.095 | TFLOPs: 53.80 |
 iteration      487/    1571 | consumed samples:        54344 | consumed tokens:    111296512 | elapsed time per iteration (s): 78.46 | learning rate: 9.729E-05 | global batch size:   400 | lm loss: 6.103469E+00 | loss scale: 4096.0 | grad norm: 3496.067 | num zeros: 0.0 | params norm: 517.364 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.098 | TFLOPs: 53.84 |
 iteration      488/    1571 | consumed samples:        54744 | consumed tokens:    112115712 | elapsed time per iteration (s): 78.48 | learning rate: 9.725E-05 | global batch size:   400 | lm loss: 6.104580E+00 | loss scale: 4096.0 | grad norm: 3533.567 | num zeros: 0.0 | params norm: 517.385 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.097 | TFLOPs: 53.82 |
 iteration      489/    1571 | consumed samples:        55144 | consumed tokens:    112934912 | elapsed time per iteration (s): 78.43 | learning rate: 9.720E-05 | global batch size:   400 | lm loss: 6.080764E+00 | loss scale: 4096.0 | grad norm: 4123.981 | num zeros: 0.0 | params norm: 517.407 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.100 | TFLOPs: 53.85 |
 iteration      490/    1571 | consumed samples:        55544 | consumed tokens:    113754112 | elapsed time per iteration (s): 78.48 | learning rate: 9.715E-05 | global batch size:   400 | lm loss: 6.058787E+00 | loss scale: 4096.0 | grad norm: 5059.964 | num zeros: 0.0 | params norm: 517.430 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.097 | TFLOPs: 53.82 |
 iteration      491/    1571 | consumed samples:        55944 | consumed tokens:    114573312 | elapsed time per iteration (s): 78.44 | learning rate: 9.711E-05 | global batch size:   400 | lm loss: 6.077785E+00 | loss scale: 4096.0 | grad norm: 4135.539 | num zeros: 0.0 | params norm: 517.452 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.099 | TFLOPs: 53.84 |
 iteration      492/    1571 | consumed samples:        56344 | consumed tokens:    115392512 | elapsed time per iteration (s): 78.51 | learning rate: 9.706E-05 | global batch size:   400 | lm loss: 6.118039E+00 | loss scale: 4096.0 | grad norm: 4882.858 | num zeros: 0.0 | params norm: 517.474 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.095 | TFLOPs: 53.80 |
 iteration      493/    1571 | consumed samples:        56744 | consumed tokens:    116211712 | elapsed time per iteration (s): 78.43 | learning rate: 9.701E-05 | global batch size:   400 | lm loss: 6.088999E+00 | loss scale: 4096.0 | grad norm: 3500.854 | num zeros: 0.0 | params norm: 517.496 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.100 | TFLOPs: 53.86 |
 iteration      494/    1571 | consumed samples:        57144 | consumed tokens:    117030912 | elapsed time per iteration (s): 78.47 | learning rate: 9.696E-05 | global batch size:   400 | lm loss: 6.079139E+00 | loss scale: 4096.0 | grad norm: 3214.215 | num zeros: 0.0 | params norm: 517.519 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.097 | TFLOPs: 53.82 |
 iteration      495/    1571 | consumed samples:        57544 | consumed tokens:    117850112 | elapsed time per iteration (s): 78.47 | learning rate: 9.691E-05 | global batch size:   400 | lm loss: 6.059690E+00 | loss scale: 4096.0 | grad norm: 3346.190 | num zeros: 0.0 | params norm: 517.542 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.098 | TFLOPs: 53.83 |
 iteration      496/    1571 | consumed samples:        57944 | consumed tokens:    118669312 | elapsed time per iteration (s): 78.47 | learning rate: 9.686E-05 | global batch size:   400 | lm loss: 6.052754E+00 | loss scale: 4096.0 | grad norm: 3925.776 | num zeros: 0.0 | params norm: 517.564 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.098 | TFLOPs: 53.83 |
 iteration      497/    1571 | consumed samples:        58344 | consumed tokens:    119488512 | elapsed time per iteration (s): 78.44 | learning rate: 9.682E-05 | global batch size:   400 | lm loss: 6.068791E+00 | loss scale: 4096.0 | grad norm: 4102.070 | num zeros: 0.0 | params norm: 517.587 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.100 | TFLOPs: 53.85 |
 iteration      498/    1571 | consumed samples:        58744 | consumed tokens:    120307712 | elapsed time per iteration (s): 78.47 | learning rate: 9.677E-05 | global batch size:   400 | lm loss: 6.071303E+00 | loss scale: 4096.0 | grad norm: 4730.612 | num zeros: 0.0 | params norm: 517.609 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.098 | TFLOPs: 53.83 |
 iteration      499/    1571 | consumed samples:        59144 | consumed tokens:    121126912 | elapsed time per iteration (s): 78.44 | learning rate: 9.672E-05 | global batch size:   400 | lm loss: 6.068528E+00 | loss scale: 4096.0 | grad norm: 3572.229 | num zeros: 0.0 | params norm: 517.631 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.100 | TFLOPs: 53.85 |
 iteration      500/    1571 | consumed samples:        59544 | consumed tokens:    121946112 | elapsed time per iteration (s): 78.53 | learning rate: 9.667E-05 | global batch size:   400 | lm loss: 6.040524E+00 | loss scale: 4096.0 | grad norm: 3191.160 | num zeros: 0.0 | params norm: 517.654 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.094 | TFLOPs: 53.78 |
 iteration      501/    1571 | consumed samples:        59944 | consumed tokens:    122765312 | elapsed time per iteration (s): 1200.73 | learning rate: 9.661E-05 | global batch size:   400 | lm loss: 6.050603E+00 | loss scale: 4096.0 | grad norm: 3896.886 | num zeros: 0.0 | params norm: 517.675 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.333 | TFLOPs: 3.52 |
 iteration      502/    1571 | consumed samples:        60344 | consumed tokens:    123584512 | elapsed time per iteration (s): 78.64 | learning rate: 9.656E-05 | global batch size:   400 | lm loss: 6.049166E+00 | loss scale: 4096.0 | grad norm: 3582.042 | num zeros: 0.0 | params norm: 517.699 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.087 | TFLOPs: 53.71 |
 iteration      503/    1571 | consumed samples:        60744 | consumed tokens:    124403712 | elapsed time per iteration (s): 78.45 | learning rate: 9.651E-05 | global batch size:   400 | lm loss: 6.020631E+00 | loss scale: 4096.0 | grad norm: 3537.359 | num zeros: 0.0 | params norm: 517.721 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.099 | TFLOPs: 53.84 |
 iteration      504/    1571 | consumed samples:        61144 | consumed tokens:    125222912 | elapsed time per iteration (s): 78.54 | learning rate: 9.646E-05 | global batch size:   400 | lm loss: 6.035546E+00 | loss scale: 4096.0 | grad norm: 4715.943 | num zeros: 0.0 | params norm: 517.744 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.093 | TFLOPs: 53.77 |
 iteration      505/    1571 | consumed samples:        61544 | consumed tokens:    126042112 | elapsed time per iteration (s): 78.55 | learning rate: 9.641E-05 | global batch size:   400 | lm loss: 6.042990E+00 | loss scale: 4096.0 | grad norm: 4044.318 | num zeros: 0.0 | params norm: 517.766 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.092 | TFLOPs: 53.77 |
 iteration      506/    1571 | consumed samples:        61944 | consumed tokens:    126861312 | elapsed time per iteration (s): 78.55 | learning rate: 9.636E-05 | global batch size:   400 | lm loss: 6.053065E+00 | loss scale: 4096.0 | grad norm: 4548.735 | num zeros: 0.0 | params norm: 517.788 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.092 | TFLOPs: 53.77 |
 iteration      507/    1571 | consumed samples:        62344 | consumed tokens:    127680512 | elapsed time per iteration (s): 78.45 | learning rate: 9.630E-05 | global batch size:   400 | lm loss: 6.031245E+00 | loss scale: 4096.0 | grad norm: 3998.594 | num zeros: 0.0 | params norm: 517.810 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.099 | TFLOPs: 53.84 |
 iteration      508/    1571 | consumed samples:        62744 | consumed tokens:    128499712 | elapsed time per iteration (s): 78.56 | learning rate: 9.625E-05 | global batch size:   400 | lm loss: 6.018138E+00 | loss scale: 4096.0 | grad norm: 3582.292 | num zeros: 0.0 | params norm: 517.832 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.092 | TFLOPs: 53.77 |
 iteration      509/    1571 | consumed samples:        63144 | consumed tokens:    129318912 | elapsed time per iteration (s): 78.43 | learning rate: 9.620E-05 | global batch size:   400 | lm loss: 6.031329E+00 | loss scale: 4096.0 | grad norm: 5025.061 | num zeros: 0.0 | params norm: 517.853 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.100 | TFLOPs: 53.85 |
 iteration      510/    1571 | consumed samples:        63544 | consumed tokens:    130138112 | elapsed time per iteration (s): 78.51 | learning rate: 9.614E-05 | global batch size:   400 | lm loss: 6.020134E+00 | loss scale: 4096.0 | grad norm: 2549.795 | num zeros: 0.0 | params norm: 517.877 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.095 | TFLOPs: 53.79 |
 iteration      511/    1571 | consumed samples:        63944 | consumed tokens:    130957312 | elapsed time per iteration (s): 78.47 | learning rate: 9.609E-05 | global batch size:   400 | lm loss: 6.027234E+00 | loss scale: 4096.0 | grad norm: 3257.681 | num zeros: 0.0 | params norm: 517.899 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.098 | TFLOPs: 53.83 |
 iteration      512/    1571 | consumed samples:        64344 | consumed tokens:    131776512 | elapsed time per iteration (s): 78.52 | learning rate: 9.603E-05 | global batch size:   400 | lm loss: 6.026117E+00 | loss scale: 4096.0 | grad norm: 3557.807 | num zeros: 0.0 | params norm: 517.922 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.094 | TFLOPs: 53.79 |
 iteration      513/    1571 | consumed samples:        64744 | consumed tokens:    132595712 | elapsed time per iteration (s): 78.56 | learning rate: 9.598E-05 | global batch size:   400 | lm loss: 6.039434E+00 | loss scale: 4096.0 | grad norm: 4350.999 | num zeros: 0.0 | params norm: 517.944 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.092 | TFLOPs: 53.76 |
 iteration      514/    1571 | consumed samples:        65144 | consumed tokens:    133414912 | elapsed time per iteration (s): 78.54 | learning rate: 9.592E-05 | global batch size:   400 | lm loss: 5.986836E+00 | loss scale: 4096.0 | grad norm: 3299.129 | num zeros: 0.0 | params norm: 517.967 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.093 | TFLOPs: 53.78 |
 iteration      515/    1571 | consumed samples:        65544 | consumed tokens:    134234112 | elapsed time per iteration (s): 78.49 | learning rate: 9.587E-05 | global batch size:   400 | lm loss: 5.996487E+00 | loss scale: 4096.0 | grad norm: 3736.103 | num zeros: 0.0 | params norm: 517.989 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.096 | TFLOPs: 53.81 |
 iteration      516/    1571 | consumed samples:        65944 | consumed tokens:    135053312 | elapsed time per iteration (s): 78.50 | learning rate: 9.581E-05 | global batch size:   400 | lm loss: 5.997087E+00 | loss scale: 4096.0 | grad norm: 4179.738 | num zeros: 0.0 | params norm: 518.012 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.096 | TFLOPs: 53.81 |
 iteration      517/    1571 | consumed samples:        66344 | consumed tokens:    135872512 | elapsed time per iteration (s): 78.49 | learning rate: 9.575E-05 | global batch size:   400 | lm loss: 6.018267E+00 | loss scale: 4096.0 | grad norm: 4668.489 | num zeros: 0.0 | params norm: 518.034 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.096 | TFLOPs: 53.81 |
 iteration      518/    1571 | consumed samples:        66744 | consumed tokens:    136691712 | elapsed time per iteration (s): 78.51 | learning rate: 9.570E-05 | global batch size:   400 | lm loss: 5.988007E+00 | loss scale: 4096.0 | grad norm: 3968.028 | num zeros: 0.0 | params norm: 518.056 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.095 | TFLOPs: 53.80 |
 iteration      519/    1571 | consumed samples:        67144 | consumed tokens:    137510912 | elapsed time per iteration (s): 78.47 | learning rate: 9.564E-05 | global batch size:   400 | lm loss: 6.017355E+00 | loss scale: 4096.0 | grad norm: 4231.303 | num zeros: 0.0 | params norm: 518.079 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.098 | TFLOPs: 53.83 |
 iteration      520/    1571 | consumed samples:        67544 | consumed tokens:    138330112 | elapsed time per iteration (s): 78.54 | learning rate: 9.558E-05 | global batch size:   400 | lm loss: 5.979252E+00 | loss scale: 4096.0 | grad norm: 6197.174 | num zeros: 0.0 | params norm: 518.099 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.093 | TFLOPs: 53.78 |
 iteration      521/    1571 | consumed samples:        67944 | consumed tokens:    139149312 | elapsed time per iteration (s): 78.49 | learning rate: 9.552E-05 | global batch size:   400 | lm loss: 6.000182E+00 | loss scale: 4096.0 | grad norm: 3776.857 | num zeros: 0.0 | params norm: 518.120 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.096 | TFLOPs: 53.81 |
 iteration      522/    1571 | consumed samples:        68344 | consumed tokens:    139968512 | elapsed time per iteration (s): 78.53 | learning rate: 9.547E-05 | global batch size:   400 | lm loss: 5.957504E+00 | loss scale: 4096.0 | grad norm: 2964.777 | num zeros: 0.0 | params norm: 518.141 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.094 | TFLOPs: 53.78 |
 iteration      523/    1571 | consumed samples:        68744 | consumed tokens:    140787712 | elapsed time per iteration (s): 78.47 | learning rate: 9.541E-05 | global batch size:   400 | lm loss: 5.990742E+00 | loss scale: 4096.0 | grad norm: 3491.902 | num zeros: 0.0 | params norm: 518.164 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.097 | TFLOPs: 53.82 |
 iteration      524/    1571 | consumed samples:        69144 | consumed tokens:    141606912 | elapsed time per iteration (s): 78.49 | learning rate: 9.535E-05 | global batch size:   400 | lm loss: 5.979027E+00 | loss scale: 4096.0 | grad norm: 3860.632 | num zeros: 0.0 | params norm: 518.185 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.096 | TFLOPs: 53.81 |
 iteration      525/    1571 | consumed samples:        69544 | consumed tokens:    142426112 | elapsed time per iteration (s): 78.47 | learning rate: 9.529E-05 | global batch size:   400 | lm loss: 5.974656E+00 | loss scale: 4096.0 | grad norm: 4544.149 | num zeros: 0.0 | params norm: 518.208 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.098 | TFLOPs: 53.83 |
 iteration      526/    1571 | consumed samples:        69944 | consumed tokens:    143245312 | elapsed time per iteration (s): 78.50 | learning rate: 9.523E-05 | global batch size:   400 | lm loss: 5.970527E+00 | loss scale: 4096.0 | grad norm: 3247.304 | num zeros: 0.0 | params norm: 518.229 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.096 | TFLOPs: 53.81 |
 iteration      527/    1571 | consumed samples:        70344 | consumed tokens:    144064512 | elapsed time per iteration (s): 78.43 | learning rate: 9.517E-05 | global batch size:   400 | lm loss: 5.982091E+00 | loss scale: 4096.0 | grad norm: 4183.192 | num zeros: 0.0 | params norm: 518.250 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.100 | TFLOPs: 53.85 |
 iteration      528/    1571 | consumed samples:        70744 | consumed tokens:    144883712 | elapsed time per iteration (s): 78.50 | learning rate: 9.511E-05 | global batch size:   400 | lm loss: 5.955591E+00 | loss scale: 4096.0 | grad norm: 3462.632 | num zeros: 0.0 | params norm: 518.272 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.096 | TFLOPs: 53.81 |
 iteration      529/    1571 | consumed samples:        71144 | consumed tokens:    145702912 | elapsed time per iteration (s): 78.42 | learning rate: 9.505E-05 | global batch size:   400 | lm loss: 5.952162E+00 | loss scale: 4096.0 | grad norm: 3196.395 | num zeros: 0.0 | params norm: 518.295 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.101 | TFLOPs: 53.86 |
 iteration      530/    1571 | consumed samples:        71544 | consumed tokens:    146522112 | elapsed time per iteration (s): 78.51 | learning rate: 9.499E-05 | global batch size:   400 | lm loss: 5.975258E+00 | loss scale: 4096.0 | grad norm: 4629.233 | num zeros: 0.0 | params norm: 518.317 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.095 | TFLOPs: 53.80 |
 iteration      531/    1571 | consumed samples:        71944 | consumed tokens:    147341312 | elapsed time per iteration (s): 78.49 | learning rate: 9.492E-05 | global batch size:   400 | lm loss: 5.955080E+00 | loss scale: 4096.0 | grad norm: 4207.946 | num zeros: 0.0 | params norm: 518.339 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.096 | TFLOPs: 53.81 |
 iteration      532/    1571 | consumed samples:        72344 | consumed tokens:    148160512 | elapsed time per iteration (s): 78.51 | learning rate: 9.486E-05 | global batch size:   400 | lm loss: 5.962707E+00 | loss scale: 4096.0 | grad norm: 4095.431 | num zeros: 0.0 | params norm: 518.360 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.095 | TFLOPs: 53.80 |
 iteration      533/    1571 | consumed samples:        72744 | consumed tokens:    148979712 | elapsed time per iteration (s): 78.46 | learning rate: 9.480E-05 | global batch size:   400 | lm loss: 5.944581E+00 | loss scale: 4096.0 | grad norm: 4464.391 | num zeros: 0.0 | params norm: 518.382 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.098 | TFLOPs: 53.83 |
 iteration      534/    1571 | consumed samples:        73144 | consumed tokens:    149798912 | elapsed time per iteration (s): 78.49 | learning rate: 9.474E-05 | global batch size:   400 | lm loss: 5.963384E+00 | loss scale: 4096.0 | grad norm: 4379.649 | num zeros: 0.0 | params norm: 518.404 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.096 | TFLOPs: 53.81 |
 iteration      535/    1571 | consumed samples:        73544 | consumed tokens:    150618112 | elapsed time per iteration (s): 78.48 | learning rate: 9.467E-05 | global batch size:   400 | lm loss: 5.932028E+00 | loss scale: 4096.0 | grad norm: 3591.048 | num zeros: 0.0 | params norm: 518.425 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.097 | TFLOPs: 53.82 |
 iteration      536/    1571 | consumed samples:        73944 | consumed tokens:    151437312 | elapsed time per iteration (s): 78.51 | learning rate: 9.461E-05 | global batch size:   400 | lm loss: 5.941220E+00 | loss scale: 4096.0 | grad norm: 3102.553 | num zeros: 0.0 | params norm: 518.447 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.095 | TFLOPs: 53.80 |
 iteration      537/    1571 | consumed samples:        74344 | consumed tokens:    152256512 | elapsed time per iteration (s): 78.51 | learning rate: 9.455E-05 | global batch size:   400 | lm loss: 5.920133E+00 | loss scale: 4096.0 | grad norm: 4001.998 | num zeros: 0.0 | params norm: 518.469 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.095 | TFLOPs: 53.80 |
 iteration      538/    1571 | consumed samples:        74744 | consumed tokens:    153075712 | elapsed time per iteration (s): 78.54 | learning rate: 9.448E-05 | global batch size:   400 | lm loss: 5.923363E+00 | loss scale: 4096.0 | grad norm: 4434.488 | num zeros: 0.0 | params norm: 518.491 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.093 | TFLOPs: 53.78 |
 iteration      539/    1571 | consumed samples:        75144 | consumed tokens:    153894912 | elapsed time per iteration (s): 78.49 | learning rate: 9.442E-05 | global batch size:   400 | lm loss: 5.915497E+00 | loss scale: 4096.0 | grad norm: 4609.660 | num zeros: 0.0 | params norm: 518.513 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.096 | TFLOPs: 53.81 |
 iteration      540/    1571 | consumed samples:        75544 | consumed tokens:    154714112 | elapsed time per iteration (s): 78.54 | learning rate: 9.435E-05 | global batch size:   400 | lm loss: 5.919500E+00 | loss scale: 4096.0 | grad norm: 4071.973 | num zeros: 0.0 | params norm: 518.535 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.093 | TFLOPs: 53.78 |
 iteration      541/    1571 | consumed samples:        75944 | consumed tokens:    155533312 | elapsed time per iteration (s): 78.52 | learning rate: 9.429E-05 | global batch size:   400 | lm loss: 5.917494E+00 | loss scale: 4096.0 | grad norm: 3128.309 | num zeros: 0.0 | params norm: 518.558 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.095 | TFLOPs: 53.79 |
 iteration      542/    1571 | consumed samples:        76344 | consumed tokens:    156352512 | elapsed time per iteration (s): 78.52 | learning rate: 9.422E-05 | global batch size:   400 | lm loss: 5.931188E+00 | loss scale: 4096.0 | grad norm: 4129.694 | num zeros: 0.0 | params norm: 518.579 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.094 | TFLOPs: 53.79 |
 iteration      543/    1571 | consumed samples:        76744 | consumed tokens:    157171712 | elapsed time per iteration (s): 78.50 | learning rate: 9.416E-05 | global batch size:   400 | lm loss: 5.874997E+00 | loss scale: 4096.0 | grad norm: 3527.993 | num zeros: 0.0 | params norm: 518.602 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.096 | TFLOPs: 53.81 |
 iteration      544/    1571 | consumed samples:        77144 | consumed tokens:    157990912 | elapsed time per iteration (s): 78.53 | learning rate: 9.409E-05 | global batch size:   400 | lm loss: 5.892001E+00 | loss scale: 4096.0 | grad norm: 3000.166 | num zeros: 0.0 | params norm: 518.625 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.093 | TFLOPs: 53.78 |
 iteration      545/    1571 | consumed samples:        77544 | consumed tokens:    158810112 | elapsed time per iteration (s): 78.45 | learning rate: 9.403E-05 | global batch size:   400 | lm loss: 5.912561E+00 | loss scale: 4096.0 | grad norm: 2893.254 | num zeros: 0.0 | params norm: 518.648 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.099 | TFLOPs: 53.84 |
 iteration      546/    1571 | consumed samples:        77944 | consumed tokens:    159629312 | elapsed time per iteration (s): 78.49 | learning rate: 9.396E-05 | global batch size:   400 | lm loss: 5.903022E+00 | loss scale: 4096.0 | grad norm: 4505.651 | num zeros: 0.0 | params norm: 518.671 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.096 | TFLOPs: 53.81 |
 iteration      547/    1571 | consumed samples:        78344 | consumed tokens:    160448512 | elapsed time per iteration (s): 78.52 | learning rate: 9.389E-05 | global batch size:   400 | lm loss: 5.909517E+00 | loss scale: 4096.0 | grad norm: 4961.690 | num zeros: 0.0 | params norm: 518.694 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.094 | TFLOPs: 53.79 |
 iteration      548/    1571 | consumed samples:        78744 | consumed tokens:    161267712 | elapsed time per iteration (s): 78.55 | learning rate: 9.382E-05 | global batch size:   400 | lm loss: 5.889921E+00 | loss scale: 4096.0 | grad norm: 3944.546 | num zeros: 0.0 | params norm: 518.718 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.092 | TFLOPs: 53.77 |
 iteration      549/    1571 | consumed samples:        79144 | consumed tokens:    162086912 | elapsed time per iteration (s): 78.52 | learning rate: 9.376E-05 | global batch size:   400 | lm loss: 5.923915E+00 | loss scale: 4096.0 | grad norm: 5058.287 | num zeros: 0.0 | params norm: 518.739 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.094 | TFLOPs: 53.79 |
 iteration      550/    1571 | consumed samples:        79544 | consumed tokens:    162906112 | elapsed time per iteration (s): 78.57 | learning rate: 9.369E-05 | global batch size:   400 | lm loss: 5.901427E+00 | loss scale: 4096.0 | grad norm: 4193.953 | num zeros: 0.0 | params norm: 518.762 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.091 | TFLOPs: 53.76 |
 iteration      551/    1571 | consumed samples:        79944 | consumed tokens:    163725312 | elapsed time per iteration (s): 78.48 | learning rate: 9.362E-05 | global batch size:   400 | lm loss: 5.873713E+00 | loss scale: 4096.0 | grad norm: 4246.104 | num zeros: 0.0 | params norm: 518.784 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.097 | TFLOPs: 53.82 |
 iteration      552/    1571 | consumed samples:        80344 | consumed tokens:    164544512 | elapsed time per iteration (s): 78.50 | learning rate: 9.355E-05 | global batch size:   400 | lm loss: 5.895242E+00 | loss scale: 4096.0 | grad norm: 4531.727 | num zeros: 0.0 | params norm: 518.806 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.096 | TFLOPs: 53.81 |
 iteration      553/    1571 | consumed samples:        80744 | consumed tokens:    165363712 | elapsed time per iteration (s): 78.40 | learning rate: 9.348E-05 | global batch size:   400 | lm loss: 5.903801E+00 | loss scale: 4096.0 | grad norm: 4616.348 | num zeros: 0.0 | params norm: 518.828 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.102 | TFLOPs: 53.87 |
 iteration      554/    1571 | consumed samples:        81144 | consumed tokens:    166182912 | elapsed time per iteration (s): 78.52 | learning rate: 9.341E-05 | global batch size:   400 | lm loss: 5.889045E+00 | loss scale: 4096.0 | grad norm: 4796.232 | num zeros: 0.0 | params norm: 518.850 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.094 | TFLOPs: 53.79 |
 iteration      555/    1571 | consumed samples:        81544 | consumed tokens:    167002112 | elapsed time per iteration (s): 78.51 | learning rate: 9.334E-05 | global batch size:   400 | lm loss: 5.861008E+00 | loss scale: 4096.0 | grad norm: 4749.238 | num zeros: 0.0 | params norm: 518.873 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.095 | TFLOPs: 53.80 |
 iteration      556/    1571 | consumed samples:        81944 | consumed tokens:    167821312 | elapsed time per iteration (s): 78.58 | learning rate: 9.327E-05 | global batch size:   400 | lm loss: 5.854935E+00 | loss scale: 4096.0 | grad norm: 3533.522 | num zeros: 0.0 | params norm: 518.895 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.090 | TFLOPs: 53.75 |
 iteration      557/    1571 | consumed samples:        82344 | consumed tokens:    168640512 | elapsed time per iteration (s): 78.50 | learning rate: 9.320E-05 | global batch size:   400 | lm loss: 5.874094E+00 | loss scale: 4096.0 | grad norm: 3235.606 | num zeros: 0.0 | params norm: 518.918 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.096 | TFLOPs: 53.81 |
 iteration      558/    1571 | consumed samples:        82744 | consumed tokens:    169459712 | elapsed time per iteration (s): 78.58 | learning rate: 9.313E-05 | global batch size:   400 | lm loss: 5.856322E+00 | loss scale: 4096.0 | grad norm: 3876.310 | num zeros: 0.0 | params norm: 518.941 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.090 | TFLOPs: 53.75 |
 iteration      559/    1571 | consumed samples:        83144 | consumed tokens:    170278912 | elapsed time per iteration (s): 78.53 | learning rate: 9.306E-05 | global batch size:   400 | lm loss: 5.861598E+00 | loss scale: 4096.0 | grad norm: 3787.179 | num zeros: 0.0 | params norm: 518.964 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.094 | TFLOPs: 53.79 |
 iteration      560/    1571 | consumed samples:        83544 | consumed tokens:    171098112 | elapsed time per iteration (s): 78.57 | learning rate: 9.299E-05 | global batch size:   400 | lm loss: 5.893832E+00 | loss scale: 4096.0 | grad norm: 5376.563 | num zeros: 0.0 | params norm: 518.987 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.091 | TFLOPs: 53.75 |
 iteration      561/    1571 | consumed samples:        83944 | consumed tokens:    171917312 | elapsed time per iteration (s): 78.49 | learning rate: 9.292E-05 | global batch size:   400 | lm loss: 5.843346E+00 | loss scale: 4096.0 | grad norm: 3659.676 | num zeros: 0.0 | params norm: 519.009 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.096 | TFLOPs: 53.81 |
 iteration      562/    1571 | consumed samples:        84344 | consumed tokens:    172736512 | elapsed time per iteration (s): 78.62 | learning rate: 9.284E-05 | global batch size:   400 | lm loss: 5.862158E+00 | loss scale: 4096.0 | grad norm: 5058.005 | num zeros: 0.0 | params norm: 519.031 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.088 | TFLOPs: 53.72 |
 iteration      563/    1571 | consumed samples:        84744 | consumed tokens:    173555712 | elapsed time per iteration (s): 78.60 | learning rate: 9.277E-05 | global batch size:   400 | lm loss: 5.842393E+00 | loss scale: 4096.0 | grad norm: 4291.230 | num zeros: 0.0 | params norm: 519.054 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.089 | TFLOPs: 53.73 |
 iteration      564/    1571 | consumed samples:        85144 | consumed tokens:    174374912 | elapsed time per iteration (s): 78.55 | learning rate: 9.270E-05 | global batch size:   400 | lm loss: 5.866482E+00 | loss scale: 4096.0 | grad norm: 4326.739 | num zeros: 0.0 | params norm: 519.076 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.092 | TFLOPs: 53.77 |
 iteration      565/    1571 | consumed samples:        85544 | consumed tokens:    175194112 | elapsed time per iteration (s): 78.50 | learning rate: 9.263E-05 | global batch size:   400 | lm loss: 5.845980E+00 | loss scale: 4096.0 | grad norm: 5249.803 | num zeros: 0.0 | params norm: 519.098 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.095 | TFLOPs: 53.80 |
 iteration      566/    1571 | consumed samples:        85944 | consumed tokens:    176013312 | elapsed time per iteration (s): 78.56 | learning rate: 9.255E-05 | global batch size:   400 | lm loss: 5.826993E+00 | loss scale: 4096.0 | grad norm: 3311.992 | num zeros: 0.0 | params norm: 519.121 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.091 | TFLOPs: 53.76 |
 iteration      567/    1571 | consumed samples:        86344 | consumed tokens:    176832512 | elapsed time per iteration (s): 78.53 | learning rate: 9.248E-05 | global batch size:   400 | lm loss: 5.836037E+00 | loss scale: 4096.0 | grad norm: 2864.063 | num zeros: 0.0 | params norm: 519.143 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.094 | TFLOPs: 53.78 |
 iteration      568/    1571 | consumed samples:        86744 | consumed tokens:    177651712 | elapsed time per iteration (s): 78.53 | learning rate: 9.240E-05 | global batch size:   400 | lm loss: 5.839517E+00 | loss scale: 4096.0 | grad norm: 2606.024 | num zeros: 0.0 | params norm: 519.166 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.093 | TFLOPs: 53.78 |
 iteration      569/    1571 | consumed samples:        87144 | consumed tokens:    178470912 | elapsed time per iteration (s): 78.46 | learning rate: 9.233E-05 | global batch size:   400 | lm loss: 5.823762E+00 | loss scale: 4096.0 | grad norm: 2407.553 | num zeros: 0.0 | params norm: 519.188 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.098 | TFLOPs: 53.83 |
 iteration      570/    1571 | consumed samples:        87544 | consumed tokens:    179290112 | elapsed time per iteration (s): 78.55 | learning rate: 9.226E-05 | global batch size:   400 | lm loss: 5.809885E+00 | loss scale: 4096.0 | grad norm: 3876.172 | num zeros: 0.0 | params norm: 519.212 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.092 | TFLOPs: 53.77 |
 iteration      571/    1571 | consumed samples:        87944 | consumed tokens:    180109312 | elapsed time per iteration (s): 78.51 | learning rate: 9.218E-05 | global batch size:   400 | lm loss: 5.840275E+00 | loss scale: 4096.0 | grad norm: 5914.097 | num zeros: 0.0 | params norm: 519.233 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.095 | TFLOPs: 53.80 |
 iteration      572/    1571 | consumed samples:        88344 | consumed tokens:    180928512 | elapsed time per iteration (s): 78.53 | learning rate: 9.210E-05 | global batch size:   400 | lm loss: 5.795832E+00 | loss scale: 4096.0 | grad norm: 2944.227 | num zeros: 0.0 | params norm: 519.255 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.094 | TFLOPs: 53.78 |
 iteration      573/    1571 | consumed samples:        88744 | consumed tokens:    181747712 | elapsed time per iteration (s): 78.50 | learning rate: 9.203E-05 | global batch size:   400 | lm loss: 5.805827E+00 | loss scale: 4096.0 | grad norm: 3577.202 | num zeros: 0.0 | params norm: 519.278 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.096 | TFLOPs: 53.81 |
 iteration      574/    1571 | consumed samples:        89144 | consumed tokens:    182566912 | elapsed time per iteration (s): 78.59 | learning rate: 9.195E-05 | global batch size:   400 | lm loss: 5.812417E+00 | loss scale: 4096.0 | grad norm: 5260.045 | num zeros: 0.0 | params norm: 519.300 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.090 | TFLOPs: 53.74 |
 iteration      575/    1571 | consumed samples:        89544 | consumed tokens:    183386112 | elapsed time per iteration (s): 78.50 | learning rate: 9.188E-05 | global batch size:   400 | lm loss: 5.836052E+00 | loss scale: 4096.0 | grad norm: 5842.005 | num zeros: 0.0 | params norm: 519.323 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.096 | TFLOPs: 53.81 |
 iteration      576/    1571 | consumed samples:        89944 | consumed tokens:    184205312 | elapsed time per iteration (s): 78.59 | learning rate: 9.180E-05 | global batch size:   400 | lm loss: 5.796110E+00 | loss scale: 4096.0 | grad norm: 3924.325 | num zeros: 0.0 | params norm: 519.345 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.089 | TFLOPs: 53.74 |
 iteration      577/    1571 | consumed samples:        90344 | consumed tokens:    185024512 | elapsed time per iteration (s): 78.55 | learning rate: 9.172E-05 | global batch size:   400 | lm loss: 5.834415E+00 | loss scale: 4096.0 | grad norm: 5514.081 | num zeros: 0.0 | params norm: 519.367 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.092 | TFLOPs: 53.77 |
 iteration      578/    1571 | consumed samples:        90744 | consumed tokens:    185843712 | elapsed time per iteration (s): 78.61 | learning rate: 9.164E-05 | global batch size:   400 | lm loss: 5.807387E+00 | loss scale: 4096.0 | grad norm: 4649.768 | num zeros: 0.0 | params norm: 519.388 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.088 | TFLOPs: 53.73 |
 iteration      579/    1571 | consumed samples:        91144 | consumed tokens:    186662912 | elapsed time per iteration (s): 78.51 | learning rate: 9.157E-05 | global batch size:   400 | lm loss: 5.806315E+00 | loss scale: 4096.0 | grad norm: 4292.248 | num zeros: 0.0 | params norm: 519.411 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.095 | TFLOPs: 53.80 |
 iteration      580/    1571 | consumed samples:        91544 | consumed tokens:    187482112 | elapsed time per iteration (s): 78.59 | learning rate: 9.149E-05 | global batch size:   400 | lm loss: 5.830672E+00 | loss scale: 4096.0 | grad norm: 5607.420 | num zeros: 0.0 | params norm: 519.433 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.090 | TFLOPs: 53.74 |
 iteration      581/    1571 | consumed samples:        91944 | consumed tokens:    188301312 | elapsed time per iteration (s): 78.56 | learning rate: 9.141E-05 | global batch size:   400 | lm loss: 5.812669E+00 | loss scale: 4096.0 | grad norm: 4345.724 | num zeros: 0.0 | params norm: 519.455 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.092 | TFLOPs: 53.77 |
 iteration      582/    1571 | consumed samples:        92344 | consumed tokens:    189120512 | elapsed time per iteration (s): 78.62 | learning rate: 9.133E-05 | global batch size:   400 | lm loss: 5.813972E+00 | loss scale: 4096.0 | grad norm: 5119.249 | num zeros: 0.0 | params norm: 519.477 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.088 | TFLOPs: 53.73 |
 iteration      583/    1571 | consumed samples:        92744 | consumed tokens:    189939712 | elapsed time per iteration (s): 78.52 | learning rate: 9.125E-05 | global batch size:   400 | lm loss: 5.779924E+00 | loss scale: 4096.0 | grad norm: 4593.248 | num zeros: 0.0 | params norm: 519.499 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.094 | TFLOPs: 53.79 |
 iteration      584/    1571 | consumed samples:        93144 | consumed tokens:    190758912 | elapsed time per iteration (s): 78.60 | learning rate: 9.117E-05 | global batch size:   400 | lm loss: 5.793637E+00 | loss scale: 4096.0 | grad norm: 4131.436 | num zeros: 0.0 | params norm: 519.520 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.089 | TFLOPs: 53.73 |
 iteration      585/    1571 | consumed samples:        93544 | consumed tokens:    191578112 | elapsed time per iteration (s): 78.60 | learning rate: 9.109E-05 | global batch size:   400 | lm loss: 5.749227E+00 | loss scale: 4096.0 | grad norm: 3660.662 | num zeros: 0.0 | params norm: 519.543 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.089 | TFLOPs: 53.74 |
 iteration      586/    1571 | consumed samples:        93944 | consumed tokens:    192397312 | elapsed time per iteration (s): 78.57 | learning rate: 9.101E-05 | global batch size:   400 | lm loss: 5.777643E+00 | loss scale: 4096.0 | grad norm: 5109.099 | num zeros: 0.0 | params norm: 519.566 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.091 | TFLOPs: 53.75 |
 iteration      587/    1571 | consumed samples:        94344 | consumed tokens:    193216512 | elapsed time per iteration (s): 78.51 | learning rate: 9.093E-05 | global batch size:   400 | lm loss: 5.790553E+00 | loss scale: 4096.0 | grad norm: 2903.900 | num zeros: 0.0 | params norm: 519.588 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.095 | TFLOPs: 53.80 |
 iteration      588/    1571 | consumed samples:        94744 | consumed tokens:    194035712 | elapsed time per iteration (s): 78.54 | learning rate: 9.085E-05 | global batch size:   400 | lm loss: 5.766015E+00 | loss scale: 4096.0 | grad norm: 3238.236 | num zeros: 0.0 | params norm: 519.610 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.093 | TFLOPs: 53.78 |
 iteration      589/    1571 | consumed samples:        95144 | consumed tokens:    194854912 | elapsed time per iteration (s): 78.53 | learning rate: 9.077E-05 | global batch size:   400 | lm loss: 5.772118E+00 | loss scale: 4096.0 | grad norm: 3717.147 | num zeros: 0.0 | params norm: 519.631 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.094 | TFLOPs: 53.78 |
 iteration      590/    1571 | consumed samples:        95544 | consumed tokens:    195674112 | elapsed time per iteration (s): 78.63 | learning rate: 9.069E-05 | global batch size:   400 | lm loss: 5.772747E+00 | loss scale: 4096.0 | grad norm: 3954.389 | num zeros: 0.0 | params norm: 519.654 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.087 | TFLOPs: 53.72 |
 iteration      591/    1571 | consumed samples:        95944 | consumed tokens:    196493312 | elapsed time per iteration (s): 78.56 | learning rate: 9.061E-05 | global batch size:   400 | lm loss: 5.771669E+00 | loss scale: 4096.0 | grad norm: 4090.810 | num zeros: 0.0 | params norm: 519.676 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.092 | TFLOPs: 53.76 |
 iteration      592/    1571 | consumed samples:        96344 | consumed tokens:    197312512 | elapsed time per iteration (s): 78.58 | learning rate: 9.053E-05 | global batch size:   400 | lm loss: 5.777415E+00 | loss scale: 4096.0 | grad norm: 3949.680 | num zeros: 0.0 | params norm: 519.698 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.091 | TFLOPs: 53.75 |
 iteration      593/    1571 | consumed samples:        96744 | consumed tokens:    198131712 | elapsed time per iteration (s): 78.52 | learning rate: 9.044E-05 | global batch size:   400 | lm loss: 5.766681E+00 | loss scale: 4096.0 | grad norm: 4659.979 | num zeros: 0.0 | params norm: 519.720 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.094 | TFLOPs: 53.79 |
 iteration      594/    1571 | consumed samples:        97144 | consumed tokens:    198950912 | elapsed time per iteration (s): 78.55 | learning rate: 9.036E-05 | global batch size:   400 | lm loss: 5.745226E+00 | loss scale: 4096.0 | grad norm: 4067.527 | num zeros: 0.0 | params norm: 519.743 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.092 | TFLOPs: 53.77 |
 iteration      595/    1571 | consumed samples:        97544 | consumed tokens:    199770112 | elapsed time per iteration (s): 78.49 | learning rate: 9.028E-05 | global batch size:   400 | lm loss: 5.735108E+00 | loss scale: 4096.0 | grad norm: 3349.577 | num zeros: 0.0 | params norm: 519.765 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.096 | TFLOPs: 53.81 |
 iteration      596/    1571 | consumed samples:        97944 | consumed tokens:    200589312 | elapsed time per iteration (s): 78.54 | learning rate: 9.020E-05 | global batch size:   400 | lm loss: 5.764740E+00 | loss scale: 4096.0 | grad norm: 3979.290 | num zeros: 0.0 | params norm: 519.787 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.093 | TFLOPs: 53.77 |
 iteration      597/    1571 | consumed samples:        98344 | consumed tokens:    201408512 | elapsed time per iteration (s): 78.50 | learning rate: 9.011E-05 | global batch size:   400 | lm loss: 5.735066E+00 | loss scale: 4096.0 | grad norm: 4041.181 | num zeros: 0.0 | params norm: 519.810 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.095 | TFLOPs: 53.80 |
 iteration      598/    1571 | consumed samples:        98744 | consumed tokens:    202227712 | elapsed time per iteration (s): 78.56 | learning rate: 9.003E-05 | global batch size:   400 | lm loss: 5.740501E+00 | loss scale: 4096.0 | grad norm: 3495.459 | num zeros: 0.0 | params norm: 519.832 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.092 | TFLOPs: 53.76 |
 iteration      599/    1571 | consumed samples:        99144 | consumed tokens:    203046912 | elapsed time per iteration (s): 78.48 | learning rate: 8.994E-05 | global batch size:   400 | lm loss: 5.754977E+00 | loss scale: 4096.0 | grad norm: 4185.422 | num zeros: 0.0 | params norm: 519.855 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.097 | TFLOPs: 53.82 |
 iteration      600/    1571 | consumed samples:        99544 | consumed tokens:    203866112 | elapsed time per iteration (s): 78.51 | learning rate: 8.986E-05 | global batch size:   400 | lm loss: 5.733710E+00 | loss scale: 4096.0 | grad norm: 4723.673 | num zeros: 0.0 | params norm: 519.877 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.095 | TFLOPs: 53.80 |
 iteration      601/    1571 | consumed samples:        99944 | consumed tokens:    204685312 | elapsed time per iteration (s): 78.48 | learning rate: 8.978E-05 | global batch size:   400 | lm loss: 5.730067E+00 | loss scale: 4096.0 | grad norm: 3629.130 | num zeros: 0.0 | params norm: 519.899 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.097 | TFLOPs: 53.82 |
 iteration      602/    1571 | consumed samples:       100344 | consumed tokens:    205504512 | elapsed time per iteration (s): 78.57 | learning rate: 8.969E-05 | global batch size:   400 | lm loss: 5.716661E+00 | loss scale: 4096.0 | grad norm: 2498.093 | num zeros: 0.0 | params norm: 519.922 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.091 | TFLOPs: 53.75 |
 iteration      603/    1571 | consumed samples:       100744 | consumed tokens:    206323712 | elapsed time per iteration (s): 78.55 | learning rate: 8.960E-05 | global batch size:   400 | lm loss: 5.764297E+00 | loss scale: 4096.0 | grad norm: 3405.011 | num zeros: 0.0 | params norm: 519.944 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.092 | TFLOPs: 53.77 |
 iteration      604/    1571 | consumed samples:       101144 | consumed tokens:    207142912 | elapsed time per iteration (s): 78.58 | learning rate: 8.952E-05 | global batch size:   400 | lm loss: 5.721075E+00 | loss scale: 4096.0 | grad norm: 4149.207 | num zeros: 0.0 | params norm: 519.966 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.091 | TFLOPs: 53.75 |
 iteration      605/    1571 | consumed samples:       101544 | consumed tokens:    207962112 | elapsed time per iteration (s): 78.57 | learning rate: 8.943E-05 | global batch size:   400 | lm loss: 5.719557E+00 | loss scale: 4096.0 | grad norm: 4241.637 | num zeros: 0.0 | params norm: 519.988 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.091 | TFLOPs: 53.75 |
 iteration      606/    1571 | consumed samples:       101944 | consumed tokens:    208781312 | elapsed time per iteration (s): 78.61 | learning rate: 8.935E-05 | global batch size:   400 | lm loss: 5.705378E+00 | loss scale: 4096.0 | grad norm: 4234.905 | num zeros: 0.0 | params norm: 520.011 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.089 | TFLOPs: 53.73 |
 iteration      607/    1571 | consumed samples:       102344 | consumed tokens:    209600512 | elapsed time per iteration (s): 78.52 | learning rate: 8.926E-05 | global batch size:   400 | lm loss: 5.769572E+00 | loss scale: 4096.0 | grad norm: 5438.648 | num zeros: 0.0 | params norm: 520.033 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.094 | TFLOPs: 53.79 |
 iteration      608/    1571 | consumed samples:       102744 | consumed tokens:    210419712 | elapsed time per iteration (s): 78.56 | learning rate: 8.917E-05 | global batch size:   400 | lm loss: 5.733923E+00 | loss scale: 4096.0 | grad norm: 4698.705 | num zeros: 0.0 | params norm: 520.054 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.091 | TFLOPs: 53.76 |
 iteration      609/    1571 | consumed samples:       103144 | consumed tokens:    211238912 | elapsed time per iteration (s): 78.55 | learning rate: 8.909E-05 | global batch size:   400 | lm loss: 5.732556E+00 | loss scale: 4096.0 | grad norm: 4563.256 | num zeros: 0.0 | params norm: 520.077 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.092 | TFLOPs: 53.77 |
 iteration      610/    1571 | consumed samples:       103544 | consumed tokens:    212058112 | elapsed time per iteration (s): 78.54 | learning rate: 8.900E-05 | global batch size:   400 | lm loss: 5.719581E+00 | loss scale: 4096.0 | grad norm: 4548.471 | num zeros: 0.0 | params norm: 520.098 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.093 | TFLOPs: 53.78 |
 iteration      611/    1571 | consumed samples:       103944 | consumed tokens:    212877312 | elapsed time per iteration (s): 78.46 | learning rate: 8.891E-05 | global batch size:   400 | lm loss: 5.716544E+00 | loss scale: 4096.0 | grad norm: 4126.602 | num zeros: 0.0 | params norm: 520.121 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.098 | TFLOPs: 53.83 |
 iteration      612/    1571 | consumed samples:       104344 | consumed tokens:    213696512 | elapsed time per iteration (s): 78.50 | learning rate: 8.882E-05 | global batch size:   400 | lm loss: 5.713578E+00 | loss scale: 4096.0 | grad norm: 4691.645 | num zeros: 0.0 | params norm: 520.143 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.095 | TFLOPs: 53.80 |
 iteration      613/    1571 | consumed samples:       104744 | consumed tokens:    214515712 | elapsed time per iteration (s): 78.58 | learning rate: 8.873E-05 | global batch size:   400 | lm loss: 5.704751E+00 | loss scale: 4096.0 | grad norm: 4839.148 | num zeros: 0.0 | params norm: 520.164 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.090 | TFLOPs: 53.75 |
 iteration      614/    1571 | consumed samples:       105144 | consumed tokens:    215334912 | elapsed time per iteration (s): 78.55 | learning rate: 8.865E-05 | global batch size:   400 | lm loss: 5.679248E+00 | loss scale: 4096.0 | grad norm: 3745.859 | num zeros: 0.0 | params norm: 520.187 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.092 | TFLOPs: 53.77 |
 iteration      615/    1571 | consumed samples:       105544 | consumed tokens:    216154112 | elapsed time per iteration (s): 78.53 | learning rate: 8.856E-05 | global batch size:   400 | lm loss: 5.711969E+00 | loss scale: 4096.0 | grad norm: 5125.210 | num zeros: 0.0 | params norm: 520.208 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.094 | TFLOPs: 53.78 |
 iteration      616/    1571 | consumed samples:       105944 | consumed tokens:    216973312 | elapsed time per iteration (s): 78.62 | learning rate: 8.847E-05 | global batch size:   400 | lm loss: 5.729176E+00 | loss scale: 4096.0 | grad norm: 4579.714 | num zeros: 0.0 | params norm: 520.230 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.088 | TFLOPs: 53.73 |
 iteration      617/    1571 | consumed samples:       106344 | consumed tokens:    217792512 | elapsed time per iteration (s): 78.49 | learning rate: 8.838E-05 | global batch size:   400 | lm loss: 5.661316E+00 | loss scale: 4096.0 | grad norm: 4331.746 | num zeros: 0.0 | params norm: 520.252 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.096 | TFLOPs: 53.81 |
 iteration      618/    1571 | consumed samples:       106744 | consumed tokens:    218611712 | elapsed time per iteration (s): 78.55 | learning rate: 8.829E-05 | global batch size:   400 | lm loss: 5.735402E+00 | loss scale: 4096.0 | grad norm: 6067.526 | num zeros: 0.0 | params norm: 520.273 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.093 | TFLOPs: 53.77 |
 iteration      619/    1571 | consumed samples:       107144 | consumed tokens:    219430912 | elapsed time per iteration (s): 78.54 | learning rate: 8.820E-05 | global batch size:   400 | lm loss: 5.701988E+00 | loss scale: 4096.0 | grad norm: 3715.499 | num zeros: 0.0 | params norm: 520.294 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.093 | TFLOPs: 53.77 |
 iteration      620/    1571 | consumed samples:       107544 | consumed tokens:    220250112 | elapsed time per iteration (s): 78.56 | learning rate: 8.811E-05 | global batch size:   400 | lm loss: 5.708519E+00 | loss scale: 4096.0 | grad norm: 4430.816 | num zeros: 0.0 | params norm: 520.315 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.092 | TFLOPs: 53.77 |
 iteration      621/    1571 | consumed samples:       107944 | consumed tokens:    221069312 | elapsed time per iteration (s): 78.52 | learning rate: 8.802E-05 | global batch size:   400 | lm loss: 5.716811E+00 | loss scale: 4096.0 | grad norm: 3388.854 | num zeros: 0.0 | params norm: 520.337 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.094 | TFLOPs: 53.79 |
 iteration      622/    1571 | consumed samples:       108344 | consumed tokens:    221888512 | elapsed time per iteration (s): 78.65 | learning rate: 8.793E-05 | global batch size:   400 | lm loss: 5.704882E+00 | loss scale: 4096.0 | grad norm: 3989.103 | num zeros: 0.0 | params norm: 520.358 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.086 | TFLOPs: 53.71 |
 iteration      623/    1571 | consumed samples:       108744 | consumed tokens:    222707712 | elapsed time per iteration (s): 78.49 | learning rate: 8.783E-05 | global batch size:   400 | lm loss: 5.679828E+00 | loss scale: 4096.0 | grad norm: 3172.538 | num zeros: 0.0 | params norm: 520.380 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.096 | TFLOPs: 53.81 |
 iteration      624/    1571 | consumed samples:       109144 | consumed tokens:    223526912 | elapsed time per iteration (s): 78.56 | learning rate: 8.774E-05 | global batch size:   400 | lm loss: 5.694838E+00 | loss scale: 4096.0 | grad norm: 3147.675 | num zeros: 0.0 | params norm: 520.402 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.091 | TFLOPs: 53.76 |
 iteration      625/    1571 | consumed samples:       109544 | consumed tokens:    224346112 | elapsed time per iteration (s): 78.53 | learning rate: 8.765E-05 | global batch size:   400 | lm loss: 5.655127E+00 | loss scale: 4096.0 | grad norm: 3042.982 | num zeros: 0.0 | params norm: 520.424 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.094 | TFLOPs: 53.78 |
 iteration      626/    1571 | consumed samples:       109944 | consumed tokens:    225165312 | elapsed time per iteration (s): 78.54 | learning rate: 8.756E-05 | global batch size:   400 | lm loss: 5.667941E+00 | loss scale: 4096.0 | grad norm: 2932.279 | num zeros: 0.0 | params norm: 520.446 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.093 | TFLOPs: 53.78 |
 iteration      627/    1571 | consumed samples:       110344 | consumed tokens:    225984512 | elapsed time per iteration (s): 78.52 | learning rate: 8.747E-05 | global batch size:   400 | lm loss: 5.668555E+00 | loss scale: 4096.0 | grad norm: 2633.354 | num zeros: 0.0 | params norm: 520.469 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.094 | TFLOPs: 53.79 |
 iteration      628/    1571 | consumed samples:       110744 | consumed tokens:    226803712 | elapsed time per iteration (s): 78.61 | learning rate: 8.737E-05 | global batch size:   400 | lm loss: 5.633507E+00 | loss scale: 4096.0 | grad norm: 3697.756 | num zeros: 0.0 | params norm: 520.491 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.088 | TFLOPs: 53.73 |
 iteration      629/    1571 | consumed samples:       111144 | consumed tokens:    227622912 | elapsed time per iteration (s): 78.50 | learning rate: 8.728E-05 | global batch size:   400 | lm loss: 5.683469E+00 | loss scale: 4096.0 | grad norm: 4298.258 | num zeros: 0.0 | params norm: 520.514 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.095 | TFLOPs: 53.80 |
 iteration      630/    1571 | consumed samples:       111544 | consumed tokens:    228442112 | elapsed time per iteration (s): 78.55 | learning rate: 8.719E-05 | global batch size:   400 | lm loss: 5.665569E+00 | loss scale: 4096.0 | grad norm: 5002.821 | num zeros: 0.0 | params norm: 520.536 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.092 | TFLOPs: 53.77 |
 iteration      631/    1571 | consumed samples:       111944 | consumed tokens:    229261312 | elapsed time per iteration (s): 78.56 | learning rate: 8.709E-05 | global batch size:   400 | lm loss: 5.645094E+00 | loss scale: 4096.0 | grad norm: 3756.185 | num zeros: 0.0 | params norm: 520.558 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.091 | TFLOPs: 53.76 |
 iteration      632/    1571 | consumed samples:       112344 | consumed tokens:    230080512 | elapsed time per iteration (s): 78.46 | learning rate: 8.700E-05 | global batch size:   400 | lm loss: 5.646592E+00 | loss scale: 4096.0 | grad norm: 3946.123 | num zeros: 0.0 | params norm: 520.579 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.098 | TFLOPs: 53.83 |
 iteration      633/    1571 | consumed samples:       112744 | consumed tokens:    230899712 | elapsed time per iteration (s): 78.37 | learning rate: 8.691E-05 | global batch size:   400 | lm loss: 5.662194E+00 | loss scale: 4096.0 | grad norm: 5368.962 | num zeros: 0.0 | params norm: 520.601 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.104 | TFLOPs: 53.89 |
 iteration      634/    1571 | consumed samples:       113144 | consumed tokens:    231718912 | elapsed time per iteration (s): 78.54 | learning rate: 8.681E-05 | global batch size:   400 | lm loss: 5.648586E+00 | loss scale: 4096.0 | grad norm: 4813.754 | num zeros: 0.0 | params norm: 520.623 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.093 | TFLOPs: 53.78 |
 iteration      635/    1571 | consumed samples:       113544 | consumed tokens:    232538112 | elapsed time per iteration (s): 78.51 | learning rate: 8.672E-05 | global batch size:   400 | lm loss: 5.650178E+00 | loss scale: 4096.0 | grad norm: 5814.140 | num zeros: 0.0 | params norm: 520.644 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.095 | TFLOPs: 53.80 |
 iteration      636/    1571 | consumed samples:       113944 | consumed tokens:    233357312 | elapsed time per iteration (s): 78.49 | learning rate: 8.662E-05 | global batch size:   400 | lm loss: 5.624197E+00 | loss scale: 4096.0 | grad norm: 3258.948 | num zeros: 0.0 | params norm: 520.665 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.096 | TFLOPs: 53.81 |
 iteration      637/    1571 | consumed samples:       114344 | consumed tokens:    234176512 | elapsed time per iteration (s): 78.53 | learning rate: 8.653E-05 | global batch size:   400 | lm loss: 5.641713E+00 | loss scale: 4096.0 | grad norm: 3771.623 | num zeros: 0.0 | params norm: 520.687 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.094 | TFLOPs: 53.78 |
 iteration      638/    1571 | consumed samples:       114744 | consumed tokens:    234995712 | elapsed time per iteration (s): 78.48 | learning rate: 8.643E-05 | global batch size:   400 | lm loss: 5.635215E+00 | loss scale: 4096.0 | grad norm: 4057.592 | num zeros: 0.0 | params norm: 520.708 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.097 | TFLOPs: 53.82 |
 iteration      639/    1571 | consumed samples:       115144 | consumed tokens:    235814912 | elapsed time per iteration (s): 78.51 | learning rate: 8.633E-05 | global batch size:   400 | lm loss: 5.636326E+00 | loss scale: 4096.0 | grad norm: 5084.930 | num zeros: 0.0 | params norm: 520.730 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.095 | TFLOPs: 53.80 |
 iteration      640/    1571 | consumed samples:       115544 | consumed tokens:    236634112 | elapsed time per iteration (s): 78.56 | learning rate: 8.624E-05 | global batch size:   400 | lm loss: 5.633761E+00 | loss scale: 4096.0 | grad norm: 4079.686 | num zeros: 0.0 | params norm: 520.751 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.092 | TFLOPs: 53.77 |
 iteration      641/    1571 | consumed samples:       115944 | consumed tokens:    237453312 | elapsed time per iteration (s): 78.55 | learning rate: 8.614E-05 | global batch size:   400 | lm loss: 5.641412E+00 | loss scale: 4096.0 | grad norm: 4038.935 | num zeros: 0.0 | params norm: 520.773 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.093 | TFLOPs: 53.77 |
 iteration      642/    1571 | consumed samples:       116344 | consumed tokens:    238272512 | elapsed time per iteration (s): 78.59 | learning rate: 8.605E-05 | global batch size:   400 | lm loss: 5.631462E+00 | loss scale: 4096.0 | grad norm: 3151.795 | num zeros: 0.0 | params norm: 520.795 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.090 | TFLOPs: 53.75 |
 iteration      643/    1571 | consumed samples:       116744 | consumed tokens:    239091712 | elapsed time per iteration (s): 78.52 | learning rate: 8.595E-05 | global batch size:   400 | lm loss: 5.613757E+00 | loss scale: 4096.0 | grad norm: 3792.292 | num zeros: 0.0 | params norm: 520.817 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.094 | TFLOPs: 53.79 |
 iteration      644/    1571 | consumed samples:       117144 | consumed tokens:    239910912 | elapsed time per iteration (s): 78.58 | learning rate: 8.585E-05 | global batch size:   400 | lm loss: 5.642947E+00 | loss scale: 4096.0 | grad norm: 5300.197 | num zeros: 0.0 | params norm: 520.839 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.090 | TFLOPs: 53.75 |
 iteration      645/    1571 | consumed samples:       117544 | consumed tokens:    240730112 | elapsed time per iteration (s): 78.58 | learning rate: 8.575E-05 | global batch size:   400 | lm loss: 5.630333E+00 | loss scale: 4096.0 | grad norm: 4088.725 | num zeros: 0.0 | params norm: 520.861 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.090 | TFLOPs: 53.75 |
 iteration      646/    1571 | consumed samples:       117944 | consumed tokens:    241549312 | elapsed time per iteration (s): 78.49 | learning rate: 8.566E-05 | global batch size:   400 | lm loss: 5.608394E+00 | loss scale: 4096.0 | grad norm: 3566.044 | num zeros: 0.0 | params norm: 520.883 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.096 | TFLOPs: 53.81 |
 iteration      647/    1571 | consumed samples:       118344 | consumed tokens:    242368512 | elapsed time per iteration (s): 78.42 | learning rate: 8.556E-05 | global batch size:   400 | lm loss: 5.601306E+00 | loss scale: 4096.0 | grad norm: 3687.914 | num zeros: 0.0 | params norm: 520.905 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.101 | TFLOPs: 53.86 |
 iteration      648/    1571 | consumed samples:       118744 | consumed tokens:    243187712 | elapsed time per iteration (s): 78.58 | learning rate: 8.546E-05 | global batch size:   400 | lm loss: 5.592047E+00 | loss scale: 4096.0 | grad norm: 3712.777 | num zeros: 0.0 | params norm: 520.927 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.090 | TFLOPs: 53.75 |
 iteration      649/    1571 | consumed samples:       119144 | consumed tokens:    244006912 | elapsed time per iteration (s): 78.53 | learning rate: 8.536E-05 | global batch size:   400 | lm loss: 5.600927E+00 | loss scale: 4096.0 | grad norm: 3427.862 | num zeros: 0.0 | params norm: 520.950 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.093 | TFLOPs: 53.78 |
 iteration      650/    1571 | consumed samples:       119544 | consumed tokens:    244826112 | elapsed time per iteration (s): 78.64 | learning rate: 8.526E-05 | global batch size:   400 | lm loss: 5.610948E+00 | loss scale: 4096.0 | grad norm: 3791.291 | num zeros: 0.0 | params norm: 520.971 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.087 | TFLOPs: 53.71 |
 iteration      651/    1571 | consumed samples:       119944 | consumed tokens:    245645312 | elapsed time per iteration (s): 78.52 | learning rate: 8.516E-05 | global batch size:   400 | lm loss: 5.580597E+00 | loss scale: 4096.0 | grad norm: 4805.683 | num zeros: 0.0 | params norm: 520.994 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.094 | TFLOPs: 53.79 |
 iteration      652/    1571 | consumed samples:       120344 | consumed tokens:    246464512 | elapsed time per iteration (s): 78.55 | learning rate: 8.506E-05 | global batch size:   400 | lm loss: 5.569197E+00 | loss scale: 4096.0 | grad norm: 2806.002 | num zeros: 0.0 | params norm: 521.016 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.092 | TFLOPs: 53.77 |
 iteration      653/    1571 | consumed samples:       120744 | consumed tokens:    247283712 | elapsed time per iteration (s): 78.57 | learning rate: 8.496E-05 | global batch size:   400 | lm loss: 5.618290E+00 | loss scale: 4096.0 | grad norm: 3537.914 | num zeros: 0.0 | params norm: 521.038 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.091 | TFLOPs: 53.76 |
 iteration      654/    1571 | consumed samples:       121144 | consumed tokens:    248102912 | elapsed time per iteration (s): 78.60 | learning rate: 8.486E-05 | global batch size:   400 | lm loss: 5.607151E+00 | loss scale: 4096.0 | grad norm: 5616.835 | num zeros: 0.0 | params norm: 521.059 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.089 | TFLOPs: 53.74 |
 iteration      655/    1571 | consumed samples:       121544 | consumed tokens:    248922112 | elapsed time per iteration (s): 78.55 | learning rate: 8.476E-05 | global batch size:   400 | lm loss: 5.611000E+00 | loss scale: 4096.0 | grad norm: 3684.563 | num zeros: 0.0 | params norm: 521.081 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.092 | TFLOPs: 53.77 |
 iteration      656/    1571 | consumed samples:       121944 | consumed tokens:    249741312 | elapsed time per iteration (s): 78.53 | learning rate: 8.466E-05 | global batch size:   400 | lm loss: 5.591740E+00 | loss scale: 4096.0 | grad norm: 4024.803 | num zeros: 0.0 | params norm: 521.103 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.093 | TFLOPs: 53.78 |
 iteration      657/    1571 | consumed samples:       122344 | consumed tokens:    250560512 | elapsed time per iteration (s): 78.41 | learning rate: 8.456E-05 | global batch size:   400 | lm loss: 5.599404E+00 | loss scale: 8192.0 | grad norm: 4652.004 | num zeros: 0.0 | params norm: 521.124 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.101 | TFLOPs: 53.87 |
 iteration      658/    1571 | consumed samples:       122744 | consumed tokens:    251379712 | elapsed time per iteration (s): 78.65 | learning rate: 8.446E-05 | global batch size:   400 | lm loss: 5.584861E+00 | loss scale: 8192.0 | grad norm: 7078.069 | num zeros: 0.0 | params norm: 521.148 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.086 | TFLOPs: 53.70 |
 iteration      659/    1571 | consumed samples:       123144 | consumed tokens:    252198912 | elapsed time per iteration (s): 78.64 | learning rate: 8.436E-05 | global batch size:   400 | lm loss: 5.600135E+00 | loss scale: 8192.0 | grad norm: 9562.132 | num zeros: 0.0 | params norm: 521.172 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.086 | TFLOPs: 53.71 |
 iteration      660/    1571 | consumed samples:       123544 | consumed tokens:    253018112 | elapsed time per iteration (s): 78.67 | learning rate: 8.426E-05 | global batch size:   400 | lm loss: 5.583664E+00 | loss scale: 8192.0 | grad norm: 7164.027 | num zeros: 0.0 | params norm: 521.198 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.085 | TFLOPs: 53.69 |
 iteration      661/    1571 | consumed samples:       123944 | consumed tokens:    253837312 | elapsed time per iteration (s): 78.64 | learning rate: 8.416E-05 | global batch size:   400 | lm loss: 5.582310E+00 | loss scale: 8192.0 | grad norm: 7755.056 | num zeros: 0.0 | params norm: 521.224 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.086 | TFLOPs: 53.71 |
 iteration      662/    1571 | consumed samples:       124344 | consumed tokens:    254656512 | elapsed time per iteration (s): 78.66 | learning rate: 8.406E-05 | global batch size:   400 | lm loss: 5.567560E+00 | loss scale: 8192.0 | grad norm: 7893.103 | num zeros: 0.0 | params norm: 521.250 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.085 | TFLOPs: 53.70 |
 iteration      663/    1571 | consumed samples:       124744 | consumed tokens:    255475712 | elapsed time per iteration (s): 78.65 | learning rate: 8.395E-05 | global batch size:   400 | lm loss: 5.613689E+00 | loss scale: 8192.0 | grad norm: 6252.019 | num zeros: 0.0 | params norm: 521.277 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.086 | TFLOPs: 53.70 |
 iteration      664/    1571 | consumed samples:       125144 | consumed tokens:    256294912 | elapsed time per iteration (s): 78.62 | learning rate: 8.385E-05 | global batch size:   400 | lm loss: 5.561352E+00 | loss scale: 8192.0 | grad norm: 8013.861 | num zeros: 0.0 | params norm: 521.304 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.088 | TFLOPs: 53.72 |
 iteration      665/    1571 | consumed samples:       125544 | consumed tokens:    257114112 | elapsed time per iteration (s): 78.65 | learning rate: 8.375E-05 | global batch size:   400 | lm loss: 5.556696E+00 | loss scale: 8192.0 | grad norm: 8306.359 | num zeros: 0.0 | params norm: 521.331 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.086 | TFLOPs: 53.70 |
 iteration      666/    1571 | consumed samples:       125944 | consumed tokens:    257933312 | elapsed time per iteration (s): 78.72 | learning rate: 8.364E-05 | global batch size:   400 | lm loss: 5.594945E+00 | loss scale: 8192.0 | grad norm: 6569.241 | num zeros: 0.0 | params norm: 521.358 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      667/    1571 | consumed samples:       126344 | consumed tokens:    258752512 | elapsed time per iteration (s): 78.61 | learning rate: 8.354E-05 | global batch size:   400 | lm loss: 5.573091E+00 | loss scale: 8192.0 | grad norm: 8783.021 | num zeros: 0.0 | params norm: 521.383 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.088 | TFLOPs: 53.73 |
 iteration      668/    1571 | consumed samples:       126744 | consumed tokens:    259571712 | elapsed time per iteration (s): 78.66 | learning rate: 8.344E-05 | global batch size:   400 | lm loss: 5.562011E+00 | loss scale: 8192.0 | grad norm: 10002.258 | num zeros: 0.0 | params norm: 521.410 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.085 | TFLOPs: 53.69 |
 iteration      669/    1571 | consumed samples:       127144 | consumed tokens:    260390912 | elapsed time per iteration (s): 78.64 | learning rate: 8.333E-05 | global batch size:   400 | lm loss: 5.579944E+00 | loss scale: 8192.0 | grad norm: 9110.557 | num zeros: 0.0 | params norm: 521.436 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.086 | TFLOPs: 53.71 |
 iteration      670/    1571 | consumed samples:       127544 | consumed tokens:    261210112 | elapsed time per iteration (s): 78.64 | learning rate: 8.323E-05 | global batch size:   400 | lm loss: 5.543483E+00 | loss scale: 8192.0 | grad norm: 10841.639 | num zeros: 0.0 | params norm: 521.462 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.087 | TFLOPs: 53.71 |
 iteration      671/    1571 | consumed samples:       127944 | consumed tokens:    262029312 | elapsed time per iteration (s): 78.57 | learning rate: 8.313E-05 | global batch size:   400 | lm loss: 5.583719E+00 | loss scale: 8192.0 | grad norm: 8543.723 | num zeros: 0.0 | params norm: 521.488 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.091 | TFLOPs: 53.76 |
 iteration      672/    1571 | consumed samples:       128344 | consumed tokens:    262848512 | elapsed time per iteration (s): 78.66 | learning rate: 8.302E-05 | global batch size:   400 | lm loss: 5.527821E+00 | loss scale: 8192.0 | grad norm: 8175.996 | num zeros: 0.0 | params norm: 521.514 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.085 | TFLOPs: 53.70 |
 iteration      673/    1571 | consumed samples:       128744 | consumed tokens:    263667712 | elapsed time per iteration (s): 78.62 | learning rate: 8.292E-05 | global batch size:   400 | lm loss: 5.555463E+00 | loss scale: 8192.0 | grad norm: 8559.828 | num zeros: 0.0 | params norm: 521.538 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.088 | TFLOPs: 53.73 |
 iteration      674/    1571 | consumed samples:       129144 | consumed tokens:    264486912 | elapsed time per iteration (s): 78.64 | learning rate: 8.281E-05 | global batch size:   400 | lm loss: 5.523502E+00 | loss scale: 8192.0 | grad norm: 7914.118 | num zeros: 0.0 | params norm: 521.564 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.086 | TFLOPs: 53.71 |
 iteration      675/    1571 | consumed samples:       129544 | consumed tokens:    265306112 | elapsed time per iteration (s): 78.62 | learning rate: 8.271E-05 | global batch size:   400 | lm loss: 5.538276E+00 | loss scale: 8192.0 | grad norm: 6717.488 | num zeros: 0.0 | params norm: 521.589 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.088 | TFLOPs: 53.73 |
 iteration      676/    1571 | consumed samples:       129944 | consumed tokens:    266125312 | elapsed time per iteration (s): 78.64 | learning rate: 8.260E-05 | global batch size:   400 | lm loss: 5.537940E+00 | loss scale: 8192.0 | grad norm: 6459.133 | num zeros: 0.0 | params norm: 521.615 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.087 | TFLOPs: 53.71 |
 iteration      677/    1571 | consumed samples:       130344 | consumed tokens:    266944512 | elapsed time per iteration (s): 78.66 | learning rate: 8.250E-05 | global batch size:   400 | lm loss: 5.520485E+00 | loss scale: 8192.0 | grad norm: 6308.174 | num zeros: 0.0 | params norm: 521.641 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.085 | TFLOPs: 53.70 |
 iteration      678/    1571 | consumed samples:       130744 | consumed tokens:    267763712 | elapsed time per iteration (s): 78.65 | learning rate: 8.239E-05 | global batch size:   400 | lm loss: 5.541185E+00 | loss scale: 8192.0 | grad norm: 6528.032 | num zeros: 0.0 | params norm: 521.666 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.086 | TFLOPs: 53.70 |
 iteration      679/    1571 | consumed samples:       131144 | consumed tokens:    268582912 | elapsed time per iteration (s): 78.61 | learning rate: 8.228E-05 | global batch size:   400 | lm loss: 5.558352E+00 | loss scale: 8192.0 | grad norm: 8105.143 | num zeros: 0.0 | params norm: 521.691 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.089 | TFLOPs: 53.73 |
 iteration      680/    1571 | consumed samples:       131544 | consumed tokens:    269402112 | elapsed time per iteration (s): 78.66 | learning rate: 8.218E-05 | global batch size:   400 | lm loss: 5.540148E+00 | loss scale: 8192.0 | grad norm: 9767.238 | num zeros: 0.0 | params norm: 521.716 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.085 | TFLOPs: 53.70 |
 iteration      681/    1571 | consumed samples:       131944 | consumed tokens:    270221312 | elapsed time per iteration (s): 78.62 | learning rate: 8.207E-05 | global batch size:   400 | lm loss: 5.499671E+00 | loss scale: 8192.0 | grad norm: 9200.216 | num zeros: 0.0 | params norm: 521.741 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.088 | TFLOPs: 53.72 |
 iteration      682/    1571 | consumed samples:       132344 | consumed tokens:    271040512 | elapsed time per iteration (s): 78.72 | learning rate: 8.196E-05 | global batch size:   400 | lm loss: 5.521317E+00 | loss scale: 8192.0 | grad norm: 9289.794 | num zeros: 0.0 | params norm: 521.766 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.66 |
 iteration      683/    1571 | consumed samples:       132744 | consumed tokens:    271859712 | elapsed time per iteration (s): 78.61 | learning rate: 8.186E-05 | global batch size:   400 | lm loss: 5.519633E+00 | loss scale: 8192.0 | grad norm: 9642.999 | num zeros: 0.0 | params norm: 521.790 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.088 | TFLOPs: 53.73 |
 iteration      684/    1571 | consumed samples:       133144 | consumed tokens:    272678912 | elapsed time per iteration (s): 78.69 | learning rate: 8.175E-05 | global batch size:   400 | lm loss: 5.531512E+00 | loss scale: 8192.0 | grad norm: 9078.040 | num zeros: 0.0 | params norm: 521.814 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.68 |
 iteration      685/    1571 | consumed samples:       133544 | consumed tokens:    273498112 | elapsed time per iteration (s): 78.64 | learning rate: 8.164E-05 | global batch size:   400 | lm loss: 5.533692E+00 | loss scale: 8192.0 | grad norm: 10143.026 | num zeros: 0.0 | params norm: 521.838 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.087 | TFLOPs: 53.71 |
 iteration      686/    1571 | consumed samples:       133944 | consumed tokens:    274317312 | elapsed time per iteration (s): 78.65 | learning rate: 8.153E-05 | global batch size:   400 | lm loss: 5.528871E+00 | loss scale: 8192.0 | grad norm: 7694.920 | num zeros: 0.0 | params norm: 521.862 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.086 | TFLOPs: 53.70 |
 iteration      687/    1571 | consumed samples:       134344 | consumed tokens:    275136512 | elapsed time per iteration (s): 78.62 | learning rate: 8.142E-05 | global batch size:   400 | lm loss: 5.523383E+00 | loss scale: 8192.0 | grad norm: 7586.781 | num zeros: 0.0 | params norm: 521.885 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.088 | TFLOPs: 53.72 |
 iteration      688/    1571 | consumed samples:       134744 | consumed tokens:    275955712 | elapsed time per iteration (s): 78.65 | learning rate: 8.132E-05 | global batch size:   400 | lm loss: 5.527706E+00 | loss scale: 8192.0 | grad norm: 8846.224 | num zeros: 0.0 | params norm: 521.909 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.086 | TFLOPs: 53.70 |
 iteration      689/    1571 | consumed samples:       135144 | consumed tokens:    276774912 | elapsed time per iteration (s): 78.66 | learning rate: 8.121E-05 | global batch size:   400 | lm loss: 5.497006E+00 | loss scale: 8192.0 | grad norm: 9640.948 | num zeros: 0.0 | params norm: 521.932 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.085 | TFLOPs: 53.70 |
 iteration      690/    1571 | consumed samples:       135544 | consumed tokens:    277594112 | elapsed time per iteration (s): 78.64 | learning rate: 8.110E-05 | global batch size:   400 | lm loss: 5.515397E+00 | loss scale: 8192.0 | grad norm: 6843.978 | num zeros: 0.0 | params norm: 521.955 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.087 | TFLOPs: 53.71 |
 iteration      691/    1571 | consumed samples:       135944 | consumed tokens:    278413312 | elapsed time per iteration (s): 78.65 | learning rate: 8.099E-05 | global batch size:   400 | lm loss: 5.537150E+00 | loss scale: 8192.0 | grad norm: 5467.565 | num zeros: 0.0 | params norm: 521.979 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.086 | TFLOPs: 53.70 |
 iteration      692/    1571 | consumed samples:       136344 | consumed tokens:    279232512 | elapsed time per iteration (s): 78.73 | learning rate: 8.088E-05 | global batch size:   400 | lm loss: 5.502757E+00 | loss scale: 8192.0 | grad norm: 4715.273 | num zeros: 0.0 | params norm: 522.002 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      693/    1571 | consumed samples:       136744 | consumed tokens:    280051712 | elapsed time per iteration (s): 78.64 | learning rate: 8.077E-05 | global batch size:   400 | lm loss: 5.493550E+00 | loss scale: 8192.0 | grad norm: 5345.589 | num zeros: 0.0 | params norm: 522.026 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.087 | TFLOPs: 53.71 |
 iteration      694/    1571 | consumed samples:       137144 | consumed tokens:    280870912 | elapsed time per iteration (s): 78.70 | learning rate: 8.066E-05 | global batch size:   400 | lm loss: 5.505974E+00 | loss scale: 8192.0 | grad norm: 4870.090 | num zeros: 0.0 | params norm: 522.050 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration      695/    1571 | consumed samples:       137544 | consumed tokens:    281690112 | elapsed time per iteration (s): 78.66 | learning rate: 8.055E-05 | global batch size:   400 | lm loss: 5.510097E+00 | loss scale: 8192.0 | grad norm: 5979.018 | num zeros: 0.0 | params norm: 522.073 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.085 | TFLOPs: 53.69 |
 iteration      696/    1571 | consumed samples:       137944 | consumed tokens:    282509312 | elapsed time per iteration (s): 78.72 | learning rate: 8.044E-05 | global batch size:   400 | lm loss: 5.474274E+00 | loss scale: 8192.0 | grad norm: 7270.377 | num zeros: 0.0 | params norm: 522.097 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      697/    1571 | consumed samples:       138344 | consumed tokens:    283328512 | elapsed time per iteration (s): 78.60 | learning rate: 8.033E-05 | global batch size:   400 | lm loss: 5.477570E+00 | loss scale: 8192.0 | grad norm: 7914.395 | num zeros: 0.0 | params norm: 522.121 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.089 | TFLOPs: 53.74 |
 iteration      698/    1571 | consumed samples:       138744 | consumed tokens:    284147712 | elapsed time per iteration (s): 78.69 | learning rate: 8.022E-05 | global batch size:   400 | lm loss: 5.472422E+00 | loss scale: 8192.0 | grad norm: 7927.219 | num zeros: 0.0 | params norm: 522.144 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration      699/    1571 | consumed samples:       139144 | consumed tokens:    284966912 | elapsed time per iteration (s): 78.63 | learning rate: 8.011E-05 | global batch size:   400 | lm loss: 5.504676E+00 | loss scale: 8192.0 | grad norm: 9142.698 | num zeros: 0.0 | params norm: 522.167 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.087 | TFLOPs: 53.72 |
 iteration      700/    1571 | consumed samples:       139544 | consumed tokens:    285786112 | elapsed time per iteration (s): 78.71 | learning rate: 8.000E-05 | global batch size:   400 | lm loss: 5.513138E+00 | loss scale: 8192.0 | grad norm: 8232.902 | num zeros: 0.0 | params norm: 522.190 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.66 |
 iteration      701/    1571 | consumed samples:       139944 | consumed tokens:    286605312 | elapsed time per iteration (s): 78.64 | learning rate: 7.989E-05 | global batch size:   400 | lm loss: 5.487442E+00 | loss scale: 8192.0 | grad norm: 9036.646 | num zeros: 0.0 | params norm: 522.214 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.086 | TFLOPs: 53.71 |
 iteration      702/    1571 | consumed samples:       140344 | consumed tokens:    287424512 | elapsed time per iteration (s): 78.76 | learning rate: 7.977E-05 | global batch size:   400 | lm loss: 5.487578E+00 | loss scale: 8192.0 | grad norm: 9923.675 | num zeros: 0.0 | params norm: 522.237 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      703/    1571 | consumed samples:       140744 | consumed tokens:    288243712 | elapsed time per iteration (s): 78.63 | learning rate: 7.966E-05 | global batch size:   400 | lm loss: 5.477525E+00 | loss scale: 8192.0 | grad norm: 8525.296 | num zeros: 0.0 | params norm: 522.259 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.087 | TFLOPs: 53.71 |
 iteration      704/    1571 | consumed samples:       141144 | consumed tokens:    289062912 | elapsed time per iteration (s): 78.75 | learning rate: 7.955E-05 | global batch size:   400 | lm loss: 5.469748E+00 | loss scale: 8192.0 | grad norm: 9091.070 | num zeros: 0.0 | params norm: 522.282 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      705/    1571 | consumed samples:       141544 | consumed tokens:    289882112 | elapsed time per iteration (s): 78.61 | learning rate: 7.944E-05 | global batch size:   400 | lm loss: 5.443243E+00 | loss scale: 8192.0 | grad norm: 9043.976 | num zeros: 0.0 | params norm: 522.305 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.089 | TFLOPs: 53.73 |
 iteration      706/    1571 | consumed samples:       141944 | consumed tokens:    290701312 | elapsed time per iteration (s): 78.69 | learning rate: 7.933E-05 | global batch size:   400 | lm loss: 5.475442E+00 | loss scale: 8192.0 | grad norm: 6635.062 | num zeros: 0.0 | params norm: 522.328 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration      707/    1571 | consumed samples:       142344 | consumed tokens:    291520512 | elapsed time per iteration (s): 78.63 | learning rate: 7.921E-05 | global batch size:   400 | lm loss: 5.454735E+00 | loss scale: 8192.0 | grad norm: 6478.351 | num zeros: 0.0 | params norm: 522.351 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.087 | TFLOPs: 53.71 |
 iteration      708/    1571 | consumed samples:       142744 | consumed tokens:    292339712 | elapsed time per iteration (s): 78.71 | learning rate: 7.910E-05 | global batch size:   400 | lm loss: 5.478747E+00 | loss scale: 8192.0 | grad norm: 9648.473 | num zeros: 0.0 | params norm: 522.373 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.66 |
 iteration      709/    1571 | consumed samples:       143144 | consumed tokens:    293158912 | elapsed time per iteration (s): 78.68 | learning rate: 7.899E-05 | global batch size:   400 | lm loss: 5.460403E+00 | loss scale: 8192.0 | grad norm: 10934.572 | num zeros: 0.0 | params norm: 522.396 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.68 |
 iteration      710/    1571 | consumed samples:       143544 | consumed tokens:    293978112 | elapsed time per iteration (s): 78.67 | learning rate: 7.887E-05 | global batch size:   400 | lm loss: 5.441525E+00 | loss scale: 8192.0 | grad norm: 6866.516 | num zeros: 0.0 | params norm: 522.419 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.69 |
 iteration      711/    1571 | consumed samples:       143944 | consumed tokens:    294797312 | elapsed time per iteration (s): 78.63 | learning rate: 7.876E-05 | global batch size:   400 | lm loss: 5.459634E+00 | loss scale: 8192.0 | grad norm: 7983.778 | num zeros: 0.0 | params norm: 522.441 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.087 | TFLOPs: 53.71 |
 iteration      712/    1571 | consumed samples:       144344 | consumed tokens:    295616512 | elapsed time per iteration (s): 78.75 | learning rate: 7.865E-05 | global batch size:   400 | lm loss: 5.455821E+00 | loss scale: 8192.0 | grad norm: 7736.525 | num zeros: 0.0 | params norm: 522.464 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      713/    1571 | consumed samples:       144744 | consumed tokens:    296435712 | elapsed time per iteration (s): 78.68 | learning rate: 7.853E-05 | global batch size:   400 | lm loss: 5.457600E+00 | loss scale: 8192.0 | grad norm: 9272.363 | num zeros: 0.0 | params norm: 522.486 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.68 |
 iteration      714/    1571 | consumed samples:       145144 | consumed tokens:    297254912 | elapsed time per iteration (s): 78.68 | learning rate: 7.842E-05 | global batch size:   400 | lm loss: 5.434712E+00 | loss scale: 8192.0 | grad norm: 7832.645 | num zeros: 0.0 | params norm: 522.508 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.68 |
 iteration      715/    1571 | consumed samples:       145544 | consumed tokens:    298074112 | elapsed time per iteration (s): 78.70 | learning rate: 7.831E-05 | global batch size:   400 | lm loss: 5.448754E+00 | loss scale: 8192.0 | grad norm: 7320.265 | num zeros: 0.0 | params norm: 522.531 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration      716/    1571 | consumed samples:       145944 | consumed tokens:    298893312 | elapsed time per iteration (s): 78.72 | learning rate: 7.819E-05 | global batch size:   400 | lm loss: 5.448807E+00 | loss scale: 8192.0 | grad norm: 7841.280 | num zeros: 0.0 | params norm: 522.553 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.66 |
 iteration      717/    1571 | consumed samples:       146344 | consumed tokens:    299712512 | elapsed time per iteration (s): 78.68 | learning rate: 7.808E-05 | global batch size:   400 | lm loss: 5.456833E+00 | loss scale: 8192.0 | grad norm: 6705.246 | num zeros: 0.0 | params norm: 522.575 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.68 |
 iteration      718/    1571 | consumed samples:       146744 | consumed tokens:    300531712 | elapsed time per iteration (s): 78.66 | learning rate: 7.796E-05 | global batch size:   400 | lm loss: 5.449489E+00 | loss scale: 8192.0 | grad norm: 6833.459 | num zeros: 0.0 | params norm: 522.598 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.085 | TFLOPs: 53.69 |
 iteration      719/    1571 | consumed samples:       147144 | consumed tokens:    301350912 | elapsed time per iteration (s): 78.68 | learning rate: 7.785E-05 | global batch size:   400 | lm loss: 5.420189E+00 | loss scale: 8192.0 | grad norm: 7236.606 | num zeros: 0.0 | params norm: 522.620 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.68 |
 iteration      720/    1571 | consumed samples:       147544 | consumed tokens:    302170112 | elapsed time per iteration (s): 78.73 | learning rate: 7.773E-05 | global batch size:   400 | lm loss: 5.420108E+00 | loss scale: 8192.0 | grad norm: 6608.325 | num zeros: 0.0 | params norm: 522.643 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      721/    1571 | consumed samples:       147944 | consumed tokens:    302989312 | elapsed time per iteration (s): 78.68 | learning rate: 7.761E-05 | global batch size:   400 | lm loss: 5.431127E+00 | loss scale: 8192.0 | grad norm: 6574.665 | num zeros: 0.0 | params norm: 522.666 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.68 |
 iteration      722/    1571 | consumed samples:       148344 | consumed tokens:    303808512 | elapsed time per iteration (s): 78.66 | learning rate: 7.750E-05 | global batch size:   400 | lm loss: 5.443569E+00 | loss scale: 8192.0 | grad norm: 8801.418 | num zeros: 0.0 | params norm: 522.689 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.085 | TFLOPs: 53.69 |
 iteration      723/    1571 | consumed samples:       148744 | consumed tokens:    304627712 | elapsed time per iteration (s): 78.61 | learning rate: 7.738E-05 | global batch size:   400 | lm loss: 5.431494E+00 | loss scale: 8192.0 | grad norm: 8515.121 | num zeros: 0.0 | params norm: 522.712 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.089 | TFLOPs: 53.73 |
 iteration      724/    1571 | consumed samples:       149144 | consumed tokens:    305446912 | elapsed time per iteration (s): 78.60 | learning rate: 7.727E-05 | global batch size:   400 | lm loss: 5.411264E+00 | loss scale: 8192.0 | grad norm: 7972.716 | num zeros: 0.0 | params norm: 522.735 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.089 | TFLOPs: 53.73 |
 iteration      725/    1571 | consumed samples:       149544 | consumed tokens:    306266112 | elapsed time per iteration (s): 78.55 | learning rate: 7.715E-05 | global batch size:   400 | lm loss: 5.420532E+00 | loss scale: 8192.0 | grad norm: 7734.966 | num zeros: 0.0 | params norm: 522.757 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.092 | TFLOPs: 53.77 |
 iteration      726/    1571 | consumed samples:       149944 | consumed tokens:    307085312 | elapsed time per iteration (s): 78.61 | learning rate: 7.703E-05 | global batch size:   400 | lm loss: 5.412051E+00 | loss scale: 8192.0 | grad norm: 7573.163 | num zeros: 0.0 | params norm: 522.779 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.088 | TFLOPs: 53.73 |
 iteration      727/    1571 | consumed samples:       150344 | consumed tokens:    307904512 | elapsed time per iteration (s): 78.55 | learning rate: 7.692E-05 | global batch size:   400 | lm loss: 5.400232E+00 | loss scale: 8192.0 | grad norm: 8100.430 | num zeros: 0.0 | params norm: 522.802 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.092 | TFLOPs: 53.77 |
 iteration      728/    1571 | consumed samples:       150744 | consumed tokens:    308723712 | elapsed time per iteration (s): 78.60 | learning rate: 7.680E-05 | global batch size:   400 | lm loss: 5.427722E+00 | loss scale: 8192.0 | grad norm: 8504.500 | num zeros: 0.0 | params norm: 522.824 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.089 | TFLOPs: 53.74 |
 iteration      729/    1571 | consumed samples:       151144 | consumed tokens:    309542912 | elapsed time per iteration (s): 78.53 | learning rate: 7.668E-05 | global batch size:   400 | lm loss: 5.383980E+00 | loss scale: 8192.0 | grad norm: 6812.548 | num zeros: 0.0 | params norm: 522.846 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.094 | TFLOPs: 53.79 |
 iteration      730/    1571 | consumed samples:       151544 | consumed tokens:    310362112 | elapsed time per iteration (s): 78.62 | learning rate: 7.657E-05 | global batch size:   400 | lm loss: 5.419603E+00 | loss scale: 8192.0 | grad norm: 9364.068 | num zeros: 0.0 | params norm: 522.868 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.088 | TFLOPs: 53.73 |
 iteration      731/    1571 | consumed samples:       151944 | consumed tokens:    311181312 | elapsed time per iteration (s): 78.61 | learning rate: 7.645E-05 | global batch size:   400 | lm loss: 5.430725E+00 | loss scale: 8192.0 | grad norm: 8024.136 | num zeros: 0.0 | params norm: 522.890 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.088 | TFLOPs: 53.73 |
 iteration      732/    1571 | consumed samples:       152344 | consumed tokens:    312000512 | elapsed time per iteration (s): 78.69 | learning rate: 7.633E-05 | global batch size:   400 | lm loss: 5.402742E+00 | loss scale: 8192.0 | grad norm: 6736.228 | num zeros: 0.0 | params norm: 522.912 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration      733/    1571 | consumed samples:       152744 | consumed tokens:    312819712 | elapsed time per iteration (s): 78.66 | learning rate: 7.621E-05 | global batch size:   400 | lm loss: 5.384267E+00 | loss scale: 8192.0 | grad norm: 7942.053 | num zeros: 0.0 | params norm: 522.934 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.085 | TFLOPs: 53.69 |
 iteration      734/    1571 | consumed samples:       153144 | consumed tokens:    313638912 | elapsed time per iteration (s): 78.77 | learning rate: 7.610E-05 | global batch size:   400 | lm loss: 5.388535E+00 | loss scale: 8192.0 | grad norm: 9012.098 | num zeros: 0.0 | params norm: 522.956 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      735/    1571 | consumed samples:       153544 | consumed tokens:    314458112 | elapsed time per iteration (s): 78.59 | learning rate: 7.598E-05 | global batch size:   400 | lm loss: 5.396556E+00 | loss scale: 8192.0 | grad norm: 8874.296 | num zeros: 0.0 | params norm: 522.978 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.090 | TFLOPs: 53.74 |
 iteration      736/    1571 | consumed samples:       153944 | consumed tokens:    315277312 | elapsed time per iteration (s): 78.61 | learning rate: 7.586E-05 | global batch size:   400 | lm loss: 5.384102E+00 | loss scale: 8192.0 | grad norm: 8163.419 | num zeros: 0.0 | params norm: 522.999 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.089 | TFLOPs: 53.73 |
 iteration      737/    1571 | consumed samples:       154344 | consumed tokens:    316096512 | elapsed time per iteration (s): 78.65 | learning rate: 7.574E-05 | global batch size:   400 | lm loss: 5.395322E+00 | loss scale: 8192.0 | grad norm: 8688.145 | num zeros: 0.0 | params norm: 523.021 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.086 | TFLOPs: 53.70 |
 iteration      738/    1571 | consumed samples:       154744 | consumed tokens:    316915712 | elapsed time per iteration (s): 78.78 | learning rate: 7.562E-05 | global batch size:   400 | lm loss: 5.383597E+00 | loss scale: 8192.0 | grad norm: 8591.895 | num zeros: 0.0 | params norm: 523.042 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      739/    1571 | consumed samples:       155144 | consumed tokens:    317734912 | elapsed time per iteration (s): 78.64 | learning rate: 7.550E-05 | global batch size:   400 | lm loss: 5.366301E+00 | loss scale: 8192.0 | grad norm: 9951.447 | num zeros: 0.0 | params norm: 523.064 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.086 | TFLOPs: 53.71 |
 iteration      740/    1571 | consumed samples:       155544 | consumed tokens:    318554112 | elapsed time per iteration (s): 78.73 | learning rate: 7.538E-05 | global batch size:   400 | lm loss: 5.372612E+00 | loss scale: 8192.0 | grad norm: 7716.426 | num zeros: 0.0 | params norm: 523.085 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      741/    1571 | consumed samples:       155944 | consumed tokens:    319373312 | elapsed time per iteration (s): 78.68 | learning rate: 7.526E-05 | global batch size:   400 | lm loss: 5.366899E+00 | loss scale: 8192.0 | grad norm: 6603.927 | num zeros: 0.0 | params norm: 523.107 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.68 |
 iteration      742/    1571 | consumed samples:       156344 | consumed tokens:    320192512 | elapsed time per iteration (s): 78.80 | learning rate: 7.514E-05 | global batch size:   400 | lm loss: 5.370554E+00 | loss scale: 8192.0 | grad norm: 5567.256 | num zeros: 0.0 | params norm: 523.129 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration      743/    1571 | consumed samples:       156744 | consumed tokens:    321011712 | elapsed time per iteration (s): 78.67 | learning rate: 7.502E-05 | global batch size:   400 | lm loss: 5.373904E+00 | loss scale: 8192.0 | grad norm: 7013.434 | num zeros: 0.0 | params norm: 523.150 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.69 |
 iteration      744/    1571 | consumed samples:       157144 | consumed tokens:    321830912 | elapsed time per iteration (s): 78.69 | learning rate: 7.490E-05 | global batch size:   400 | lm loss: 5.399835E+00 | loss scale: 8192.0 | grad norm: 8712.082 | num zeros: 0.0 | params norm: 523.172 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.68 |
 iteration      745/    1571 | consumed samples:       157544 | consumed tokens:    322650112 | elapsed time per iteration (s): 78.66 | learning rate: 7.478E-05 | global batch size:   400 | lm loss: 5.342740E+00 | loss scale: 8192.0 | grad norm: 9227.457 | num zeros: 0.0 | params norm: 523.193 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.085 | TFLOPs: 53.69 |
 iteration      746/    1571 | consumed samples:       157944 | consumed tokens:    323469312 | elapsed time per iteration (s): 78.77 | learning rate: 7.466E-05 | global batch size:   400 | lm loss: 5.366161E+00 | loss scale: 8192.0 | grad norm: 8163.606 | num zeros: 0.0 | params norm: 523.215 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      747/    1571 | consumed samples:       158344 | consumed tokens:    324288512 | elapsed time per iteration (s): 78.67 | learning rate: 7.454E-05 | global batch size:   400 | lm loss: 5.395374E+00 | loss scale: 8192.0 | grad norm: 11197.660 | num zeros: 0.0 | params norm: 523.235 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.085 | TFLOPs: 53.69 |
 iteration      748/    1571 | consumed samples:       158744 | consumed tokens:    325107712 | elapsed time per iteration (s): 78.65 | learning rate: 7.442E-05 | global batch size:   400 | lm loss: 5.366151E+00 | loss scale: 8192.0 | grad norm: 6092.564 | num zeros: 0.0 | params norm: 523.256 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.086 | TFLOPs: 53.71 |
 iteration      749/    1571 | consumed samples:       159144 | consumed tokens:    325926912 | elapsed time per iteration (s): 78.60 | learning rate: 7.430E-05 | global batch size:   400 | lm loss: 5.359134E+00 | loss scale: 8192.0 | grad norm: 5267.431 | num zeros: 0.0 | params norm: 523.277 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.089 | TFLOPs: 53.74 |
 iteration      750/    1571 | consumed samples:       159544 | consumed tokens:    326746112 | elapsed time per iteration (s): 78.65 | learning rate: 7.418E-05 | global batch size:   400 | lm loss: 5.319335E+00 | loss scale: 8192.0 | grad norm: 6106.648 | num zeros: 0.0 | params norm: 523.299 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.086 | TFLOPs: 53.70 |
 iteration      751/    1571 | consumed samples:       159944 | consumed tokens:    327565312 | elapsed time per iteration (s): 78.64 | learning rate: 7.406E-05 | global batch size:   400 | lm loss: 5.344625E+00 | loss scale: 8192.0 | grad norm: 6390.415 | num zeros: 0.0 | params norm: 523.321 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.086 | TFLOPs: 53.71 |
 iteration      752/    1571 | consumed samples:       160344 | consumed tokens:    328384512 | elapsed time per iteration (s): 78.71 | learning rate: 7.394E-05 | global batch size:   400 | lm loss: 5.354699E+00 | loss scale: 8192.0 | grad norm: 6687.854 | num zeros: 0.0 | params norm: 523.342 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.66 |
 iteration      753/    1571 | consumed samples:       160744 | consumed tokens:    329203712 | elapsed time per iteration (s): 78.70 | learning rate: 7.382E-05 | global batch size:   400 | lm loss: 5.362162E+00 | loss scale: 8192.0 | grad norm: 8032.788 | num zeros: 0.0 | params norm: 523.363 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration      754/    1571 | consumed samples:       161144 | consumed tokens:    330022912 | elapsed time per iteration (s): 78.67 | learning rate: 7.370E-05 | global batch size:   400 | lm loss: 5.353518E+00 | loss scale: 8192.0 | grad norm: 9973.666 | num zeros: 0.0 | params norm: 523.384 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.69 |
 iteration      755/    1571 | consumed samples:       161544 | consumed tokens:    330842112 | elapsed time per iteration (s): 78.67 | learning rate: 7.357E-05 | global batch size:   400 | lm loss: 5.376160E+00 | loss scale: 8192.0 | grad norm: 7586.784 | num zeros: 0.0 | params norm: 523.405 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.69 |
 iteration      756/    1571 | consumed samples:       161944 | consumed tokens:    331661312 | elapsed time per iteration (s): 78.77 | learning rate: 7.345E-05 | global batch size:   400 | lm loss: 5.343752E+00 | loss scale: 8192.0 | grad norm: 8370.081 | num zeros: 0.0 | params norm: 523.426 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      757/    1571 | consumed samples:       162344 | consumed tokens:    332480512 | elapsed time per iteration (s): 78.63 | learning rate: 7.333E-05 | global batch size:   400 | lm loss: 5.350762E+00 | loss scale: 8192.0 | grad norm: 8921.913 | num zeros: 0.0 | params norm: 523.447 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.087 | TFLOPs: 53.71 |
 iteration      758/    1571 | consumed samples:       162744 | consumed tokens:    333299712 | elapsed time per iteration (s): 78.71 | learning rate: 7.321E-05 | global batch size:   400 | lm loss: 5.323729E+00 | loss scale: 8192.0 | grad norm: 7901.306 | num zeros: 0.0 | params norm: 523.468 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.66 |
 iteration      759/    1571 | consumed samples:       163144 | consumed tokens:    334118912 | elapsed time per iteration (s): 78.61 | learning rate: 7.309E-05 | global batch size:   400 | lm loss: 5.349549E+00 | loss scale: 8192.0 | grad norm: 8733.419 | num zeros: 0.0 | params norm: 523.489 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.088 | TFLOPs: 53.73 |
 iteration      760/    1571 | consumed samples:       163544 | consumed tokens:    334938112 | elapsed time per iteration (s): 78.72 | learning rate: 7.296E-05 | global batch size:   400 | lm loss: 5.329591E+00 | loss scale: 8192.0 | grad norm: 7356.039 | num zeros: 0.0 | params norm: 523.510 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      761/    1571 | consumed samples:       163944 | consumed tokens:    335757312 | elapsed time per iteration (s): 78.66 | learning rate: 7.284E-05 | global batch size:   400 | lm loss: 5.349992E+00 | loss scale: 8192.0 | grad norm: 7869.053 | num zeros: 0.0 | params norm: 523.532 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.085 | TFLOPs: 53.69 |
 iteration      762/    1571 | consumed samples:       164344 | consumed tokens:    336576512 | elapsed time per iteration (s): 78.75 | learning rate: 7.272E-05 | global batch size:   400 | lm loss: 5.338010E+00 | loss scale: 8192.0 | grad norm: 6553.293 | num zeros: 0.0 | params norm: 523.553 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration      763/    1571 | consumed samples:       164744 | consumed tokens:    337395712 | elapsed time per iteration (s): 78.65 | learning rate: 7.260E-05 | global batch size:   400 | lm loss: 5.338980E+00 | loss scale: 8192.0 | grad norm: 5919.714 | num zeros: 0.0 | params norm: 523.575 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.086 | TFLOPs: 53.70 |
 iteration      764/    1571 | consumed samples:       165144 | consumed tokens:    338214912 | elapsed time per iteration (s): 78.73 | learning rate: 7.247E-05 | global batch size:   400 | lm loss: 5.323552E+00 | loss scale: 8192.0 | grad norm: 5915.140 | num zeros: 0.0 | params norm: 523.596 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.65 |
 iteration      765/    1571 | consumed samples:       165544 | consumed tokens:    339034112 | elapsed time per iteration (s): 78.73 | learning rate: 7.235E-05 | global batch size:   400 | lm loss: 5.312034E+00 | loss scale: 8192.0 | grad norm: 6293.491 | num zeros: 0.0 | params norm: 523.618 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      766/    1571 | consumed samples:       165944 | consumed tokens:    339853312 | elapsed time per iteration (s): 78.70 | learning rate: 7.223E-05 | global batch size:   400 | lm loss: 5.298020E+00 | loss scale: 8192.0 | grad norm: 7289.513 | num zeros: 0.0 | params norm: 523.639 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.67 |
 iteration      767/    1571 | consumed samples:       166344 | consumed tokens:    340672512 | elapsed time per iteration (s): 78.70 | learning rate: 7.210E-05 | global batch size:   400 | lm loss: 5.326919E+00 | loss scale: 8192.0 | grad norm: 9194.997 | num zeros: 0.0 | params norm: 523.660 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.67 |
 iteration      768/    1571 | consumed samples:       166744 | consumed tokens:    341491712 | elapsed time per iteration (s): 78.71 | learning rate: 7.198E-05 | global batch size:   400 | lm loss: 5.319770E+00 | loss scale: 8192.0 | grad norm: 9631.414 | num zeros: 0.0 | params norm: 523.681 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.66 |
 iteration      769/    1571 | consumed samples:       167144 | consumed tokens:    342310912 | elapsed time per iteration (s): 78.74 | learning rate: 7.185E-05 | global batch size:   400 | lm loss: 5.296933E+00 | loss scale: 8192.0 | grad norm: 7959.916 | num zeros: 0.0 | params norm: 523.702 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration      770/    1571 | consumed samples:       167544 | consumed tokens:    343130112 | elapsed time per iteration (s): 78.82 | learning rate: 7.173E-05 | global batch size:   400 | lm loss: 5.296957E+00 | loss scale: 8192.0 | grad norm: 7990.111 | num zeros: 0.0 | params norm: 523.723 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration      771/    1571 | consumed samples:       167944 | consumed tokens:    343949312 | elapsed time per iteration (s): 78.68 | learning rate: 7.161E-05 | global batch size:   400 | lm loss: 5.313825E+00 | loss scale: 8192.0 | grad norm: 7582.085 | num zeros: 0.0 | params norm: 523.745 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.68 |
 iteration      772/    1571 | consumed samples:       168344 | consumed tokens:    344768512 | elapsed time per iteration (s): 78.79 | learning rate: 7.148E-05 | global batch size:   400 | lm loss: 5.335895E+00 | loss scale: 8192.0 | grad norm: 10015.292 | num zeros: 0.0 | params norm: 523.765 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration      773/    1571 | consumed samples:       168744 | consumed tokens:    345587712 | elapsed time per iteration (s): 78.75 | learning rate: 7.136E-05 | global batch size:   400 | lm loss: 5.319990E+00 | loss scale: 8192.0 | grad norm: 8637.539 | num zeros: 0.0 | params norm: 523.786 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration      774/    1571 | consumed samples:       169144 | consumed tokens:    346406912 | elapsed time per iteration (s): 78.70 | learning rate: 7.123E-05 | global batch size:   400 | lm loss: 5.313255E+00 | loss scale: 8192.0 | grad norm: 8906.961 | num zeros: 0.0 | params norm: 523.807 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.67 |
 iteration      775/    1571 | consumed samples:       169544 | consumed tokens:    347226112 | elapsed time per iteration (s): 78.69 | learning rate: 7.111E-05 | global batch size:   400 | lm loss: 5.307564E+00 | loss scale: 8192.0 | grad norm: 7519.269 | num zeros: 0.0 | params norm: 523.828 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.68 |
 iteration      776/    1571 | consumed samples:       169944 | consumed tokens:    348045312 | elapsed time per iteration (s): 78.68 | learning rate: 7.098E-05 | global batch size:   400 | lm loss: 5.321605E+00 | loss scale: 8192.0 | grad norm: 6308.827 | num zeros: 0.0 | params norm: 523.848 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.68 |
 iteration      777/    1571 | consumed samples:       170344 | consumed tokens:    348864512 | elapsed time per iteration (s): 78.66 | learning rate: 7.086E-05 | global batch size:   400 | lm loss: 5.268560E+00 | loss scale: 8192.0 | grad norm: 5252.691 | num zeros: 0.0 | params norm: 523.870 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.085 | TFLOPs: 53.69 |
 iteration      778/    1571 | consumed samples:       170744 | consumed tokens:    349683712 | elapsed time per iteration (s): 78.77 | learning rate: 7.073E-05 | global batch size:   400 | lm loss: 5.293189E+00 | loss scale: 8192.0 | grad norm: 5599.723 | num zeros: 0.0 | params norm: 523.891 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      779/    1571 | consumed samples:       171144 | consumed tokens:    350502912 | elapsed time per iteration (s): 78.70 | learning rate: 7.061E-05 | global batch size:   400 | lm loss: 5.280656E+00 | loss scale: 8192.0 | grad norm: 6536.396 | num zeros: 0.0 | params norm: 523.912 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration      780/    1571 | consumed samples:       171544 | consumed tokens:    351322112 | elapsed time per iteration (s): 78.68 | learning rate: 7.048E-05 | global batch size:   400 | lm loss: 5.284695E+00 | loss scale: 8192.0 | grad norm: 7692.838 | num zeros: 0.0 | params norm: 523.933 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.68 |
 iteration      781/    1571 | consumed samples:       171944 | consumed tokens:    352141312 | elapsed time per iteration (s): 78.68 | learning rate: 7.036E-05 | global batch size:   400 | lm loss: 5.301001E+00 | loss scale: 8192.0 | grad norm: 8724.277 | num zeros: 0.0 | params norm: 523.954 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.68 |
 iteration      782/    1571 | consumed samples:       172344 | consumed tokens:    352960512 | elapsed time per iteration (s): 78.78 | learning rate: 7.023E-05 | global batch size:   400 | lm loss: 5.291398E+00 | loss scale: 8192.0 | grad norm: 10508.484 | num zeros: 0.0 | params norm: 523.975 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration      783/    1571 | consumed samples:       172744 | consumed tokens:    353779712 | elapsed time per iteration (s): 78.62 | learning rate: 7.010E-05 | global batch size:   400 | lm loss: 5.252231E+00 | loss scale: 8192.0 | grad norm: 9971.621 | num zeros: 0.0 | params norm: 523.995 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.088 | TFLOPs: 53.72 |
 iteration      784/    1571 | consumed samples:       173144 | consumed tokens:    354598912 | elapsed time per iteration (s): 78.62 | learning rate: 6.998E-05 | global batch size:   400 | lm loss: 5.290768E+00 | loss scale: 8192.0 | grad norm: 8809.950 | num zeros: 0.0 | params norm: 524.015 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.088 | TFLOPs: 53.72 |
 iteration      785/    1571 | consumed samples:       173544 | consumed tokens:    355418112 | elapsed time per iteration (s): 78.59 | learning rate: 6.985E-05 | global batch size:   400 | lm loss: 5.283727E+00 | loss scale: 8192.0 | grad norm: 9055.140 | num zeros: 0.0 | params norm: 524.036 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.090 | TFLOPs: 53.74 |
 iteration      786/    1571 | consumed samples:       173944 | consumed tokens:    356237312 | elapsed time per iteration (s): 78.60 | learning rate: 6.972E-05 | global batch size:   400 | lm loss: 5.319819E+00 | loss scale: 8192.0 | grad norm: 7675.281 | num zeros: 0.0 | params norm: 524.056 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.089 | TFLOPs: 53.73 |
 iteration      787/    1571 | consumed samples:       174344 | consumed tokens:    357056512 | elapsed time per iteration (s): 78.59 | learning rate: 6.960E-05 | global batch size:   400 | lm loss: 5.259534E+00 | loss scale: 8192.0 | grad norm: 8150.068 | num zeros: 0.0 | params norm: 524.076 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.090 | TFLOPs: 53.74 |
 iteration      788/    1571 | consumed samples:       174744 | consumed tokens:    357875712 | elapsed time per iteration (s): 78.72 | learning rate: 6.947E-05 | global batch size:   400 | lm loss: 5.268387E+00 | loss scale: 8192.0 | grad norm: 6986.717 | num zeros: 0.0 | params norm: 524.097 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.66 |
 iteration      789/    1571 | consumed samples:       175144 | consumed tokens:    358694912 | elapsed time per iteration (s): 78.75 | learning rate: 6.935E-05 | global batch size:   400 | lm loss: 5.269732E+00 | loss scale: 8192.0 | grad norm: 5639.850 | num zeros: 0.0 | params norm: 524.117 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      790/    1571 | consumed samples:       175544 | consumed tokens:    359514112 | elapsed time per iteration (s): 78.66 | learning rate: 6.922E-05 | global batch size:   400 | lm loss: 5.261867E+00 | loss scale: 8192.0 | grad norm: 6052.164 | num zeros: 0.0 | params norm: 524.138 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.085 | TFLOPs: 53.69 |
 iteration      791/    1571 | consumed samples:       175944 | consumed tokens:    360333312 | elapsed time per iteration (s): 78.62 | learning rate: 6.909E-05 | global batch size:   400 | lm loss: 5.281673E+00 | loss scale: 8192.0 | grad norm: 6441.804 | num zeros: 0.0 | params norm: 524.158 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.087 | TFLOPs: 53.72 |
 iteration      792/    1571 | consumed samples:       176344 | consumed tokens:    361152512 | elapsed time per iteration (s): 78.81 | learning rate: 6.896E-05 | global batch size:   400 | lm loss: 5.251484E+00 | loss scale: 8192.0 | grad norm: 5972.250 | num zeros: 0.0 | params norm: 524.179 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration      793/    1571 | consumed samples:       176744 | consumed tokens:    361971712 | elapsed time per iteration (s): 78.60 | learning rate: 6.884E-05 | global batch size:   400 | lm loss: 5.263643E+00 | loss scale: 8192.0 | grad norm: 7400.561 | num zeros: 0.0 | params norm: 524.200 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.089 | TFLOPs: 53.73 |
 iteration      794/    1571 | consumed samples:       177144 | consumed tokens:    362790912 | elapsed time per iteration (s): 78.69 | learning rate: 6.871E-05 | global batch size:   400 | lm loss: 5.269897E+00 | loss scale: 8192.0 | grad norm: 10822.946 | num zeros: 0.0 | params norm: 524.220 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration      795/    1571 | consumed samples:       177544 | consumed tokens:    363610112 | elapsed time per iteration (s): 78.73 | learning rate: 6.858E-05 | global batch size:   400 | lm loss: 5.266975E+00 | loss scale: 8192.0 | grad norm: 7993.197 | num zeros: 0.0 | params norm: 524.240 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      796/    1571 | consumed samples:       177944 | consumed tokens:    364429312 | elapsed time per iteration (s): 78.63 | learning rate: 6.845E-05 | global batch size:   400 | lm loss: 5.273729E+00 | loss scale: 8192.0 | grad norm: 7884.018 | num zeros: 0.0 | params norm: 524.260 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.087 | TFLOPs: 53.71 |
 iteration      797/    1571 | consumed samples:       178344 | consumed tokens:    365248512 | elapsed time per iteration (s): 78.61 | learning rate: 6.833E-05 | global batch size:   400 | lm loss: 5.246885E+00 | loss scale: 8192.0 | grad norm: 8345.504 | num zeros: 0.0 | params norm: 524.280 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.088 | TFLOPs: 53.73 |
 iteration      798/    1571 | consumed samples:       178744 | consumed tokens:    366067712 | elapsed time per iteration (s): 78.72 | learning rate: 6.820E-05 | global batch size:   400 | lm loss: 5.266273E+00 | loss scale: 8192.0 | grad norm: 9558.357 | num zeros: 0.0 | params norm: 524.300 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      799/    1571 | consumed samples:       179144 | consumed tokens:    366886912 | elapsed time per iteration (s): 78.71 | learning rate: 6.807E-05 | global batch size:   400 | lm loss: 5.264072E+00 | loss scale: 8192.0 | grad norm: 7794.292 | num zeros: 0.0 | params norm: 524.320 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.66 |
 iteration      800/    1571 | consumed samples:       179544 | consumed tokens:    367706112 | elapsed time per iteration (s): 78.63 | learning rate: 6.794E-05 | global batch size:   400 | lm loss: 5.243133E+00 | loss scale: 8192.0 | grad norm: 10552.102 | num zeros: 0.0 | params norm: 524.339 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.087 | TFLOPs: 53.71 |
 iteration      801/    1571 | consumed samples:       179944 | consumed tokens:    368525312 | elapsed time per iteration (s): 78.64 | learning rate: 6.782E-05 | global batch size:   400 | lm loss: 5.268459E+00 | loss scale: 8192.0 | grad norm: 6539.718 | num zeros: 0.0 | params norm: 524.359 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.086 | TFLOPs: 53.71 |
 iteration      802/    1571 | consumed samples:       180344 | consumed tokens:    369344512 | elapsed time per iteration (s): 78.80 | learning rate: 6.769E-05 | global batch size:   400 | lm loss: 5.242691E+00 | loss scale: 8192.0 | grad norm: 7927.978 | num zeros: 0.0 | params norm: 524.379 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration      803/    1571 | consumed samples:       180744 | consumed tokens:    370163712 | elapsed time per iteration (s): 78.66 | learning rate: 6.756E-05 | global batch size:   400 | lm loss: 5.266118E+00 | loss scale: 8192.0 | grad norm: 7981.404 | num zeros: 0.0 | params norm: 524.399 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.085 | TFLOPs: 53.69 |
 iteration      804/    1571 | consumed samples:       181144 | consumed tokens:    370982912 | elapsed time per iteration (s): 78.71 | learning rate: 6.743E-05 | global batch size:   400 | lm loss: 5.247383E+00 | loss scale: 8192.0 | grad norm: 6940.781 | num zeros: 0.0 | params norm: 524.419 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.66 |
 iteration      805/    1571 | consumed samples:       181544 | consumed tokens:    371802112 | elapsed time per iteration (s): 78.69 | learning rate: 6.730E-05 | global batch size:   400 | lm loss: 5.197874E+00 | loss scale: 8192.0 | grad norm: 6936.853 | num zeros: 0.0 | params norm: 524.438 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.68 |
 iteration      806/    1571 | consumed samples:       181944 | consumed tokens:    372621312 | elapsed time per iteration (s): 78.80 | learning rate: 6.717E-05 | global batch size:   400 | lm loss: 5.231298E+00 | loss scale: 8192.0 | grad norm: 6491.553 | num zeros: 0.0 | params norm: 524.459 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration      807/    1571 | consumed samples:       182344 | consumed tokens:    373440512 | elapsed time per iteration (s): 78.64 | learning rate: 6.704E-05 | global batch size:   400 | lm loss: 5.210604E+00 | loss scale: 8192.0 | grad norm: 5658.719 | num zeros: 0.0 | params norm: 524.479 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.087 | TFLOPs: 53.71 |
 iteration      808/    1571 | consumed samples:       182744 | consumed tokens:    374259712 | elapsed time per iteration (s): 78.71 | learning rate: 6.691E-05 | global batch size:   400 | lm loss: 5.222753E+00 | loss scale: 8192.0 | grad norm: 5269.610 | num zeros: 0.0 | params norm: 524.499 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.66 |
 iteration      809/    1571 | consumed samples:       183144 | consumed tokens:    375078912 | elapsed time per iteration (s): 78.72 | learning rate: 6.679E-05 | global batch size:   400 | lm loss: 5.212831E+00 | loss scale: 8192.0 | grad norm: 5500.691 | num zeros: 0.0 | params norm: 524.519 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.66 |
 iteration      810/    1571 | consumed samples:       183544 | consumed tokens:    375898112 | elapsed time per iteration (s): 78.72 | learning rate: 6.666E-05 | global batch size:   400 | lm loss: 5.230268E+00 | loss scale: 8192.0 | grad norm: 6373.289 | num zeros: 0.0 | params norm: 524.539 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      811/    1571 | consumed samples:       183944 | consumed tokens:    376717312 | elapsed time per iteration (s): 78.70 | learning rate: 6.653E-05 | global batch size:   400 | lm loss: 5.229303E+00 | loss scale: 8192.0 | grad norm: 6996.660 | num zeros: 0.0 | params norm: 524.559 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration      812/    1571 | consumed samples:       184344 | consumed tokens:    377536512 | elapsed time per iteration (s): 78.74 | learning rate: 6.640E-05 | global batch size:   400 | lm loss: 5.237235E+00 | loss scale: 8192.0 | grad norm: 7831.445 | num zeros: 0.0 | params norm: 524.579 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration      813/    1571 | consumed samples:       184744 | consumed tokens:    378355712 | elapsed time per iteration (s): 78.72 | learning rate: 6.627E-05 | global batch size:   400 | lm loss: 5.215698E+00 | loss scale: 8192.0 | grad norm: 9201.426 | num zeros: 0.0 | params norm: 524.599 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      814/    1571 | consumed samples:       185144 | consumed tokens:    379174912 | elapsed time per iteration (s): 78.73 | learning rate: 6.614E-05 | global batch size:   400 | lm loss: 5.217312E+00 | loss scale: 8192.0 | grad norm: 11335.884 | num zeros: 0.0 | params norm: 524.619 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.65 |
 iteration      815/    1571 | consumed samples:       185544 | consumed tokens:    379994112 | elapsed time per iteration (s): 78.75 | learning rate: 6.601E-05 | global batch size:   400 | lm loss: 5.222349E+00 | loss scale: 8192.0 | grad norm: 7482.448 | num zeros: 0.0 | params norm: 524.639 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      816/    1571 | consumed samples:       185944 | consumed tokens:    380813312 | elapsed time per iteration (s): 78.64 | learning rate: 6.588E-05 | global batch size:   400 | lm loss: 5.225205E+00 | loss scale: 8192.0 | grad norm: 7202.604 | num zeros: 0.0 | params norm: 524.658 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.086 | TFLOPs: 53.71 |
 iteration      817/    1571 | consumed samples:       186344 | consumed tokens:    381632512 | elapsed time per iteration (s): 78.54 | learning rate: 6.575E-05 | global batch size:   400 | lm loss: 5.213645E+00 | loss scale: 8192.0 | grad norm: 7439.627 | num zeros: 0.0 | params norm: 524.677 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.093 | TFLOPs: 53.78 |
 iteration      818/    1571 | consumed samples:       186744 | consumed tokens:    382451712 | elapsed time per iteration (s): 78.70 | learning rate: 6.562E-05 | global batch size:   400 | lm loss: 5.237227E+00 | loss scale: 8192.0 | grad norm: 8175.497 | num zeros: 0.0 | params norm: 524.697 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration      819/    1571 | consumed samples:       187144 | consumed tokens:    383270912 | elapsed time per iteration (s): 78.76 | learning rate: 6.549E-05 | global batch size:   400 | lm loss: 5.219104E+00 | loss scale: 8192.0 | grad norm: 9063.446 | num zeros: 0.0 | params norm: 524.716 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      820/    1571 | consumed samples:       187544 | consumed tokens:    384090112 | elapsed time per iteration (s): 78.68 | learning rate: 6.536E-05 | global batch size:   400 | lm loss: 5.223689E+00 | loss scale: 8192.0 | grad norm: 7204.528 | num zeros: 0.0 | params norm: 524.736 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.68 |
 iteration      821/    1571 | consumed samples:       187944 | consumed tokens:    384909312 | elapsed time per iteration (s): 78.66 | learning rate: 6.523E-05 | global batch size:   400 | lm loss: 5.185934E+00 | loss scale: 8192.0 | grad norm: 7152.965 | num zeros: 0.0 | params norm: 524.755 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.085 | TFLOPs: 53.70 |
 iteration      822/    1571 | consumed samples:       188344 | consumed tokens:    385728512 | elapsed time per iteration (s): 78.76 | learning rate: 6.510E-05 | global batch size:   400 | lm loss: 5.182895E+00 | loss scale: 8192.0 | grad norm: 7180.461 | num zeros: 0.0 | params norm: 524.774 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      823/    1571 | consumed samples:       188744 | consumed tokens:    386547712 | elapsed time per iteration (s): 78.75 | learning rate: 6.497E-05 | global batch size:   400 | lm loss: 5.213465E+00 | loss scale: 8192.0 | grad norm: 5855.022 | num zeros: 0.0 | params norm: 524.794 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      824/    1571 | consumed samples:       189144 | consumed tokens:    387366912 | elapsed time per iteration (s): 78.73 | learning rate: 6.484E-05 | global batch size:   400 | lm loss: 5.205810E+00 | loss scale: 8192.0 | grad norm: 5162.736 | num zeros: 0.0 | params norm: 524.814 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      825/    1571 | consumed samples:       189544 | consumed tokens:    388186112 | elapsed time per iteration (s): 78.69 | learning rate: 6.471E-05 | global batch size:   400 | lm loss: 5.157555E+00 | loss scale: 8192.0 | grad norm: 5435.220 | num zeros: 0.0 | params norm: 524.833 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration      826/    1571 | consumed samples:       189944 | consumed tokens:    389005312 | elapsed time per iteration (s): 78.79 | learning rate: 6.458E-05 | global batch size:   400 | lm loss: 5.170678E+00 | loss scale: 8192.0 | grad norm: 6776.451 | num zeros: 0.0 | params norm: 524.853 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration      827/    1571 | consumed samples:       190344 | consumed tokens:    389824512 | elapsed time per iteration (s): 78.67 | learning rate: 6.445E-05 | global batch size:   400 | lm loss: 5.195782E+00 | loss scale: 8192.0 | grad norm: 8538.445 | num zeros: 0.0 | params norm: 524.872 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.085 | TFLOPs: 53.69 |
 iteration      828/    1571 | consumed samples:       190744 | consumed tokens:    390643712 | elapsed time per iteration (s): 78.75 | learning rate: 6.432E-05 | global batch size:   400 | lm loss: 5.204029E+00 | loss scale: 8192.0 | grad norm: 10422.246 | num zeros: 0.0 | params norm: 524.892 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      829/    1571 | consumed samples:       191144 | consumed tokens:    391462912 | elapsed time per iteration (s): 78.74 | learning rate: 6.419E-05 | global batch size:   400 | lm loss: 5.208138E+00 | loss scale: 8192.0 | grad norm: 7086.350 | num zeros: 0.0 | params norm: 524.911 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration      830/    1571 | consumed samples:       191544 | consumed tokens:    392282112 | elapsed time per iteration (s): 78.76 | learning rate: 6.405E-05 | global batch size:   400 | lm loss: 5.191875E+00 | loss scale: 8192.0 | grad norm: 7638.884 | num zeros: 0.0 | params norm: 524.931 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      831/    1571 | consumed samples:       191944 | consumed tokens:    393101312 | elapsed time per iteration (s): 78.70 | learning rate: 6.392E-05 | global batch size:   400 | lm loss: 5.182766E+00 | loss scale: 8192.0 | grad norm: 9008.181 | num zeros: 0.0 | params norm: 524.949 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.67 |
 iteration      832/    1571 | consumed samples:       192344 | consumed tokens:    393920512 | elapsed time per iteration (s): 78.68 | learning rate: 6.379E-05 | global batch size:   400 | lm loss: 5.182531E+00 | loss scale: 8192.0 | grad norm: 7658.648 | num zeros: 0.0 | params norm: 524.969 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.68 |
 iteration      833/    1571 | consumed samples:       192744 | consumed tokens:    394739712 | elapsed time per iteration (s): 78.63 | learning rate: 6.366E-05 | global batch size:   400 | lm loss: 5.207492E+00 | loss scale: 8192.0 | grad norm: 9825.590 | num zeros: 0.0 | params norm: 524.987 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.087 | TFLOPs: 53.72 |
 iteration      834/    1571 | consumed samples:       193144 | consumed tokens:    395558912 | elapsed time per iteration (s): 78.77 | learning rate: 6.353E-05 | global batch size:   400 | lm loss: 5.193998E+00 | loss scale: 8192.0 | grad norm: 8657.031 | num zeros: 0.0 | params norm: 525.006 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      835/    1571 | consumed samples:       193544 | consumed tokens:    396378112 | elapsed time per iteration (s): 78.75 | learning rate: 6.340E-05 | global batch size:   400 | lm loss: 5.200290E+00 | loss scale: 8192.0 | grad norm: 9269.859 | num zeros: 0.0 | params norm: 525.025 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration      836/    1571 | consumed samples:       193944 | consumed tokens:    397197312 | elapsed time per iteration (s): 78.77 | learning rate: 6.327E-05 | global batch size:   400 | lm loss: 5.184624E+00 | loss scale: 8192.0 | grad norm: 9943.878 | num zeros: 0.0 | params norm: 525.044 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      837/    1571 | consumed samples:       194344 | consumed tokens:    398016512 | elapsed time per iteration (s): 78.72 | learning rate: 6.314E-05 | global batch size:   400 | lm loss: 5.150410E+00 | loss scale: 8192.0 | grad norm: 8368.697 | num zeros: 0.0 | params norm: 525.062 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.66 |
 iteration      838/    1571 | consumed samples:       194744 | consumed tokens:    398835712 | elapsed time per iteration (s): 78.70 | learning rate: 6.300E-05 | global batch size:   400 | lm loss: 5.146626E+00 | loss scale: 8192.0 | grad norm: 8128.872 | num zeros: 0.0 | params norm: 525.081 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.67 |
 iteration      839/    1571 | consumed samples:       195144 | consumed tokens:    399654912 | elapsed time per iteration (s): 78.72 | learning rate: 6.287E-05 | global batch size:   400 | lm loss: 5.162626E+00 | loss scale: 8192.0 | grad norm: 9403.881 | num zeros: 0.0 | params norm: 525.100 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      840/    1571 | consumed samples:       195544 | consumed tokens:    400474112 | elapsed time per iteration (s): 78.75 | learning rate: 6.274E-05 | global batch size:   400 | lm loss: 5.162704E+00 | loss scale: 8192.0 | grad norm: 7216.303 | num zeros: 0.0 | params norm: 525.118 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.64 |
 iteration      841/    1571 | consumed samples:       195944 | consumed tokens:    401293312 | elapsed time per iteration (s): 78.71 | learning rate: 6.261E-05 | global batch size:   400 | lm loss: 5.154317E+00 | loss scale: 8192.0 | grad norm: 6230.487 | num zeros: 0.0 | params norm: 525.137 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.66 |
 iteration      842/    1571 | consumed samples:       196344 | consumed tokens:    402112512 | elapsed time per iteration (s): 78.83 | learning rate: 6.248E-05 | global batch size:   400 | lm loss: 5.198997E+00 | loss scale: 8192.0 | grad norm: 6006.313 | num zeros: 0.0 | params norm: 525.156 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.58 |
 iteration      843/    1571 | consumed samples:       196744 | consumed tokens:    402931712 | elapsed time per iteration (s): 78.70 | learning rate: 6.234E-05 | global batch size:   400 | lm loss: 5.164314E+00 | loss scale: 8192.0 | grad norm: 5476.640 | num zeros: 0.0 | params norm: 525.174 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.67 |
 iteration      844/    1571 | consumed samples:       197144 | consumed tokens:    403750912 | elapsed time per iteration (s): 78.75 | learning rate: 6.221E-05 | global batch size:   400 | lm loss: 5.189244E+00 | loss scale: 8192.0 | grad norm: 6698.488 | num zeros: 0.0 | params norm: 525.193 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      845/    1571 | consumed samples:       197544 | consumed tokens:    404570112 | elapsed time per iteration (s): 78.74 | learning rate: 6.208E-05 | global batch size:   400 | lm loss: 5.185110E+00 | loss scale: 8192.0 | grad norm: 6152.141 | num zeros: 0.0 | params norm: 525.212 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration      846/    1571 | consumed samples:       197944 | consumed tokens:    405389312 | elapsed time per iteration (s): 78.75 | learning rate: 6.195E-05 | global batch size:   400 | lm loss: 5.151280E+00 | loss scale: 8192.0 | grad norm: 5895.824 | num zeros: 0.0 | params norm: 525.230 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      847/    1571 | consumed samples:       198344 | consumed tokens:    406208512 | elapsed time per iteration (s): 78.73 | learning rate: 6.182E-05 | global batch size:   400 | lm loss: 5.146612E+00 | loss scale: 8192.0 | grad norm: 7064.797 | num zeros: 0.0 | params norm: 525.249 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      848/    1571 | consumed samples:       198744 | consumed tokens:    407027712 | elapsed time per iteration (s): 78.75 | learning rate: 6.168E-05 | global batch size:   400 | lm loss: 5.145226E+00 | loss scale: 8192.0 | grad norm: 6841.482 | num zeros: 0.0 | params norm: 525.268 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      849/    1571 | consumed samples:       199144 | consumed tokens:    407846912 | elapsed time per iteration (s): 78.70 | learning rate: 6.155E-05 | global batch size:   400 | lm loss: 5.163168E+00 | loss scale: 8192.0 | grad norm: 6845.943 | num zeros: 0.0 | params norm: 525.287 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration      850/    1571 | consumed samples:       199544 | consumed tokens:    408666112 | elapsed time per iteration (s): 78.71 | learning rate: 6.142E-05 | global batch size:   400 | lm loss: 5.153411E+00 | loss scale: 8192.0 | grad norm: 7613.668 | num zeros: 0.0 | params norm: 525.306 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.66 |
 iteration      851/    1571 | consumed samples:       199944 | consumed tokens:    409485312 | elapsed time per iteration (s): 78.70 | learning rate: 6.129E-05 | global batch size:   400 | lm loss: 5.135026E+00 | loss scale: 8192.0 | grad norm: 8639.126 | num zeros: 0.0 | params norm: 525.325 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.66 |
 iteration      852/    1571 | consumed samples:       200344 | consumed tokens:    410304512 | elapsed time per iteration (s): 78.81 | learning rate: 6.115E-05 | global batch size:   400 | lm loss: 5.162777E+00 | loss scale: 8192.0 | grad norm: 9807.868 | num zeros: 0.0 | params norm: 525.343 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.59 |
 iteration      853/    1571 | consumed samples:       200744 | consumed tokens:    411123712 | elapsed time per iteration (s): 78.63 | learning rate: 6.102E-05 | global batch size:   400 | lm loss: 5.155903E+00 | loss scale: 8192.0 | grad norm: 8421.368 | num zeros: 0.0 | params norm: 525.361 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.087 | TFLOPs: 53.72 |
 iteration      854/    1571 | consumed samples:       201144 | consumed tokens:    411942912 | elapsed time per iteration (s): 78.72 | learning rate: 6.089E-05 | global batch size:   400 | lm loss: 5.144192E+00 | loss scale: 8192.0 | grad norm: 8572.921 | num zeros: 0.0 | params norm: 525.380 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      855/    1571 | consumed samples:       201544 | consumed tokens:    412762112 | elapsed time per iteration (s): 78.71 | learning rate: 6.076E-05 | global batch size:   400 | lm loss: 5.132146E+00 | loss scale: 8192.0 | grad norm: 7657.673 | num zeros: 0.0 | params norm: 525.398 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.66 |
 iteration      856/    1571 | consumed samples:       201944 | consumed tokens:    413581312 | elapsed time per iteration (s): 78.77 | learning rate: 6.062E-05 | global batch size:   400 | lm loss: 5.130137E+00 | loss scale: 8192.0 | grad norm: 8516.647 | num zeros: 0.0 | params norm: 525.417 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      857/    1571 | consumed samples:       202344 | consumed tokens:    414400512 | elapsed time per iteration (s): 78.71 | learning rate: 6.049E-05 | global batch size:   400 | lm loss: 5.147075E+00 | loss scale: 8192.0 | grad norm: 8276.286 | num zeros: 0.0 | params norm: 525.435 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.66 |
 iteration      858/    1571 | consumed samples:       202744 | consumed tokens:    415219712 | elapsed time per iteration (s): 78.82 | learning rate: 6.036E-05 | global batch size:   400 | lm loss: 5.142938E+00 | loss scale: 8192.0 | grad norm: 8199.566 | num zeros: 0.0 | params norm: 525.453 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration      859/    1571 | consumed samples:       203144 | consumed tokens:    416038912 | elapsed time per iteration (s): 78.68 | learning rate: 6.023E-05 | global batch size:   400 | lm loss: 5.138152E+00 | loss scale: 8192.0 | grad norm: 11050.425 | num zeros: 0.0 | params norm: 525.472 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.68 |
 iteration      860/    1571 | consumed samples:       203544 | consumed tokens:    416858112 | elapsed time per iteration (s): 78.77 | learning rate: 6.009E-05 | global batch size:   400 | lm loss: 5.122466E+00 | loss scale: 8192.0 | grad norm: 8738.314 | num zeros: 0.0 | params norm: 525.490 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      861/    1571 | consumed samples:       203944 | consumed tokens:    417677312 | elapsed time per iteration (s): 78.75 | learning rate: 5.996E-05 | global batch size:   400 | lm loss: 5.125840E+00 | loss scale: 8192.0 | grad norm: 7291.793 | num zeros: 0.0 | params norm: 525.508 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      862/    1571 | consumed samples:       204344 | consumed tokens:    418496512 | elapsed time per iteration (s): 78.70 | learning rate: 5.983E-05 | global batch size:   400 | lm loss: 5.118397E+00 | loss scale: 8192.0 | grad norm: 7610.947 | num zeros: 0.0 | params norm: 525.526 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration      863/    1571 | consumed samples:       204744 | consumed tokens:    419315712 | elapsed time per iteration (s): 78.69 | learning rate: 5.969E-05 | global batch size:   400 | lm loss: 5.113968E+00 | loss scale: 8192.0 | grad norm: 7212.347 | num zeros: 0.0 | params norm: 525.544 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration      864/    1571 | consumed samples:       205144 | consumed tokens:    420134912 | elapsed time per iteration (s): 78.84 | learning rate: 5.956E-05 | global batch size:   400 | lm loss: 5.109619E+00 | loss scale: 8192.0 | grad norm: 6535.564 | num zeros: 0.0 | params norm: 525.562 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration      865/    1571 | consumed samples:       205544 | consumed tokens:    420954112 | elapsed time per iteration (s): 78.72 | learning rate: 5.943E-05 | global batch size:   400 | lm loss: 5.102176E+00 | loss scale: 8192.0 | grad norm: 6451.981 | num zeros: 0.0 | params norm: 525.580 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      866/    1571 | consumed samples:       205944 | consumed tokens:    421773312 | elapsed time per iteration (s): 78.79 | learning rate: 5.929E-05 | global batch size:   400 | lm loss: 5.131414E+00 | loss scale: 8192.0 | grad norm: 5331.440 | num zeros: 0.0 | params norm: 525.599 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration      867/    1571 | consumed samples:       206344 | consumed tokens:    422592512 | elapsed time per iteration (s): 78.75 | learning rate: 5.916E-05 | global batch size:   400 | lm loss: 5.107808E+00 | loss scale: 8192.0 | grad norm: 6413.452 | num zeros: 0.0 | params norm: 525.617 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      868/    1571 | consumed samples:       206744 | consumed tokens:    423411712 | elapsed time per iteration (s): 78.68 | learning rate: 5.903E-05 | global batch size:   400 | lm loss: 5.110693E+00 | loss scale: 8192.0 | grad norm: 6547.265 | num zeros: 0.0 | params norm: 525.635 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.68 |
 iteration      869/    1571 | consumed samples:       207144 | consumed tokens:    424230912 | elapsed time per iteration (s): 78.70 | learning rate: 5.890E-05 | global batch size:   400 | lm loss: 5.113031E+00 | loss scale: 8192.0 | grad norm: 6847.284 | num zeros: 0.0 | params norm: 525.653 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration      870/    1571 | consumed samples:       207544 | consumed tokens:    425050112 | elapsed time per iteration (s): 78.79 | learning rate: 5.876E-05 | global batch size:   400 | lm loss: 5.080105E+00 | loss scale: 8192.0 | grad norm: 7771.298 | num zeros: 0.0 | params norm: 525.671 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration      871/    1571 | consumed samples:       207944 | consumed tokens:    425869312 | elapsed time per iteration (s): 78.67 | learning rate: 5.863E-05 | global batch size:   400 | lm loss: 5.106495E+00 | loss scale: 8192.0 | grad norm: 8993.731 | num zeros: 0.0 | params norm: 525.689 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.085 | TFLOPs: 53.69 |
 iteration      872/    1571 | consumed samples:       208344 | consumed tokens:    426688512 | elapsed time per iteration (s): 78.72 | learning rate: 5.850E-05 | global batch size:   400 | lm loss: 5.113805E+00 | loss scale: 8192.0 | grad norm: 6140.017 | num zeros: 0.0 | params norm: 525.707 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      873/    1571 | consumed samples:       208744 | consumed tokens:    427507712 | elapsed time per iteration (s): 78.76 | learning rate: 5.836E-05 | global batch size:   400 | lm loss: 5.083582E+00 | loss scale: 8192.0 | grad norm: 5529.612 | num zeros: 0.0 | params norm: 525.725 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      874/    1571 | consumed samples:       209144 | consumed tokens:    428326912 | elapsed time per iteration (s): 78.76 | learning rate: 5.823E-05 | global batch size:   400 | lm loss: 5.082095E+00 | loss scale: 8192.0 | grad norm: 6353.424 | num zeros: 0.0 | params norm: 525.743 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      875/    1571 | consumed samples:       209544 | consumed tokens:    429146112 | elapsed time per iteration (s): 78.70 | learning rate: 5.810E-05 | global batch size:   400 | lm loss: 5.060117E+00 | loss scale: 8192.0 | grad norm: 6837.748 | num zeros: 0.0 | params norm: 525.761 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.67 |
 iteration      876/    1571 | consumed samples:       209944 | consumed tokens:    429965312 | elapsed time per iteration (s): 78.89 | learning rate: 5.796E-05 | global batch size:   400 | lm loss: 5.068973E+00 | loss scale: 8192.0 | grad norm: 7668.639 | num zeros: 0.0 | params norm: 525.779 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration      877/    1571 | consumed samples:       210344 | consumed tokens:    430784512 | elapsed time per iteration (s): 78.73 | learning rate: 5.783E-05 | global batch size:   400 | lm loss: 5.037956E+00 | loss scale: 8192.0 | grad norm: 7731.304 | num zeros: 0.0 | params norm: 525.797 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.65 |
 iteration      878/    1571 | consumed samples:       210744 | consumed tokens:    431603712 | elapsed time per iteration (s): 78.81 | learning rate: 5.769E-05 | global batch size:   400 | lm loss: 5.076192E+00 | loss scale: 8192.0 | grad norm: 8925.186 | num zeros: 0.0 | params norm: 525.815 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration      879/    1571 | consumed samples:       211144 | consumed tokens:    432422912 | elapsed time per iteration (s): 78.71 | learning rate: 5.756E-05 | global batch size:   400 | lm loss: 5.083528E+00 | loss scale: 8192.0 | grad norm: 9623.255 | num zeros: 0.0 | params norm: 525.832 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.66 |
 iteration      880/    1571 | consumed samples:       211544 | consumed tokens:    433242112 | elapsed time per iteration (s): 78.83 | learning rate: 5.743E-05 | global batch size:   400 | lm loss: 5.104824E+00 | loss scale: 8192.0 | grad norm: 8131.411 | num zeros: 0.0 | params norm: 525.850 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration      881/    1571 | consumed samples:       211944 | consumed tokens:    434061312 | elapsed time per iteration (s): 78.65 | learning rate: 5.729E-05 | global batch size:   400 | lm loss: 5.056541E+00 | loss scale: 8192.0 | grad norm: 6458.151 | num zeros: 0.0 | params norm: 525.868 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.086 | TFLOPs: 53.70 |
 iteration      882/    1571 | consumed samples:       212344 | consumed tokens:    434880512 | elapsed time per iteration (s): 78.79 | learning rate: 5.716E-05 | global batch size:   400 | lm loss: 5.111021E+00 | loss scale: 8192.0 | grad norm: 6568.777 | num zeros: 0.0 | params norm: 525.885 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration      883/    1571 | consumed samples:       212744 | consumed tokens:    435699712 | elapsed time per iteration (s): 78.74 | learning rate: 5.703E-05 | global batch size:   400 | lm loss: 5.077713E+00 | loss scale: 8192.0 | grad norm: 6748.996 | num zeros: 0.0 | params norm: 525.902 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration      884/    1571 | consumed samples:       213144 | consumed tokens:    436518912 | elapsed time per iteration (s): 78.84 | learning rate: 5.689E-05 | global batch size:   400 | lm loss: 5.097401E+00 | loss scale: 8192.0 | grad norm: 5942.536 | num zeros: 0.0 | params norm: 525.920 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.57 |
 iteration      885/    1571 | consumed samples:       213544 | consumed tokens:    437338112 | elapsed time per iteration (s): 78.75 | learning rate: 5.676E-05 | global batch size:   400 | lm loss: 5.089023E+00 | loss scale: 8192.0 | grad norm: 6121.225 | num zeros: 0.0 | params norm: 525.938 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration      886/    1571 | consumed samples:       213944 | consumed tokens:    438157312 | elapsed time per iteration (s): 78.78 | learning rate: 5.663E-05 | global batch size:   400 | lm loss: 5.070575E+00 | loss scale: 8192.0 | grad norm: 5543.799 | num zeros: 0.0 | params norm: 525.955 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration      887/    1571 | consumed samples:       214344 | consumed tokens:    438976512 | elapsed time per iteration (s): 78.77 | learning rate: 5.649E-05 | global batch size:   400 | lm loss: 5.109737E+00 | loss scale: 8192.0 | grad norm: 6489.985 | num zeros: 0.0 | params norm: 525.972 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      888/    1571 | consumed samples:       214744 | consumed tokens:    439795712 | elapsed time per iteration (s): 78.75 | learning rate: 5.636E-05 | global batch size:   400 | lm loss: 5.057859E+00 | loss scale: 8192.0 | grad norm: 8619.826 | num zeros: 0.0 | params norm: 525.990 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      889/    1571 | consumed samples:       215144 | consumed tokens:    440614912 | elapsed time per iteration (s): 78.83 | learning rate: 5.622E-05 | global batch size:   400 | lm loss: 5.040928E+00 | loss scale: 8192.0 | grad norm: 10442.928 | num zeros: 0.0 | params norm: 526.007 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration      890/    1571 | consumed samples:       215544 | consumed tokens:    441434112 | elapsed time per iteration (s): 78.76 | learning rate: 5.609E-05 | global batch size:   400 | lm loss: 5.074003E+00 | loss scale: 8192.0 | grad norm: 8152.043 | num zeros: 0.0 | params norm: 526.024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      891/    1571 | consumed samples:       215944 | consumed tokens:    442253312 | elapsed time per iteration (s): 78.76 | learning rate: 5.596E-05 | global batch size:   400 | lm loss: 5.076616E+00 | loss scale: 8192.0 | grad norm: 10889.660 | num zeros: 0.0 | params norm: 526.041 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      892/    1571 | consumed samples:       216344 | consumed tokens:    443072512 | elapsed time per iteration (s): 78.70 | learning rate: 5.582E-05 | global batch size:   400 | lm loss: 5.072059E+00 | loss scale: 8192.0 | grad norm: 6987.396 | num zeros: 0.0 | params norm: 526.057 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration      893/    1571 | consumed samples:       216744 | consumed tokens:    443891712 | elapsed time per iteration (s): 78.78 | learning rate: 5.569E-05 | global batch size:   400 | lm loss: 5.046076E+00 | loss scale: 8192.0 | grad norm: 6639.130 | num zeros: 0.0 | params norm: 526.074 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration      894/    1571 | consumed samples:       217144 | consumed tokens:    444710912 | elapsed time per iteration (s): 78.68 | learning rate: 5.556E-05 | global batch size:   400 | lm loss: 5.055019E+00 | loss scale: 8192.0 | grad norm: 6382.524 | num zeros: 0.0 | params norm: 526.091 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.68 |
 iteration      895/    1571 | consumed samples:       217544 | consumed tokens:    445530112 | elapsed time per iteration (s): 78.60 | learning rate: 5.542E-05 | global batch size:   400 | lm loss: 5.047198E+00 | loss scale: 8192.0 | grad norm: 6577.778 | num zeros: 0.0 | params norm: 526.108 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.089 | TFLOPs: 53.74 |
 iteration      896/    1571 | consumed samples:       217944 | consumed tokens:    446349312 | elapsed time per iteration (s): 78.70 | learning rate: 5.529E-05 | global batch size:   400 | lm loss: 5.033446E+00 | loss scale: 8192.0 | grad norm: 7990.948 | num zeros: 0.0 | params norm: 526.125 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.67 |
 iteration      897/    1571 | consumed samples:       218344 | consumed tokens:    447168512 | elapsed time per iteration (s): 78.72 | learning rate: 5.516E-05 | global batch size:   400 | lm loss: 5.021757E+00 | loss scale: 8192.0 | grad norm: 6874.281 | num zeros: 0.0 | params norm: 526.142 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      898/    1571 | consumed samples:       218744 | consumed tokens:    447987712 | elapsed time per iteration (s): 78.77 | learning rate: 5.502E-05 | global batch size:   400 | lm loss: 5.052304E+00 | loss scale: 8192.0 | grad norm: 7132.913 | num zeros: 0.0 | params norm: 526.158 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      899/    1571 | consumed samples:       219144 | consumed tokens:    448806912 | elapsed time per iteration (s): 78.82 | learning rate: 5.489E-05 | global batch size:   400 | lm loss: 5.067771E+00 | loss scale: 8192.0 | grad norm: 8544.364 | num zeros: 0.0 | params norm: 526.175 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration      900/    1571 | consumed samples:       219544 | consumed tokens:    449626112 | elapsed time per iteration (s): 78.73 | learning rate: 5.475E-05 | global batch size:   400 | lm loss: 5.022511E+00 | loss scale: 8192.0 | grad norm: 9661.136 | num zeros: 0.0 | params norm: 526.192 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      901/    1571 | consumed samples:       219944 | consumed tokens:    450445312 | elapsed time per iteration (s): 78.70 | learning rate: 5.462E-05 | global batch size:   400 | lm loss: 5.035220E+00 | loss scale: 8192.0 | grad norm: 6334.028 | num zeros: 0.0 | params norm: 526.209 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration      902/    1571 | consumed samples:       220344 | consumed tokens:    451264512 | elapsed time per iteration (s): 78.79 | learning rate: 5.449E-05 | global batch size:   400 | lm loss: 5.034227E+00 | loss scale: 8192.0 | grad norm: 7334.897 | num zeros: 0.0 | params norm: 526.226 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration      903/    1571 | consumed samples:       220744 | consumed tokens:    452083712 | elapsed time per iteration (s): 78.77 | learning rate: 5.435E-05 | global batch size:   400 | lm loss: 5.028857E+00 | loss scale: 8192.0 | grad norm: 6260.192 | num zeros: 0.0 | params norm: 526.242 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      904/    1571 | consumed samples:       221144 | consumed tokens:    452902912 | elapsed time per iteration (s): 78.76 | learning rate: 5.422E-05 | global batch size:   400 | lm loss: 4.990595E+00 | loss scale: 8192.0 | grad norm: 8154.765 | num zeros: 0.0 | params norm: 526.259 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      905/    1571 | consumed samples:       221544 | consumed tokens:    453722112 | elapsed time per iteration (s): 78.77 | learning rate: 5.409E-05 | global batch size:   400 | lm loss: 4.979148E+00 | loss scale: 8192.0 | grad norm: 7917.267 | num zeros: 0.0 | params norm: 526.276 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      906/    1571 | consumed samples:       221944 | consumed tokens:    454541312 | elapsed time per iteration (s): 78.75 | learning rate: 5.395E-05 | global batch size:   400 | lm loss: 5.033463E+00 | loss scale: 8192.0 | grad norm: 10407.398 | num zeros: 0.0 | params norm: 526.293 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      907/    1571 | consumed samples:       222344 | consumed tokens:    455360512 | elapsed time per iteration (s): 78.72 | learning rate: 5.382E-05 | global batch size:   400 | lm loss: 5.001349E+00 | loss scale: 8192.0 | grad norm: 7868.453 | num zeros: 0.0 | params norm: 526.309 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      908/    1571 | consumed samples:       222744 | consumed tokens:    456179712 | elapsed time per iteration (s): 78.70 | learning rate: 5.368E-05 | global batch size:   400 | lm loss: 5.006695E+00 | loss scale: 8192.0 | grad norm: 6503.483 | num zeros: 0.0 | params norm: 526.326 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration      909/    1571 | consumed samples:       223144 | consumed tokens:    456998912 | elapsed time per iteration (s): 78.68 | learning rate: 5.355E-05 | global batch size:   400 | lm loss: 5.014198E+00 | loss scale: 8192.0 | grad norm: 5872.132 | num zeros: 0.0 | params norm: 526.343 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.68 |
 iteration      910/    1571 | consumed samples:       223544 | consumed tokens:    457818112 | elapsed time per iteration (s): 78.87 | learning rate: 5.342E-05 | global batch size:   400 | lm loss: 5.010805E+00 | loss scale: 8192.0 | grad norm: 7197.110 | num zeros: 0.0 | params norm: 526.360 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.55 |
 iteration      911/    1571 | consumed samples:       223944 | consumed tokens:    458637312 | elapsed time per iteration (s): 78.66 | learning rate: 5.328E-05 | global batch size:   400 | lm loss: 5.037185E+00 | loss scale: 8192.0 | grad norm: 7988.928 | num zeros: 0.0 | params norm: 526.376 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.085 | TFLOPs: 53.70 |
 iteration      912/    1571 | consumed samples:       224344 | consumed tokens:    459456512 | elapsed time per iteration (s): 78.73 | learning rate: 5.315E-05 | global batch size:   400 | lm loss: 4.998526E+00 | loss scale: 8192.0 | grad norm: 7339.593 | num zeros: 0.0 | params norm: 526.393 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.65 |
 iteration      913/    1571 | consumed samples:       224744 | consumed tokens:    460275712 | elapsed time per iteration (s): 78.71 | learning rate: 5.302E-05 | global batch size:   400 | lm loss: 4.995860E+00 | loss scale: 8192.0 | grad norm: 9104.889 | num zeros: 0.0 | params norm: 526.409 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.66 |
 iteration      914/    1571 | consumed samples:       225144 | consumed tokens:    461094912 | elapsed time per iteration (s): 78.78 | learning rate: 5.288E-05 | global batch size:   400 | lm loss: 5.040393E+00 | loss scale: 8192.0 | grad norm: 9055.661 | num zeros: 0.0 | params norm: 526.426 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration      915/    1571 | consumed samples:       225544 | consumed tokens:    461914112 | elapsed time per iteration (s): 78.75 | learning rate: 5.275E-05 | global batch size:   400 | lm loss: 4.978696E+00 | loss scale: 8192.0 | grad norm: 7860.388 | num zeros: 0.0 | params norm: 526.442 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      916/    1571 | consumed samples:       225944 | consumed tokens:    462733312 | elapsed time per iteration (s): 78.86 | learning rate: 5.262E-05 | global batch size:   400 | lm loss: 4.977988E+00 | loss scale: 8192.0 | grad norm: 7964.707 | num zeros: 0.0 | params norm: 526.459 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration      917/    1571 | consumed samples:       226344 | consumed tokens:    463552512 | elapsed time per iteration (s): 78.68 | learning rate: 5.248E-05 | global batch size:   400 | lm loss: 4.992556E+00 | loss scale: 8192.0 | grad norm: 7345.508 | num zeros: 0.0 | params norm: 526.475 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.68 |
 iteration      918/    1571 | consumed samples:       226744 | consumed tokens:    464371712 | elapsed time per iteration (s): 78.78 | learning rate: 5.235E-05 | global batch size:   400 | lm loss: 5.020022E+00 | loss scale: 8192.0 | grad norm: 7082.969 | num zeros: 0.0 | params norm: 526.491 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      919/    1571 | consumed samples:       227144 | consumed tokens:    465190912 | elapsed time per iteration (s): 78.75 | learning rate: 5.221E-05 | global batch size:   400 | lm loss: 4.999356E+00 | loss scale: 8192.0 | grad norm: 8246.094 | num zeros: 0.0 | params norm: 526.508 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      920/    1571 | consumed samples:       227544 | consumed tokens:    466010112 | elapsed time per iteration (s): 78.76 | learning rate: 5.208E-05 | global batch size:   400 | lm loss: 5.022073E+00 | loss scale: 8192.0 | grad norm: 8953.271 | num zeros: 0.0 | params norm: 526.524 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      921/    1571 | consumed samples:       227944 | consumed tokens:    466829312 | elapsed time per iteration (s): 78.78 | learning rate: 5.195E-05 | global batch size:   400 | lm loss: 4.977728E+00 | loss scale: 8192.0 | grad norm: 7181.538 | num zeros: 0.0 | params norm: 526.540 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration      922/    1571 | consumed samples:       228344 | consumed tokens:    467648512 | elapsed time per iteration (s): 78.78 | learning rate: 5.181E-05 | global batch size:   400 | lm loss: 4.990734E+00 | loss scale: 8192.0 | grad norm: 9273.573 | num zeros: 0.0 | params norm: 526.556 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      923/    1571 | consumed samples:       228744 | consumed tokens:    468467712 | elapsed time per iteration (s): 78.75 | learning rate: 5.168E-05 | global batch size:   400 | lm loss: 4.954131E+00 | loss scale: 8192.0 | grad norm: 9002.560 | num zeros: 0.0 | params norm: 526.572 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      924/    1571 | consumed samples:       229144 | consumed tokens:    469286912 | elapsed time per iteration (s): 78.80 | learning rate: 5.155E-05 | global batch size:   400 | lm loss: 4.987872E+00 | loss scale: 8192.0 | grad norm: 8270.403 | num zeros: 0.0 | params norm: 526.587 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration      925/    1571 | consumed samples:       229544 | consumed tokens:    470106112 | elapsed time per iteration (s): 78.76 | learning rate: 5.141E-05 | global batch size:   400 | lm loss: 5.014940E+00 | loss scale: 8192.0 | grad norm: 7818.628 | num zeros: 0.0 | params norm: 526.603 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      926/    1571 | consumed samples:       229944 | consumed tokens:    470925312 | elapsed time per iteration (s): 78.81 | learning rate: 5.128E-05 | global batch size:   400 | lm loss: 4.983182E+00 | loss scale: 8192.0 | grad norm: 8136.044 | num zeros: 0.0 | params norm: 526.619 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration      927/    1571 | consumed samples:       230344 | consumed tokens:    471744512 | elapsed time per iteration (s): 78.77 | learning rate: 5.115E-05 | global batch size:   400 | lm loss: 5.007998E+00 | loss scale: 8192.0 | grad norm: 7671.191 | num zeros: 0.0 | params norm: 526.634 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      928/    1571 | consumed samples:       230744 | consumed tokens:    472563712 | elapsed time per iteration (s): 78.85 | learning rate: 5.101E-05 | global batch size:   400 | lm loss: 4.998880E+00 | loss scale: 8192.0 | grad norm: 7690.289 | num zeros: 0.0 | params norm: 526.650 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration      929/    1571 | consumed samples:       231144 | consumed tokens:    473382912 | elapsed time per iteration (s): 78.57 | learning rate: 5.088E-05 | global batch size:   400 | lm loss: 4.997276E+00 | loss scale: 8192.0 | grad norm: 7212.148 | num zeros: 0.0 | params norm: 526.665 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.091 | TFLOPs: 53.76 |
 iteration      930/    1571 | consumed samples:       231544 | consumed tokens:    474202112 | elapsed time per iteration (s): 78.66 | learning rate: 5.075E-05 | global batch size:   400 | lm loss: 4.968243E+00 | loss scale: 8192.0 | grad norm: 7084.365 | num zeros: 0.0 | params norm: 526.681 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.085 | TFLOPs: 53.69 |
 iteration      931/    1571 | consumed samples:       231944 | consumed tokens:    475021312 | elapsed time per iteration (s): 78.86 | learning rate: 5.061E-05 | global batch size:   400 | lm loss: 4.963769E+00 | loss scale: 8192.0 | grad norm: 7605.388 | num zeros: 0.0 | params norm: 526.696 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration      932/    1571 | consumed samples:       232344 | consumed tokens:    475840512 | elapsed time per iteration (s): 78.71 | learning rate: 5.048E-05 | global batch size:   400 | lm loss: 4.989241E+00 | loss scale: 8192.0 | grad norm: 7815.417 | num zeros: 0.0 | params norm: 526.712 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.66 |
 iteration      933/    1571 | consumed samples:       232744 | consumed tokens:    476659712 | elapsed time per iteration (s): 78.61 | learning rate: 5.035E-05 | global batch size:   400 | lm loss: 4.976111E+00 | loss scale: 8192.0 | grad norm: 7161.393 | num zeros: 0.0 | params norm: 526.727 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.089 | TFLOPs: 53.73 |
 iteration      934/    1571 | consumed samples:       233144 | consumed tokens:    477478912 | elapsed time per iteration (s): 78.73 | learning rate: 5.022E-05 | global batch size:   400 | lm loss: 4.995550E+00 | loss scale: 8192.0 | grad norm: 8431.883 | num zeros: 0.0 | params norm: 526.742 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration      935/    1571 | consumed samples:       233544 | consumed tokens:    478298112 | elapsed time per iteration (s): 78.80 | learning rate: 5.008E-05 | global batch size:   400 | lm loss: 4.992144E+00 | loss scale: 8192.0 | grad norm: 9376.510 | num zeros: 0.0 | params norm: 526.758 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration      936/    1571 | consumed samples:       233944 | consumed tokens:    479117312 | elapsed time per iteration (s): 78.70 | learning rate: 4.995E-05 | global batch size:   400 | lm loss: 4.948701E+00 | loss scale: 8192.0 | grad norm: 6884.456 | num zeros: 0.0 | params norm: 526.773 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.67 |
 iteration      937/    1571 | consumed samples:       234344 | consumed tokens:    479936512 | elapsed time per iteration (s): 78.75 | learning rate: 4.982E-05 | global batch size:   400 | lm loss: 4.986660E+00 | loss scale: 8192.0 | grad norm: 6829.140 | num zeros: 0.0 | params norm: 526.788 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration      938/    1571 | consumed samples:       234744 | consumed tokens:    480755712 | elapsed time per iteration (s): 78.88 | learning rate: 4.968E-05 | global batch size:   400 | lm loss: 4.969284E+00 | loss scale: 8192.0 | grad norm: 7390.402 | num zeros: 0.0 | params norm: 526.803 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration      939/    1571 | consumed samples:       235144 | consumed tokens:    481574912 | elapsed time per iteration (s): 78.64 | learning rate: 4.955E-05 | global batch size:   400 | lm loss: 4.936300E+00 | loss scale: 8192.0 | grad norm: 8392.755 | num zeros: 0.0 | params norm: 526.818 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.086 | TFLOPs: 53.71 |
 iteration      940/    1571 | consumed samples:       235544 | consumed tokens:    482394112 | elapsed time per iteration (s): 78.69 | learning rate: 4.942E-05 | global batch size:   400 | lm loss: 4.973614E+00 | loss scale: 8192.0 | grad norm: 11574.583 | num zeros: 0.0 | params norm: 526.833 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.68 |
 iteration      941/    1571 | consumed samples:       235944 | consumed tokens:    483213312 | elapsed time per iteration (s): 78.79 | learning rate: 4.929E-05 | global batch size:   400 | lm loss: 4.952254E+00 | loss scale: 8192.0 | grad norm: 7925.134 | num zeros: 0.0 | params norm: 526.848 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration      942/    1571 | consumed samples:       236344 | consumed tokens:    484032512 | elapsed time per iteration (s): 78.75 | learning rate: 4.915E-05 | global batch size:   400 | lm loss: 4.949720E+00 | loss scale: 8192.0 | grad norm: 10073.417 | num zeros: 0.0 | params norm: 526.863 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      943/    1571 | consumed samples:       236744 | consumed tokens:    484851712 | elapsed time per iteration (s): 78.70 | learning rate: 4.902E-05 | global batch size:   400 | lm loss: 4.955865E+00 | loss scale: 8192.0 | grad norm: 7006.023 | num zeros: 0.0 | params norm: 526.878 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration      944/    1571 | consumed samples:       237144 | consumed tokens:    485670912 | elapsed time per iteration (s): 78.86 | learning rate: 4.889E-05 | global batch size:   400 | lm loss: 4.921666E+00 | loss scale: 8192.0 | grad norm: 7265.294 | num zeros: 0.0 | params norm: 526.892 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration      945/    1571 | consumed samples:       237544 | consumed tokens:    486490112 | elapsed time per iteration (s): 78.83 | learning rate: 4.876E-05 | global batch size:   400 | lm loss: 4.925457E+00 | loss scale: 8192.0 | grad norm: 7572.862 | num zeros: 0.0 | params norm: 526.907 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration      946/    1571 | consumed samples:       237944 | consumed tokens:    487309312 | elapsed time per iteration (s): 78.83 | learning rate: 4.862E-05 | global batch size:   400 | lm loss: 4.935496E+00 | loss scale: 8192.0 | grad norm: 7831.193 | num zeros: 0.0 | params norm: 526.922 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration      947/    1571 | consumed samples:       238344 | consumed tokens:    488128512 | elapsed time per iteration (s): 78.74 | learning rate: 4.849E-05 | global batch size:   400 | lm loss: 4.927675E+00 | loss scale: 8192.0 | grad norm: 7234.000 | num zeros: 0.0 | params norm: 526.937 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration      948/    1571 | consumed samples:       238744 | consumed tokens:    488947712 | elapsed time per iteration (s): 78.86 | learning rate: 4.836E-05 | global batch size:   400 | lm loss: 4.949072E+00 | loss scale: 8192.0 | grad norm: 8823.169 | num zeros: 0.0 | params norm: 526.952 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration      949/    1571 | consumed samples:       239144 | consumed tokens:    489766912 | elapsed time per iteration (s): 78.82 | learning rate: 4.823E-05 | global batch size:   400 | lm loss: 4.918211E+00 | loss scale: 8192.0 | grad norm: 7179.255 | num zeros: 0.0 | params norm: 526.966 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration      950/    1571 | consumed samples:       239544 | consumed tokens:    490586112 | elapsed time per iteration (s): 78.81 | learning rate: 4.809E-05 | global batch size:   400 | lm loss: 4.916067E+00 | loss scale: 8192.0 | grad norm: 6806.735 | num zeros: 0.0 | params norm: 526.981 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration      951/    1571 | consumed samples:       239944 | consumed tokens:    491405312 | elapsed time per iteration (s): 78.71 | learning rate: 4.796E-05 | global batch size:   400 | lm loss: 4.939632E+00 | loss scale: 8192.0 | grad norm: 6663.582 | num zeros: 0.0 | params norm: 526.996 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.66 |
 iteration      952/    1571 | consumed samples:       240344 | consumed tokens:    492224512 | elapsed time per iteration (s): 78.76 | learning rate: 4.783E-05 | global batch size:   400 | lm loss: 4.894786E+00 | loss scale: 8192.0 | grad norm: 6076.332 | num zeros: 0.0 | params norm: 527.011 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.62 |
 iteration      953/    1571 | consumed samples:       240744 | consumed tokens:    493043712 | elapsed time per iteration (s): 78.76 | learning rate: 4.770E-05 | global batch size:   400 | lm loss: 4.921221E+00 | loss scale: 8192.0 | grad norm: 5352.733 | num zeros: 0.0 | params norm: 527.026 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      954/    1571 | consumed samples:       241144 | consumed tokens:    493862912 | elapsed time per iteration (s): 78.84 | learning rate: 4.757E-05 | global batch size:   400 | lm loss: 4.884574E+00 | loss scale: 8192.0 | grad norm: 5203.425 | num zeros: 0.0 | params norm: 527.040 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration      955/    1571 | consumed samples:       241544 | consumed tokens:    494682112 | elapsed time per iteration (s): 78.77 | learning rate: 4.743E-05 | global batch size:   400 | lm loss: 4.922475E+00 | loss scale: 8192.0 | grad norm: 5394.487 | num zeros: 0.0 | params norm: 527.055 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      956/    1571 | consumed samples:       241944 | consumed tokens:    495501312 | elapsed time per iteration (s): 78.79 | learning rate: 4.730E-05 | global batch size:   400 | lm loss: 4.925322E+00 | loss scale: 8192.0 | grad norm: 5652.819 | num zeros: 0.0 | params norm: 527.070 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration      957/    1571 | consumed samples:       242344 | consumed tokens:    496320512 | elapsed time per iteration (s): 78.77 | learning rate: 4.717E-05 | global batch size:   400 | lm loss: 4.880563E+00 | loss scale: 8192.0 | grad norm: 6677.736 | num zeros: 0.0 | params norm: 527.085 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      958/    1571 | consumed samples:       242744 | consumed tokens:    497139712 | elapsed time per iteration (s): 78.87 | learning rate: 4.704E-05 | global batch size:   400 | lm loss: 4.871129E+00 | loss scale: 8192.0 | grad norm: 8025.595 | num zeros: 0.0 | params norm: 527.099 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration      959/    1571 | consumed samples:       243144 | consumed tokens:    497958912 | elapsed time per iteration (s): 78.73 | learning rate: 4.691E-05 | global batch size:   400 | lm loss: 4.925155E+00 | loss scale: 8192.0 | grad norm: 11358.389 | num zeros: 0.0 | params norm: 527.114 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      960/    1571 | consumed samples:       243544 | consumed tokens:    498778112 | elapsed time per iteration (s): 78.81 | learning rate: 4.678E-05 | global batch size:   400 | lm loss: 4.858986E+00 | loss scale: 8192.0 | grad norm: 8100.937 | num zeros: 0.0 | params norm: 527.128 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration      961/    1571 | consumed samples:       243944 | consumed tokens:    499597312 | elapsed time per iteration (s): 78.76 | learning rate: 4.664E-05 | global batch size:   400 | lm loss: 4.910040E+00 | loss scale: 8192.0 | grad norm: 10255.696 | num zeros: 0.0 | params norm: 527.142 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      962/    1571 | consumed samples:       244344 | consumed tokens:    500416512 | elapsed time per iteration (s): 78.87 | learning rate: 4.651E-05 | global batch size:   400 | lm loss: 4.924183E+00 | loss scale: 8192.0 | grad norm: 7932.176 | num zeros: 0.0 | params norm: 527.157 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration      963/    1571 | consumed samples:       244744 | consumed tokens:    501235712 | elapsed time per iteration (s): 78.74 | learning rate: 4.638E-05 | global batch size:   400 | lm loss: 4.897004E+00 | loss scale: 8192.0 | grad norm: 10561.345 | num zeros: 0.0 | params norm: 527.170 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration      964/    1571 | consumed samples:       245144 | consumed tokens:    502054912 | elapsed time per iteration (s): 78.85 | learning rate: 4.625E-05 | global batch size:   400 | lm loss: 4.907547E+00 | loss scale: 8192.0 | grad norm: 8147.934 | num zeros: 0.0 | params norm: 527.184 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration      965/    1571 | consumed samples:       245544 | consumed tokens:    502874112 | elapsed time per iteration (s): 78.75 | learning rate: 4.612E-05 | global batch size:   400 | lm loss: 4.887045E+00 | loss scale: 8192.0 | grad norm: 6440.602 | num zeros: 0.0 | params norm: 527.198 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      966/    1571 | consumed samples:       245944 | consumed tokens:    503693312 | elapsed time per iteration (s): 78.82 | learning rate: 4.599E-05 | global batch size:   400 | lm loss: 4.925312E+00 | loss scale: 8192.0 | grad norm: 6089.272 | num zeros: 0.0 | params norm: 527.212 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.58 |
 iteration      967/    1571 | consumed samples:       246344 | consumed tokens:    504512512 | elapsed time per iteration (s): 78.76 | learning rate: 4.586E-05 | global batch size:   400 | lm loss: 4.894480E+00 | loss scale: 8192.0 | grad norm: 6928.351 | num zeros: 0.0 | params norm: 527.226 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      968/    1571 | consumed samples:       246744 | consumed tokens:    505331712 | elapsed time per iteration (s): 78.84 | learning rate: 4.573E-05 | global batch size:   400 | lm loss: 4.862596E+00 | loss scale: 8192.0 | grad norm: 7571.155 | num zeros: 0.0 | params norm: 527.241 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.57 |
 iteration      969/    1571 | consumed samples:       247144 | consumed tokens:    506150912 | elapsed time per iteration (s): 78.73 | learning rate: 4.560E-05 | global batch size:   400 | lm loss: 4.883885E+00 | loss scale: 8192.0 | grad norm: 8896.353 | num zeros: 0.0 | params norm: 527.254 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration      970/    1571 | consumed samples:       247544 | consumed tokens:    506970112 | elapsed time per iteration (s): 78.77 | learning rate: 4.546E-05 | global batch size:   400 | lm loss: 4.898844E+00 | loss scale: 8192.0 | grad norm: 10102.175 | num zeros: 0.0 | params norm: 527.268 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      971/    1571 | consumed samples:       247944 | consumed tokens:    507789312 | elapsed time per iteration (s): 78.81 | learning rate: 4.533E-05 | global batch size:   400 | lm loss: 4.880618E+00 | loss scale: 8192.0 | grad norm: 8453.055 | num zeros: 0.0 | params norm: 527.282 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration      972/    1571 | consumed samples:       248344 | consumed tokens:    508608512 | elapsed time per iteration (s): 78.69 | learning rate: 4.520E-05 | global batch size:   400 | lm loss: 4.891558E+00 | loss scale: 8192.0 | grad norm: 10032.158 | num zeros: 0.0 | params norm: 527.296 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration      973/    1571 | consumed samples:       248744 | consumed tokens:    509427712 | elapsed time per iteration (s): 78.75 | learning rate: 4.507E-05 | global batch size:   400 | lm loss: 4.856006E+00 | loss scale: 8192.0 | grad norm: 6015.864 | num zeros: 0.0 | params norm: 527.309 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration      974/    1571 | consumed samples:       249144 | consumed tokens:    510246912 | elapsed time per iteration (s): 78.93 | learning rate: 4.494E-05 | global batch size:   400 | lm loss: 4.868176E+00 | loss scale: 8192.0 | grad norm: 6379.396 | num zeros: 0.0 | params norm: 527.323 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration      975/    1571 | consumed samples:       249544 | consumed tokens:    511066112 | elapsed time per iteration (s): 78.63 | learning rate: 4.481E-05 | global batch size:   400 | lm loss: 4.887822E+00 | loss scale: 8192.0 | grad norm: 7725.214 | num zeros: 0.0 | params norm: 527.336 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.087 | TFLOPs: 53.72 |
 iteration      976/    1571 | consumed samples:       249944 | consumed tokens:    511885312 | elapsed time per iteration (s): 78.69 | learning rate: 4.468E-05 | global batch size:   400 | lm loss: 4.888574E+00 | loss scale: 8192.0 | grad norm: 10507.169 | num zeros: 0.0 | params norm: 527.350 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.68 |
 iteration      977/    1571 | consumed samples:       250344 | consumed tokens:    512704512 | elapsed time per iteration (s): 78.87 | learning rate: 4.455E-05 | global batch size:   400 | lm loss: 4.859487E+00 | loss scale: 8192.0 | grad norm: 8554.788 | num zeros: 0.0 | params norm: 527.363 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.55 |
 iteration      978/    1571 | consumed samples:       250744 | consumed tokens:    513523712 | elapsed time per iteration (s): 78.73 | learning rate: 4.442E-05 | global batch size:   400 | lm loss: 4.862214E+00 | loss scale: 8192.0 | grad norm: 7869.851 | num zeros: 0.0 | params norm: 527.376 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      979/    1571 | consumed samples:       251144 | consumed tokens:    514342912 | elapsed time per iteration (s): 78.73 | learning rate: 4.429E-05 | global batch size:   400 | lm loss: 4.871897E+00 | loss scale: 8192.0 | grad norm: 8921.348 | num zeros: 0.0 | params norm: 527.390 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      980/    1571 | consumed samples:       251544 | consumed tokens:    515162112 | elapsed time per iteration (s): 78.91 | learning rate: 4.416E-05 | global batch size:   400 | lm loss: 4.874266E+00 | loss scale: 8192.0 | grad norm: 9431.302 | num zeros: 0.0 | params norm: 527.403 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.53 |
 iteration      981/    1571 | consumed samples:       251944 | consumed tokens:    515981312 | elapsed time per iteration (s): 78.81 | learning rate: 4.403E-05 | global batch size:   400 | lm loss: 4.859710E+00 | loss scale: 8192.0 | grad norm: 7985.656 | num zeros: 0.0 | params norm: 527.416 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.59 |
 iteration      982/    1571 | consumed samples:       252344 | consumed tokens:    516800512 | elapsed time per iteration (s): 78.72 | learning rate: 4.390E-05 | global batch size:   400 | lm loss: 4.816179E+00 | loss scale: 8192.0 | grad norm: 8490.677 | num zeros: 0.0 | params norm: 527.430 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      983/    1571 | consumed samples:       252744 | consumed tokens:    517619712 | elapsed time per iteration (s): 78.70 | learning rate: 4.377E-05 | global batch size:   400 | lm loss: 4.853956E+00 | loss scale: 8192.0 | grad norm: 8608.336 | num zeros: 0.0 | params norm: 527.443 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration      984/    1571 | consumed samples:       253144 | consumed tokens:    518438912 | elapsed time per iteration (s): 78.83 | learning rate: 4.364E-05 | global batch size:   400 | lm loss: 4.830834E+00 | loss scale: 8192.0 | grad norm: 7131.999 | num zeros: 0.0 | params norm: 527.456 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration      985/    1571 | consumed samples:       253544 | consumed tokens:    519258112 | elapsed time per iteration (s): 78.73 | learning rate: 4.351E-05 | global batch size:   400 | lm loss: 4.819893E+00 | loss scale: 8192.0 | grad norm: 7447.252 | num zeros: 0.0 | params norm: 527.469 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      986/    1571 | consumed samples:       253944 | consumed tokens:    520077312 | elapsed time per iteration (s): 78.78 | learning rate: 4.338E-05 | global batch size:   400 | lm loss: 4.853035E+00 | loss scale: 8192.0 | grad norm: 7560.647 | num zeros: 0.0 | params norm: 527.483 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration      987/    1571 | consumed samples:       254344 | consumed tokens:    520896512 | elapsed time per iteration (s): 78.70 | learning rate: 4.326E-05 | global batch size:   400 | lm loss: 4.811572E+00 | loss scale: 8192.0 | grad norm: 6367.158 | num zeros: 0.0 | params norm: 527.496 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.66 |
 iteration      988/    1571 | consumed samples:       254744 | consumed tokens:    521715712 | elapsed time per iteration (s): 78.72 | learning rate: 4.313E-05 | global batch size:   400 | lm loss: 4.820460E+00 | loss scale: 8192.0 | grad norm: 6264.154 | num zeros: 0.0 | params norm: 527.509 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration      989/    1571 | consumed samples:       255144 | consumed tokens:    522534912 | elapsed time per iteration (s): 78.66 | learning rate: 4.300E-05 | global batch size:   400 | lm loss: 4.838558E+00 | loss scale: 8192.0 | grad norm: 6839.453 | num zeros: 0.0 | params norm: 527.522 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.085 | TFLOPs: 53.69 |
 iteration      990/    1571 | consumed samples:       255544 | consumed tokens:    523354112 | elapsed time per iteration (s): 78.80 | learning rate: 4.287E-05 | global batch size:   400 | lm loss: 4.828658E+00 | loss scale: 8192.0 | grad norm: 8636.942 | num zeros: 0.0 | params norm: 527.535 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration      991/    1571 | consumed samples:       255944 | consumed tokens:    524173312 | elapsed time per iteration (s): 78.79 | learning rate: 4.274E-05 | global batch size:   400 | lm loss: 4.838766E+00 | loss scale: 8192.0 | grad norm: 12485.528 | num zeros: 0.0 | params norm: 527.548 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration      992/    1571 | consumed samples:       256344 | consumed tokens:    524992512 | elapsed time per iteration (s): 78.78 | learning rate: 4.261E-05 | global batch size:   400 | lm loss: 4.844322E+00 | loss scale: 8192.0 | grad norm: 5993.158 | num zeros: 0.0 | params norm: 527.561 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration      993/    1571 | consumed samples:       256744 | consumed tokens:    525811712 | elapsed time per iteration (s): 78.81 | learning rate: 4.248E-05 | global batch size:   400 | lm loss: 4.833992E+00 | loss scale: 8192.0 | grad norm: 6392.774 | num zeros: 0.0 | params norm: 527.574 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration      994/    1571 | consumed samples:       257144 | consumed tokens:    526630912 | elapsed time per iteration (s): 78.79 | learning rate: 4.235E-05 | global batch size:   400 | lm loss: 4.876789E+00 | loss scale: 8192.0 | grad norm: 5907.580 | num zeros: 0.0 | params norm: 527.587 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration      995/    1571 | consumed samples:       257544 | consumed tokens:    527450112 | elapsed time per iteration (s): 78.79 | learning rate: 4.223E-05 | global batch size:   400 | lm loss: 4.836306E+00 | loss scale: 8192.0 | grad norm: 6017.745 | num zeros: 0.0 | params norm: 527.600 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration      996/    1571 | consumed samples:       257944 | consumed tokens:    528269312 | elapsed time per iteration (s): 78.85 | learning rate: 4.210E-05 | global batch size:   400 | lm loss: 4.826427E+00 | loss scale: 8192.0 | grad norm: 5221.469 | num zeros: 0.0 | params norm: 527.613 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration      997/    1571 | consumed samples:       258344 | consumed tokens:    529088512 | elapsed time per iteration (s): 78.77 | learning rate: 4.197E-05 | global batch size:   400 | lm loss: 4.832641E+00 | loss scale: 8192.0 | grad norm: 7316.267 | num zeros: 0.0 | params norm: 527.626 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      998/    1571 | consumed samples:       258744 | consumed tokens:    529907712 | elapsed time per iteration (s): 78.77 | learning rate: 4.184E-05 | global batch size:   400 | lm loss: 4.807481E+00 | loss scale: 8192.0 | grad norm: 11918.385 | num zeros: 0.0 | params norm: 527.639 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration      999/    1571 | consumed samples:       259144 | consumed tokens:    530726912 | elapsed time per iteration (s): 78.82 | learning rate: 4.171E-05 | global batch size:   400 | lm loss: 4.817735E+00 | loss scale: 8192.0 | grad norm: 5984.445 | num zeros: 0.0 | params norm: 527.652 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration     1000/    1571 | consumed samples:       259544 | consumed tokens:    531546112 | elapsed time per iteration (s): 78.75 | learning rate: 4.159E-05 | global batch size:   400 | lm loss: 4.789895E+00 | loss scale: 8192.0 | grad norm: 7419.775 | num zeros: 0.0 | params norm: 527.665 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration     1001/    1571 | consumed samples:       259944 | consumed tokens:    532365312 | elapsed time per iteration (s): 668.56 | learning rate: 4.146E-05 | global batch size:   400 | lm loss: 4.831938E+00 | loss scale: 8192.0 | grad norm: 8821.579 | num zeros: 0.0 | params norm: 527.677 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.598 | TFLOPs: 6.32 |
 iteration     1002/    1571 | consumed samples:       260344 | consumed tokens:    533184512 | elapsed time per iteration (s): 79.01 | learning rate: 4.133E-05 | global batch size:   400 | lm loss: 4.829134E+00 | loss scale: 8192.0 | grad norm: 9815.353 | num zeros: 0.0 | params norm: 527.690 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.063 | TFLOPs: 53.46 |
 iteration     1003/    1571 | consumed samples:       260744 | consumed tokens:    534003712 | elapsed time per iteration (s): 78.68 | learning rate: 4.120E-05 | global batch size:   400 | lm loss: 4.823661E+00 | loss scale: 8192.0 | grad norm: 7420.291 | num zeros: 0.0 | params norm: 527.702 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.68 |
 iteration     1004/    1571 | consumed samples:       261144 | consumed tokens:    534822912 | elapsed time per iteration (s): 78.74 | learning rate: 4.108E-05 | global batch size:   400 | lm loss: 4.749252E+00 | loss scale: 8192.0 | grad norm: 8416.991 | num zeros: 0.0 | params norm: 527.715 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration     1005/    1571 | consumed samples:       261544 | consumed tokens:    535642112 | elapsed time per iteration (s): 78.83 | learning rate: 4.095E-05 | global batch size:   400 | lm loss: 4.804475E+00 | loss scale: 8192.0 | grad norm: 8998.125 | num zeros: 0.0 | params norm: 527.727 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration     1006/    1571 | consumed samples:       261944 | consumed tokens:    536461312 | elapsed time per iteration (s): 78.86 | learning rate: 4.082E-05 | global batch size:   400 | lm loss: 4.794653E+00 | loss scale: 8192.0 | grad norm: 6894.183 | num zeros: 0.0 | params norm: 527.740 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1007/    1571 | consumed samples:       262344 | consumed tokens:    537280512 | elapsed time per iteration (s): 78.84 | learning rate: 4.070E-05 | global batch size:   400 | lm loss: 4.826859E+00 | loss scale: 8192.0 | grad norm: 7603.442 | num zeros: 0.0 | params norm: 527.752 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.57 |
 iteration     1008/    1571 | consumed samples:       262744 | consumed tokens:    538099712 | elapsed time per iteration (s): 78.83 | learning rate: 4.057E-05 | global batch size:   400 | lm loss: 4.827784E+00 | loss scale: 8192.0 | grad norm: 7978.580 | num zeros: 0.0 | params norm: 527.765 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration     1009/    1571 | consumed samples:       263144 | consumed tokens:    538918912 | elapsed time per iteration (s): 78.84 | learning rate: 4.044E-05 | global batch size:   400 | lm loss: 4.772803E+00 | loss scale: 8192.0 | grad norm: 8316.288 | num zeros: 0.0 | params norm: 527.777 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1010/    1571 | consumed samples:       263544 | consumed tokens:    539738112 | elapsed time per iteration (s): 78.75 | learning rate: 4.032E-05 | global batch size:   400 | lm loss: 4.833312E+00 | loss scale: 8192.0 | grad norm: 9325.625 | num zeros: 0.0 | params norm: 527.789 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration     1011/    1571 | consumed samples:       263944 | consumed tokens:    540557312 | elapsed time per iteration (s): 78.74 | learning rate: 4.019E-05 | global batch size:   400 | lm loss: 4.789080E+00 | loss scale: 8192.0 | grad norm: 7634.026 | num zeros: 0.0 | params norm: 527.801 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration     1012/    1571 | consumed samples:       264344 | consumed tokens:    541376512 | elapsed time per iteration (s): 78.89 | learning rate: 4.006E-05 | global batch size:   400 | lm loss: 4.830881E+00 | loss scale: 8192.0 | grad norm: 8385.799 | num zeros: 0.0 | params norm: 527.813 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.54 |
 iteration     1013/    1571 | consumed samples:       264744 | consumed tokens:    542195712 | elapsed time per iteration (s): 78.79 | learning rate: 3.994E-05 | global batch size:   400 | lm loss: 4.792792E+00 | loss scale: 8192.0 | grad norm: 8760.056 | num zeros: 0.0 | params norm: 527.825 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration     1014/    1571 | consumed samples:       265144 | consumed tokens:    543014912 | elapsed time per iteration (s): 78.88 | learning rate: 3.981E-05 | global batch size:   400 | lm loss: 4.814910E+00 | loss scale: 8192.0 | grad norm: 7697.053 | num zeros: 0.0 | params norm: 527.837 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1015/    1571 | consumed samples:       265544 | consumed tokens:    543834112 | elapsed time per iteration (s): 78.80 | learning rate: 3.969E-05 | global batch size:   400 | lm loss: 4.786034E+00 | loss scale: 8192.0 | grad norm: 8141.722 | num zeros: 0.0 | params norm: 527.849 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration     1016/    1571 | consumed samples:       265944 | consumed tokens:    544653312 | elapsed time per iteration (s): 78.85 | learning rate: 3.956E-05 | global batch size:   400 | lm loss: 4.805804E+00 | loss scale: 8192.0 | grad norm: 7172.054 | num zeros: 0.0 | params norm: 527.861 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1017/    1571 | consumed samples:       266344 | consumed tokens:    545472512 | elapsed time per iteration (s): 78.82 | learning rate: 3.943E-05 | global batch size:   400 | lm loss: 4.776240E+00 | loss scale: 8192.0 | grad norm: 7480.468 | num zeros: 0.0 | params norm: 527.874 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration     1018/    1571 | consumed samples:       266744 | consumed tokens:    546291712 | elapsed time per iteration (s): 78.79 | learning rate: 3.931E-05 | global batch size:   400 | lm loss: 4.824523E+00 | loss scale: 8192.0 | grad norm: 7634.473 | num zeros: 0.0 | params norm: 527.885 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration     1019/    1571 | consumed samples:       267144 | consumed tokens:    547110912 | elapsed time per iteration (s): 78.80 | learning rate: 3.918E-05 | global batch size:   400 | lm loss: 4.768909E+00 | loss scale: 8192.0 | grad norm: 6302.195 | num zeros: 0.0 | params norm: 527.897 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration     1020/    1571 | consumed samples:       267544 | consumed tokens:    547930112 | elapsed time per iteration (s): 78.90 | learning rate: 3.906E-05 | global batch size:   400 | lm loss: 4.747616E+00 | loss scale: 8192.0 | grad norm: 5702.949 | num zeros: 0.0 | params norm: 527.909 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.53 |
 iteration     1021/    1571 | consumed samples:       267944 | consumed tokens:    548749312 | elapsed time per iteration (s): 78.83 | learning rate: 3.893E-05 | global batch size:   400 | lm loss: 4.770269E+00 | loss scale: 8192.0 | grad norm: 5402.409 | num zeros: 0.0 | params norm: 527.921 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration     1022/    1571 | consumed samples:       268344 | consumed tokens:    549568512 | elapsed time per iteration (s): 78.82 | learning rate: 3.881E-05 | global batch size:   400 | lm loss: 4.777567E+00 | loss scale: 8192.0 | grad norm: 6159.546 | num zeros: 0.0 | params norm: 527.933 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration     1023/    1571 | consumed samples:       268744 | consumed tokens:    550387712 | elapsed time per iteration (s): 78.86 | learning rate: 3.868E-05 | global batch size:   400 | lm loss: 4.770597E+00 | loss scale: 8192.0 | grad norm: 8846.517 | num zeros: 0.0 | params norm: 527.945 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1024/    1571 | consumed samples:       269144 | consumed tokens:    551206912 | elapsed time per iteration (s): 78.87 | learning rate: 3.856E-05 | global batch size:   400 | lm loss: 4.794201E+00 | loss scale: 8192.0 | grad norm: 10513.479 | num zeros: 0.0 | params norm: 527.956 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.55 |
 iteration     1025/    1571 | consumed samples:       269544 | consumed tokens:    552026112 | elapsed time per iteration (s): 78.80 | learning rate: 3.843E-05 | global batch size:   400 | lm loss: 4.780478E+00 | loss scale: 8192.0 | grad norm: 8284.203 | num zeros: 0.0 | params norm: 527.968 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration     1026/    1571 | consumed samples:       269944 | consumed tokens:    552845312 | elapsed time per iteration (s): 78.85 | learning rate: 3.831E-05 | global batch size:   400 | lm loss: 4.779215E+00 | loss scale: 8192.0 | grad norm: 9247.039 | num zeros: 0.0 | params norm: 527.979 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1027/    1571 | consumed samples:       270344 | consumed tokens:    553664512 | elapsed time per iteration (s): 78.86 | learning rate: 3.819E-05 | global batch size:   400 | lm loss: 4.801440E+00 | loss scale: 8192.0 | grad norm: 5163.293 | num zeros: 0.0 | params norm: 527.990 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1028/    1571 | consumed samples:       270744 | consumed tokens:    554483712 | elapsed time per iteration (s): 78.82 | learning rate: 3.806E-05 | global batch size:   400 | lm loss: 4.741557E+00 | loss scale: 8192.0 | grad norm: 6080.376 | num zeros: 0.0 | params norm: 528.002 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration     1029/    1571 | consumed samples:       271144 | consumed tokens:    555302912 | elapsed time per iteration (s): 78.87 | learning rate: 3.794E-05 | global batch size:   400 | lm loss: 4.788214E+00 | loss scale: 8192.0 | grad norm: 5320.127 | num zeros: 0.0 | params norm: 528.013 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1030/    1571 | consumed samples:       271544 | consumed tokens:    556122112 | elapsed time per iteration (s): 78.78 | learning rate: 3.781E-05 | global batch size:   400 | lm loss: 4.745447E+00 | loss scale: 8192.0 | grad norm: 6044.392 | num zeros: 0.0 | params norm: 528.024 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration     1031/    1571 | consumed samples:       271944 | consumed tokens:    556941312 | elapsed time per iteration (s): 78.73 | learning rate: 3.769E-05 | global batch size:   400 | lm loss: 4.732935E+00 | loss scale: 8192.0 | grad norm: 7176.692 | num zeros: 0.0 | params norm: 528.036 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration     1032/    1571 | consumed samples:       272344 | consumed tokens:    557760512 | elapsed time per iteration (s): 78.86 | learning rate: 3.757E-05 | global batch size:   400 | lm loss: 4.778842E+00 | loss scale: 8192.0 | grad norm: 10470.369 | num zeros: 0.0 | params norm: 528.047 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1033/    1571 | consumed samples:       272744 | consumed tokens:    558579712 | elapsed time per iteration (s): 78.67 | learning rate: 3.744E-05 | global batch size:   400 | lm loss: 4.785394E+00 | loss scale: 8192.0 | grad norm: 9117.505 | num zeros: 0.0 | params norm: 528.058 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.69 |
 iteration     1034/    1571 | consumed samples:       273144 | consumed tokens:    559398912 | elapsed time per iteration (s): 78.73 | learning rate: 3.732E-05 | global batch size:   400 | lm loss: 4.762729E+00 | loss scale: 8192.0 | grad norm: 7968.214 | num zeros: 0.0 | params norm: 528.069 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration     1035/    1571 | consumed samples:       273544 | consumed tokens:    560218112 | elapsed time per iteration (s): 78.85 | learning rate: 3.720E-05 | global batch size:   400 | lm loss: 4.752782E+00 | loss scale: 8192.0 | grad norm: 9030.208 | num zeros: 0.0 | params norm: 528.080 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1036/    1571 | consumed samples:       273944 | consumed tokens:    561037312 | elapsed time per iteration (s): 78.81 | learning rate: 3.708E-05 | global batch size:   400 | lm loss: 4.810703E+00 | loss scale: 8192.0 | grad norm: 7855.151 | num zeros: 0.0 | params norm: 528.091 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration     1037/    1571 | consumed samples:       274344 | consumed tokens:    561856512 | elapsed time per iteration (s): 78.80 | learning rate: 3.695E-05 | global batch size:   400 | lm loss: 4.750378E+00 | loss scale: 8192.0 | grad norm: 7246.563 | num zeros: 0.0 | params norm: 528.102 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration     1038/    1571 | consumed samples:       274744 | consumed tokens:    562675712 | elapsed time per iteration (s): 78.81 | learning rate: 3.683E-05 | global batch size:   400 | lm loss: 4.766294E+00 | loss scale: 8192.0 | grad norm: 6819.499 | num zeros: 0.0 | params norm: 528.112 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration     1039/    1571 | consumed samples:       275144 | consumed tokens:    563494912 | elapsed time per iteration (s): 78.75 | learning rate: 3.671E-05 | global batch size:   400 | lm loss: 4.762269E+00 | loss scale: 8192.0 | grad norm: 6914.077 | num zeros: 0.0 | params norm: 528.123 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration     1040/    1571 | consumed samples:       275544 | consumed tokens:    564314112 | elapsed time per iteration (s): 78.82 | learning rate: 3.659E-05 | global batch size:   400 | lm loss: 4.746139E+00 | loss scale: 8192.0 | grad norm: 8289.570 | num zeros: 0.0 | params norm: 528.134 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration     1041/    1571 | consumed samples:       275944 | consumed tokens:    565133312 | elapsed time per iteration (s): 78.76 | learning rate: 3.646E-05 | global batch size:   400 | lm loss: 4.748358E+00 | loss scale: 8192.0 | grad norm: 11209.040 | num zeros: 0.0 | params norm: 528.145 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration     1042/    1571 | consumed samples:       276344 | consumed tokens:    565952512 | elapsed time per iteration (s): 78.85 | learning rate: 3.634E-05 | global batch size:   400 | lm loss: 4.720123E+00 | loss scale: 8192.0 | grad norm: 5986.145 | num zeros: 0.0 | params norm: 528.156 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1043/    1571 | consumed samples:       276744 | consumed tokens:    566771712 | elapsed time per iteration (s): 78.82 | learning rate: 3.622E-05 | global batch size:   400 | lm loss: 4.747277E+00 | loss scale: 8192.0 | grad norm: 6959.646 | num zeros: 0.0 | params norm: 528.167 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.58 |
 iteration     1044/    1571 | consumed samples:       277144 | consumed tokens:    567590912 | elapsed time per iteration (s): 78.91 | learning rate: 3.610E-05 | global batch size:   400 | lm loss: 4.711565E+00 | loss scale: 8192.0 | grad norm: 9535.009 | num zeros: 0.0 | params norm: 528.177 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.53 |
 iteration     1045/    1571 | consumed samples:       277544 | consumed tokens:    568410112 | elapsed time per iteration (s): 78.78 | learning rate: 3.598E-05 | global batch size:   400 | lm loss: 4.744478E+00 | loss scale: 8192.0 | grad norm: 9406.159 | num zeros: 0.0 | params norm: 528.188 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration     1046/    1571 | consumed samples:       277944 | consumed tokens:    569229312 | elapsed time per iteration (s): 78.85 | learning rate: 3.586E-05 | global batch size:   400 | lm loss: 4.768669E+00 | loss scale: 8192.0 | grad norm: 9702.500 | num zeros: 0.0 | params norm: 528.198 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1047/    1571 | consumed samples:       278344 | consumed tokens:    570048512 | elapsed time per iteration (s): 78.74 | learning rate: 3.574E-05 | global batch size:   400 | lm loss: 4.717748E+00 | loss scale: 8192.0 | grad norm: 8482.760 | num zeros: 0.0 | params norm: 528.209 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration     1048/    1571 | consumed samples:       278744 | consumed tokens:    570867712 | elapsed time per iteration (s): 78.79 | learning rate: 3.562E-05 | global batch size:   400 | lm loss: 4.721087E+00 | loss scale: 8192.0 | grad norm: 6683.630 | num zeros: 0.0 | params norm: 528.219 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.60 |
 iteration     1049/    1571 | consumed samples:       279144 | consumed tokens:    571686912 | elapsed time per iteration (s): 78.87 | learning rate: 3.549E-05 | global batch size:   400 | lm loss: 4.700530E+00 | loss scale: 8192.0 | grad norm: 6438.712 | num zeros: 0.0 | params norm: 528.230 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1050/    1571 | consumed samples:       279544 | consumed tokens:    572506112 | elapsed time per iteration (s): 78.84 | learning rate: 3.537E-05 | global batch size:   400 | lm loss: 4.707014E+00 | loss scale: 8192.0 | grad norm: 7142.404 | num zeros: 0.0 | params norm: 528.240 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration     1051/    1571 | consumed samples:       279944 | consumed tokens:    573325312 | elapsed time per iteration (s): 78.91 | learning rate: 3.525E-05 | global batch size:   400 | lm loss: 4.721977E+00 | loss scale: 8192.0 | grad norm: 7059.876 | num zeros: 0.0 | params norm: 528.251 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.52 |
 iteration     1052/    1571 | consumed samples:       280344 | consumed tokens:    574144512 | elapsed time per iteration (s): 78.80 | learning rate: 3.513E-05 | global batch size:   400 | lm loss: 4.720260E+00 | loss scale: 8192.0 | grad norm: 7129.832 | num zeros: 0.0 | params norm: 528.262 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration     1053/    1571 | consumed samples:       280744 | consumed tokens:    574963712 | elapsed time per iteration (s): 78.74 | learning rate: 3.501E-05 | global batch size:   400 | lm loss: 4.706574E+00 | loss scale: 8192.0 | grad norm: 6640.081 | num zeros: 0.0 | params norm: 528.272 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration     1054/    1571 | consumed samples:       281144 | consumed tokens:    575782912 | elapsed time per iteration (s): 78.92 | learning rate: 3.489E-05 | global batch size:   400 | lm loss: 4.741734E+00 | loss scale: 8192.0 | grad norm: 9210.032 | num zeros: 0.0 | params norm: 528.283 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.52 |
 iteration     1055/    1571 | consumed samples:       281544 | consumed tokens:    576602112 | elapsed time per iteration (s): 78.73 | learning rate: 3.477E-05 | global batch size:   400 | lm loss: 4.729209E+00 | loss scale: 8192.0 | grad norm: 9252.853 | num zeros: 0.0 | params norm: 528.293 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration     1056/    1571 | consumed samples:       281944 | consumed tokens:    577421312 | elapsed time per iteration (s): 78.84 | learning rate: 3.466E-05 | global batch size:   400 | lm loss: 4.715024E+00 | loss scale: 8192.0 | grad norm: 6073.913 | num zeros: 0.0 | params norm: 528.303 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.57 |
 iteration     1057/    1571 | consumed samples:       282344 | consumed tokens:    578240512 | elapsed time per iteration (s): 78.78 | learning rate: 3.454E-05 | global batch size:   400 | lm loss: 4.712311E+00 | loss scale: 8192.0 | grad norm: 6566.382 | num zeros: 0.0 | params norm: 528.313 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration     1058/    1571 | consumed samples:       282744 | consumed tokens:    579059712 | elapsed time per iteration (s): 78.78 | learning rate: 3.442E-05 | global batch size:   400 | lm loss: 4.759119E+00 | loss scale: 8192.0 | grad norm: 7658.602 | num zeros: 0.0 | params norm: 528.323 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration     1059/    1571 | consumed samples:       283144 | consumed tokens:    579878912 | elapsed time per iteration (s): 78.79 | learning rate: 3.430E-05 | global batch size:   400 | lm loss: 4.723535E+00 | loss scale: 8192.0 | grad norm: 6845.558 | num zeros: 0.0 | params norm: 528.333 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration     1060/    1571 | consumed samples:       283544 | consumed tokens:    580698112 | elapsed time per iteration (s): 78.87 | learning rate: 3.418E-05 | global batch size:   400 | lm loss: 4.701659E+00 | loss scale: 8192.0 | grad norm: 5325.559 | num zeros: 0.0 | params norm: 528.343 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.55 |
 iteration     1061/    1571 | consumed samples:       283944 | consumed tokens:    581517312 | elapsed time per iteration (s): 78.89 | learning rate: 3.406E-05 | global batch size:   400 | lm loss: 4.711658E+00 | loss scale: 8192.0 | grad norm: 6617.080 | num zeros: 0.0 | params norm: 528.353 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.54 |
 iteration     1062/    1571 | consumed samples:       284344 | consumed tokens:    582336512 | elapsed time per iteration (s): 78.92 | learning rate: 3.394E-05 | global batch size:   400 | lm loss: 4.661273E+00 | loss scale: 8192.0 | grad norm: 6355.846 | num zeros: 0.0 | params norm: 528.364 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.52 |
 iteration     1063/    1571 | consumed samples:       284744 | consumed tokens:    583155712 | elapsed time per iteration (s): 78.88 | learning rate: 3.382E-05 | global batch size:   400 | lm loss: 4.669555E+00 | loss scale: 8192.0 | grad norm: 6990.226 | num zeros: 0.0 | params norm: 528.374 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1064/    1571 | consumed samples:       285144 | consumed tokens:    583974912 | elapsed time per iteration (s): 78.87 | learning rate: 3.371E-05 | global batch size:   400 | lm loss: 4.686935E+00 | loss scale: 8192.0 | grad norm: 8180.140 | num zeros: 0.0 | params norm: 528.384 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.55 |
 iteration     1065/    1571 | consumed samples:       285544 | consumed tokens:    584794112 | elapsed time per iteration (s): 78.86 | learning rate: 3.359E-05 | global batch size:   400 | lm loss: 4.717162E+00 | loss scale: 8192.0 | grad norm: 7690.319 | num zeros: 0.0 | params norm: 528.394 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.56 |
 iteration     1066/    1571 | consumed samples:       285944 | consumed tokens:    585613312 | elapsed time per iteration (s): 78.77 | learning rate: 3.347E-05 | global batch size:   400 | lm loss: 4.697054E+00 | loss scale: 8192.0 | grad norm: 8436.802 | num zeros: 0.0 | params norm: 528.404 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration     1067/    1571 | consumed samples:       286344 | consumed tokens:    586432512 | elapsed time per iteration (s): 78.79 | learning rate: 3.335E-05 | global batch size:   400 | lm loss: 4.694446E+00 | loss scale: 8192.0 | grad norm: 7035.257 | num zeros: 0.0 | params norm: 528.413 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration     1068/    1571 | consumed samples:       286744 | consumed tokens:    587251712 | elapsed time per iteration (s): 78.97 | learning rate: 3.324E-05 | global batch size:   400 | lm loss: 4.705789E+00 | loss scale: 8192.0 | grad norm: 6147.361 | num zeros: 0.0 | params norm: 528.423 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1069/    1571 | consumed samples:       287144 | consumed tokens:    588070912 | elapsed time per iteration (s): 78.77 | learning rate: 3.312E-05 | global batch size:   400 | lm loss: 4.700686E+00 | loss scale: 8192.0 | grad norm: 5702.564 | num zeros: 0.0 | params norm: 528.433 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration     1070/    1571 | consumed samples:       287544 | consumed tokens:    588890112 | elapsed time per iteration (s): 78.94 | learning rate: 3.300E-05 | global batch size:   400 | lm loss: 4.683311E+00 | loss scale: 8192.0 | grad norm: 7015.102 | num zeros: 0.0 | params norm: 528.443 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1071/    1571 | consumed samples:       287944 | consumed tokens:    589709312 | elapsed time per iteration (s): 78.82 | learning rate: 3.289E-05 | global batch size:   400 | lm loss: 4.706005E+00 | loss scale: 8192.0 | grad norm: 7846.723 | num zeros: 0.0 | params norm: 528.453 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.58 |
 iteration     1072/    1571 | consumed samples:       288344 | consumed tokens:    590528512 | elapsed time per iteration (s): 78.86 | learning rate: 3.277E-05 | global batch size:   400 | lm loss: 4.693712E+00 | loss scale: 8192.0 | grad norm: 8164.994 | num zeros: 0.0 | params norm: 528.462 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.56 |
 iteration     1073/    1571 | consumed samples:       288744 | consumed tokens:    591347712 | elapsed time per iteration (s): 78.73 | learning rate: 3.265E-05 | global batch size:   400 | lm loss: 4.721865E+00 | loss scale: 8192.0 | grad norm: 8253.219 | num zeros: 0.0 | params norm: 528.472 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration     1074/    1571 | consumed samples:       289144 | consumed tokens:    592166912 | elapsed time per iteration (s): 78.74 | learning rate: 3.254E-05 | global batch size:   400 | lm loss: 4.708619E+00 | loss scale: 8192.0 | grad norm: 8143.670 | num zeros: 0.0 | params norm: 528.482 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration     1075/    1571 | consumed samples:       289544 | consumed tokens:    592986112 | elapsed time per iteration (s): 78.70 | learning rate: 3.242E-05 | global batch size:   400 | lm loss: 4.714331E+00 | loss scale: 8192.0 | grad norm: 8977.782 | num zeros: 0.0 | params norm: 528.491 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration     1076/    1571 | consumed samples:       289944 | consumed tokens:    593805312 | elapsed time per iteration (s): 78.73 | learning rate: 3.231E-05 | global batch size:   400 | lm loss: 4.694756E+00 | loss scale: 8192.0 | grad norm: 6794.344 | num zeros: 0.0 | params norm: 528.501 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration     1077/    1571 | consumed samples:       290344 | consumed tokens:    594624512 | elapsed time per iteration (s): 78.70 | learning rate: 3.219E-05 | global batch size:   400 | lm loss: 4.712607E+00 | loss scale: 8192.0 | grad norm: 6986.273 | num zeros: 0.0 | params norm: 528.510 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration     1078/    1571 | consumed samples:       290744 | consumed tokens:    595443712 | elapsed time per iteration (s): 78.81 | learning rate: 3.208E-05 | global batch size:   400 | lm loss: 4.674400E+00 | loss scale: 8192.0 | grad norm: 5746.146 | num zeros: 0.0 | params norm: 528.519 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.59 |
 iteration     1079/    1571 | consumed samples:       291144 | consumed tokens:    596262912 | elapsed time per iteration (s): 78.82 | learning rate: 3.196E-05 | global batch size:   400 | lm loss: 4.689821E+00 | loss scale: 8192.0 | grad norm: 5970.681 | num zeros: 0.0 | params norm: 528.529 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration     1080/    1571 | consumed samples:       291544 | consumed tokens:    597082112 | elapsed time per iteration (s): 78.80 | learning rate: 3.185E-05 | global batch size:   400 | lm loss: 4.678591E+00 | loss scale: 8192.0 | grad norm: 6587.245 | num zeros: 0.0 | params norm: 528.538 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration     1081/    1571 | consumed samples:       291944 | consumed tokens:    597901312 | elapsed time per iteration (s): 78.77 | learning rate: 3.173E-05 | global batch size:   400 | lm loss: 4.695728E+00 | loss scale: 8192.0 | grad norm: 6652.580 | num zeros: 0.0 | params norm: 528.548 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration     1082/    1571 | consumed samples:       292344 | consumed tokens:    598720512 | elapsed time per iteration (s): 78.94 | learning rate: 3.162E-05 | global batch size:   400 | lm loss: 4.674859E+00 | loss scale: 8192.0 | grad norm: 6859.235 | num zeros: 0.0 | params norm: 528.557 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.51 |
 iteration     1083/    1571 | consumed samples:       292744 | consumed tokens:    599539712 | elapsed time per iteration (s): 78.83 | learning rate: 3.150E-05 | global batch size:   400 | lm loss: 4.659068E+00 | loss scale: 8192.0 | grad norm: 6593.685 | num zeros: 0.0 | params norm: 528.566 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration     1084/    1571 | consumed samples:       293144 | consumed tokens:    600358912 | elapsed time per iteration (s): 78.80 | learning rate: 3.139E-05 | global batch size:   400 | lm loss: 4.673949E+00 | loss scale: 8192.0 | grad norm: 7711.191 | num zeros: 0.0 | params norm: 528.575 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration     1085/    1571 | consumed samples:       293544 | consumed tokens:    601178112 | elapsed time per iteration (s): 78.84 | learning rate: 3.128E-05 | global batch size:   400 | lm loss: 4.672943E+00 | loss scale: 8192.0 | grad norm: 7041.293 | num zeros: 0.0 | params norm: 528.584 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.57 |
 iteration     1086/    1571 | consumed samples:       293944 | consumed tokens:    601997312 | elapsed time per iteration (s): 78.80 | learning rate: 3.116E-05 | global batch size:   400 | lm loss: 4.679448E+00 | loss scale: 8192.0 | grad norm: 5266.474 | num zeros: 0.0 | params norm: 528.593 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration     1087/    1571 | consumed samples:       294344 | consumed tokens:    602816512 | elapsed time per iteration (s): 78.76 | learning rate: 3.105E-05 | global batch size:   400 | lm loss: 4.693593E+00 | loss scale: 8192.0 | grad norm: 6246.946 | num zeros: 0.0 | params norm: 528.602 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration     1088/    1571 | consumed samples:       294744 | consumed tokens:    603635712 | elapsed time per iteration (s): 78.93 | learning rate: 3.094E-05 | global batch size:   400 | lm loss: 4.661216E+00 | loss scale: 8192.0 | grad norm: 8103.404 | num zeros: 0.0 | params norm: 528.611 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.51 |
 iteration     1089/    1571 | consumed samples:       295144 | consumed tokens:    604454912 | elapsed time per iteration (s): 78.82 | learning rate: 3.082E-05 | global batch size:   400 | lm loss: 4.654571E+00 | loss scale: 8192.0 | grad norm: 10415.981 | num zeros: 0.0 | params norm: 528.620 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.58 |
 iteration     1090/    1571 | consumed samples:       295544 | consumed tokens:    605274112 | elapsed time per iteration (s): 78.77 | learning rate: 3.071E-05 | global batch size:   400 | lm loss: 4.665564E+00 | loss scale: 8192.0 | grad norm: 5684.749 | num zeros: 0.0 | params norm: 528.629 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration     1091/    1571 | consumed samples:       295944 | consumed tokens:    606093312 | elapsed time per iteration (s): 78.87 | learning rate: 3.060E-05 | global batch size:   400 | lm loss: 4.655632E+00 | loss scale: 8192.0 | grad norm: 7330.807 | num zeros: 0.0 | params norm: 528.638 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.55 |
 iteration     1092/    1571 | consumed samples:       296344 | consumed tokens:    606912512 | elapsed time per iteration (s): 78.91 | learning rate: 3.048E-05 | global batch size:   400 | lm loss: 4.657914E+00 | loss scale: 8192.0 | grad norm: 8367.354 | num zeros: 0.0 | params norm: 528.647 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.52 |
 iteration     1093/    1571 | consumed samples:       296744 | consumed tokens:    607731712 | elapsed time per iteration (s): 78.78 | learning rate: 3.037E-05 | global batch size:   400 | lm loss: 4.673248E+00 | loss scale: 8192.0 | grad norm: 5361.799 | num zeros: 0.0 | params norm: 528.656 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration     1094/    1571 | consumed samples:       297144 | consumed tokens:    608550912 | elapsed time per iteration (s): 78.87 | learning rate: 3.026E-05 | global batch size:   400 | lm loss: 4.671159E+00 | loss scale: 8192.0 | grad norm: 6767.727 | num zeros: 0.0 | params norm: 528.664 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.55 |
 iteration     1095/    1571 | consumed samples:       297544 | consumed tokens:    609370112 | elapsed time per iteration (s): 78.88 | learning rate: 3.015E-05 | global batch size:   400 | lm loss: 4.640046E+00 | loss scale: 8192.0 | grad norm: 5940.762 | num zeros: 0.0 | params norm: 528.673 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1096/    1571 | consumed samples:       297944 | consumed tokens:    610189312 | elapsed time per iteration (s): 78.80 | learning rate: 3.004E-05 | global batch size:   400 | lm loss: 4.656381E+00 | loss scale: 8192.0 | grad norm: 5685.599 | num zeros: 0.0 | params norm: 528.682 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration     1097/    1571 | consumed samples:       298344 | consumed tokens:    611008512 | elapsed time per iteration (s): 78.80 | learning rate: 2.993E-05 | global batch size:   400 | lm loss: 4.633583E+00 | loss scale: 8192.0 | grad norm: 6749.596 | num zeros: 0.0 | params norm: 528.690 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration     1098/    1571 | consumed samples:       298744 | consumed tokens:    611827712 | elapsed time per iteration (s): 78.94 | learning rate: 2.982E-05 | global batch size:   400 | lm loss: 4.626621E+00 | loss scale: 8192.0 | grad norm: 6803.986 | num zeros: 0.0 | params norm: 528.699 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.51 |
 iteration     1099/    1571 | consumed samples:       299144 | consumed tokens:    612646912 | elapsed time per iteration (s): 78.73 | learning rate: 2.971E-05 | global batch size:   400 | lm loss: 4.659618E+00 | loss scale: 8192.0 | grad norm: 8320.958 | num zeros: 0.0 | params norm: 528.707 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration     1100/    1571 | consumed samples:       299544 | consumed tokens:    613466112 | elapsed time per iteration (s): 78.84 | learning rate: 2.959E-05 | global batch size:   400 | lm loss: 4.639924E+00 | loss scale: 8192.0 | grad norm: 8530.415 | num zeros: 0.0 | params norm: 528.716 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.57 |
 iteration     1101/    1571 | consumed samples:       299944 | consumed tokens:    614285312 | elapsed time per iteration (s): 78.90 | learning rate: 2.948E-05 | global batch size:   400 | lm loss: 4.647447E+00 | loss scale: 8192.0 | grad norm: 6924.709 | num zeros: 0.0 | params norm: 528.724 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.53 |
 iteration     1102/    1571 | consumed samples:       300344 | consumed tokens:    615104512 | elapsed time per iteration (s): 78.89 | learning rate: 2.937E-05 | global batch size:   400 | lm loss: 4.633670E+00 | loss scale: 8192.0 | grad norm: 7528.388 | num zeros: 0.0 | params norm: 528.733 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.54 |
 iteration     1103/    1571 | consumed samples:       300744 | consumed tokens:    615923712 | elapsed time per iteration (s): 78.78 | learning rate: 2.926E-05 | global batch size:   400 | lm loss: 4.636549E+00 | loss scale: 8192.0 | grad norm: 7472.365 | num zeros: 0.0 | params norm: 528.742 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.61 |
 iteration     1104/    1571 | consumed samples:       301144 | consumed tokens:    616742912 | elapsed time per iteration (s): 78.87 | learning rate: 2.915E-05 | global batch size:   400 | lm loss: 4.593756E+00 | loss scale: 8192.0 | grad norm: 7148.879 | num zeros: 0.0 | params norm: 528.750 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.55 |
 iteration     1105/    1571 | consumed samples:       301544 | consumed tokens:    617562112 | elapsed time per iteration (s): 78.86 | learning rate: 2.905E-05 | global batch size:   400 | lm loss: 4.716724E+00 | loss scale: 8192.0 | grad norm: 7954.843 | num zeros: 0.0 | params norm: 528.759 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.56 |
 iteration     1106/    1571 | consumed samples:       301944 | consumed tokens:    618381312 | elapsed time per iteration (s): 78.85 | learning rate: 2.894E-05 | global batch size:   400 | lm loss: 4.642425E+00 | loss scale: 8192.0 | grad norm: 7710.029 | num zeros: 0.0 | params norm: 528.767 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1107/    1571 | consumed samples:       302344 | consumed tokens:    619200512 | elapsed time per iteration (s): 78.88 | learning rate: 2.883E-05 | global batch size:   400 | lm loss: 4.688676E+00 | loss scale: 8192.0 | grad norm: 7891.528 | num zeros: 0.0 | params norm: 528.776 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1108/    1571 | consumed samples:       302744 | consumed tokens:    620019712 | elapsed time per iteration (s): 78.82 | learning rate: 2.872E-05 | global batch size:   400 | lm loss: 4.650138E+00 | loss scale: 8192.0 | grad norm: 8913.553 | num zeros: 0.0 | params norm: 528.784 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration     1109/    1571 | consumed samples:       303144 | consumed tokens:    620838912 | elapsed time per iteration (s): 78.78 | learning rate: 2.861E-05 | global batch size:   400 | lm loss: 4.633650E+00 | loss scale: 8192.0 | grad norm: 7163.560 | num zeros: 0.0 | params norm: 528.792 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration     1110/    1571 | consumed samples:       303544 | consumed tokens:    621658112 | elapsed time per iteration (s): 78.88 | learning rate: 2.850E-05 | global batch size:   400 | lm loss: 4.658075E+00 | loss scale: 8192.0 | grad norm: 8220.410 | num zeros: 0.0 | params norm: 528.801 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1111/    1571 | consumed samples:       303944 | consumed tokens:    622477312 | elapsed time per iteration (s): 78.86 | learning rate: 2.839E-05 | global batch size:   400 | lm loss: 4.619471E+00 | loss scale: 8192.0 | grad norm: 8478.606 | num zeros: 0.0 | params norm: 528.809 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1112/    1571 | consumed samples:       304344 | consumed tokens:    623296512 | elapsed time per iteration (s): 78.87 | learning rate: 2.829E-05 | global batch size:   400 | lm loss: 4.608659E+00 | loss scale: 8192.0 | grad norm: 5442.471 | num zeros: 0.0 | params norm: 528.817 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.55 |
 iteration     1113/    1571 | consumed samples:       304744 | consumed tokens:    624115712 | elapsed time per iteration (s): 78.85 | learning rate: 2.818E-05 | global batch size:   400 | lm loss: 4.629414E+00 | loss scale: 8192.0 | grad norm: 5865.457 | num zeros: 0.0 | params norm: 528.825 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.56 |
 iteration     1114/    1571 | consumed samples:       305144 | consumed tokens:    624934912 | elapsed time per iteration (s): 78.83 | learning rate: 2.807E-05 | global batch size:   400 | lm loss: 4.637135E+00 | loss scale: 8192.0 | grad norm: 6164.427 | num zeros: 0.0 | params norm: 528.833 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration     1115/    1571 | consumed samples:       305544 | consumed tokens:    625754112 | elapsed time per iteration (s): 78.82 | learning rate: 2.796E-05 | global batch size:   400 | lm loss: 4.600083E+00 | loss scale: 8192.0 | grad norm: 5055.471 | num zeros: 0.0 | params norm: 528.841 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration     1116/    1571 | consumed samples:       305944 | consumed tokens:    626573312 | elapsed time per iteration (s): 78.90 | learning rate: 2.786E-05 | global batch size:   400 | lm loss: 4.624705E+00 | loss scale: 8192.0 | grad norm: 5651.497 | num zeros: 0.0 | params norm: 528.849 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.53 |
 iteration     1117/    1571 | consumed samples:       306344 | consumed tokens:    627392512 | elapsed time per iteration (s): 78.88 | learning rate: 2.775E-05 | global batch size:   400 | lm loss: 4.605089E+00 | loss scale: 8192.0 | grad norm: 5731.094 | num zeros: 0.0 | params norm: 528.857 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1118/    1571 | consumed samples:       306744 | consumed tokens:    628211712 | elapsed time per iteration (s): 78.89 | learning rate: 2.764E-05 | global batch size:   400 | lm loss: 4.575770E+00 | loss scale: 8192.0 | grad norm: 5421.515 | num zeros: 0.0 | params norm: 528.865 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.54 |
 iteration     1119/    1571 | consumed samples:       307144 | consumed tokens:    629030912 | elapsed time per iteration (s): 78.82 | learning rate: 2.754E-05 | global batch size:   400 | lm loss: 4.633387E+00 | loss scale: 8192.0 | grad norm: 5741.656 | num zeros: 0.0 | params norm: 528.874 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration     1120/    1571 | consumed samples:       307544 | consumed tokens:    629850112 | elapsed time per iteration (s): 78.91 | learning rate: 2.743E-05 | global batch size:   400 | lm loss: 4.631671E+00 | loss scale: 8192.0 | grad norm: 5977.610 | num zeros: 0.0 | params norm: 528.882 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.53 |
 iteration     1121/    1571 | consumed samples:       307944 | consumed tokens:    630669312 | elapsed time per iteration (s): 78.86 | learning rate: 2.733E-05 | global batch size:   400 | lm loss: 4.628703E+00 | loss scale: 8192.0 | grad norm: 5531.971 | num zeros: 0.0 | params norm: 528.889 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.56 |
 iteration     1122/    1571 | consumed samples:       308344 | consumed tokens:    631488512 | elapsed time per iteration (s): 78.86 | learning rate: 2.722E-05 | global batch size:   400 | lm loss: 4.609052E+00 | loss scale: 8192.0 | grad norm: 6107.905 | num zeros: 0.0 | params norm: 528.897 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1123/    1571 | consumed samples:       308744 | consumed tokens:    632307712 | elapsed time per iteration (s): 78.88 | learning rate: 2.712E-05 | global batch size:   400 | lm loss: 4.629317E+00 | loss scale: 8192.0 | grad norm: 5803.472 | num zeros: 0.0 | params norm: 528.905 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1124/    1571 | consumed samples:       309144 | consumed tokens:    633126912 | elapsed time per iteration (s): 78.87 | learning rate: 2.701E-05 | global batch size:   400 | lm loss: 4.583807E+00 | loss scale: 8192.0 | grad norm: 5434.945 | num zeros: 0.0 | params norm: 528.913 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.55 |
 iteration     1125/    1571 | consumed samples:       309544 | consumed tokens:    633946112 | elapsed time per iteration (s): 78.83 | learning rate: 2.691E-05 | global batch size:   400 | lm loss: 4.584381E+00 | loss scale: 8192.0 | grad norm: 6711.812 | num zeros: 0.0 | params norm: 528.921 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration     1126/    1571 | consumed samples:       309944 | consumed tokens:    634765312 | elapsed time per iteration (s): 78.90 | learning rate: 2.680E-05 | global batch size:   400 | lm loss: 4.590170E+00 | loss scale: 8192.0 | grad norm: 8306.258 | num zeros: 0.0 | params norm: 528.929 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.53 |
 iteration     1127/    1571 | consumed samples:       310344 | consumed tokens:    635584512 | elapsed time per iteration (s): 78.77 | learning rate: 2.670E-05 | global batch size:   400 | lm loss: 4.610423E+00 | loss scale: 8192.0 | grad norm: 8053.872 | num zeros: 0.0 | params norm: 528.937 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration     1128/    1571 | consumed samples:       310744 | consumed tokens:    636403712 | elapsed time per iteration (s): 78.89 | learning rate: 2.660E-05 | global batch size:   400 | lm loss: 4.614162E+00 | loss scale: 8192.0 | grad norm: 5901.209 | num zeros: 0.0 | params norm: 528.945 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.54 |
 iteration     1129/    1571 | consumed samples:       311144 | consumed tokens:    637222912 | elapsed time per iteration (s): 78.80 | learning rate: 2.649E-05 | global batch size:   400 | lm loss: 4.599287E+00 | loss scale: 8192.0 | grad norm: 5477.171 | num zeros: 0.0 | params norm: 528.953 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration     1130/    1571 | consumed samples:       311544 | consumed tokens:    638042112 | elapsed time per iteration (s): 78.90 | learning rate: 2.639E-05 | global batch size:   400 | lm loss: 4.591938E+00 | loss scale: 8192.0 | grad norm: 6795.210 | num zeros: 0.0 | params norm: 528.961 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.53 |
 iteration     1131/    1571 | consumed samples:       311944 | consumed tokens:    638861312 | elapsed time per iteration (s): 78.86 | learning rate: 2.629E-05 | global batch size:   400 | lm loss: 4.569541E+00 | loss scale: 8192.0 | grad norm: 8448.968 | num zeros: 0.0 | params norm: 528.968 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1132/    1571 | consumed samples:       312344 | consumed tokens:    639680512 | elapsed time per iteration (s): 78.84 | learning rate: 2.618E-05 | global batch size:   400 | lm loss: 4.614750E+00 | loss scale: 8192.0 | grad norm: 10264.047 | num zeros: 0.0 | params norm: 528.976 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1133/    1571 | consumed samples:       312744 | consumed tokens:    640499712 | elapsed time per iteration (s): 78.84 | learning rate: 2.608E-05 | global batch size:   400 | lm loss: 4.627692E+00 | loss scale: 8192.0 | grad norm: 7812.837 | num zeros: 0.0 | params norm: 528.984 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1134/    1571 | consumed samples:       313144 | consumed tokens:    641318912 | elapsed time per iteration (s): 78.83 | learning rate: 2.598E-05 | global batch size:   400 | lm loss: 4.602305E+00 | loss scale: 8192.0 | grad norm: 9326.184 | num zeros: 0.0 | params norm: 528.991 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration     1135/    1571 | consumed samples:       313544 | consumed tokens:    642138112 | elapsed time per iteration (s): 78.83 | learning rate: 2.588E-05 | global batch size:   400 | lm loss: 4.640283E+00 | loss scale: 8192.0 | grad norm: 6447.718 | num zeros: 0.0 | params norm: 528.999 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration     1136/    1571 | consumed samples:       313944 | consumed tokens:    642957312 | elapsed time per iteration (s): 78.84 | learning rate: 2.577E-05 | global batch size:   400 | lm loss: 4.575633E+00 | loss scale: 8192.0 | grad norm: 6402.062 | num zeros: 0.0 | params norm: 529.006 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1137/    1571 | consumed samples:       314344 | consumed tokens:    643776512 | elapsed time per iteration (s): 78.84 | learning rate: 2.567E-05 | global batch size:   400 | lm loss: 4.579308E+00 | loss scale: 8192.0 | grad norm: 7317.684 | num zeros: 0.0 | params norm: 529.014 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.57 |
 iteration     1138/    1571 | consumed samples:       314744 | consumed tokens:    644595712 | elapsed time per iteration (s): 78.69 | learning rate: 2.557E-05 | global batch size:   400 | lm loss: 4.595376E+00 | loss scale: 8192.0 | grad norm: 6235.519 | num zeros: 0.0 | params norm: 529.021 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.083 | TFLOPs: 53.67 |
 iteration     1139/    1571 | consumed samples:       315144 | consumed tokens:    645414912 | elapsed time per iteration (s): 78.67 | learning rate: 2.547E-05 | global batch size:   400 | lm loss: 4.605814E+00 | loss scale: 8192.0 | grad norm: 6988.532 | num zeros: 0.0 | params norm: 529.028 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.084 | TFLOPs: 53.69 |
 iteration     1140/    1571 | consumed samples:       315544 | consumed tokens:    646234112 | elapsed time per iteration (s): 78.86 | learning rate: 2.537E-05 | global batch size:   400 | lm loss: 4.603325E+00 | loss scale: 8192.0 | grad norm: 6559.710 | num zeros: 0.0 | params norm: 529.036 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1141/    1571 | consumed samples:       315944 | consumed tokens:    647053312 | elapsed time per iteration (s): 78.78 | learning rate: 2.527E-05 | global batch size:   400 | lm loss: 4.607207E+00 | loss scale: 8192.0 | grad norm: 5386.334 | num zeros: 0.0 | params norm: 529.043 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration     1142/    1571 | consumed samples:       316344 | consumed tokens:    647872512 | elapsed time per iteration (s): 78.78 | learning rate: 2.517E-05 | global batch size:   400 | lm loss: 4.601339E+00 | loss scale: 8192.0 | grad norm: 6282.604 | num zeros: 0.0 | params norm: 529.051 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration     1143/    1571 | consumed samples:       316744 | consumed tokens:    648691712 | elapsed time per iteration (s): 78.72 | learning rate: 2.507E-05 | global batch size:   400 | lm loss: 4.608062E+00 | loss scale: 8192.0 | grad norm: 6505.752 | num zeros: 0.0 | params norm: 529.058 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration     1144/    1571 | consumed samples:       317144 | consumed tokens:    649510912 | elapsed time per iteration (s): 78.79 | learning rate: 2.497E-05 | global batch size:   400 | lm loss: 4.620183E+00 | loss scale: 8192.0 | grad norm: 6993.376 | num zeros: 0.0 | params norm: 529.065 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration     1145/    1571 | consumed samples:       317544 | consumed tokens:    650330112 | elapsed time per iteration (s): 78.79 | learning rate: 2.487E-05 | global batch size:   400 | lm loss: 4.550278E+00 | loss scale: 8192.0 | grad norm: 6807.537 | num zeros: 0.0 | params norm: 529.072 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration     1146/    1571 | consumed samples:       317944 | consumed tokens:    651149312 | elapsed time per iteration (s): 78.88 | learning rate: 2.477E-05 | global batch size:   400 | lm loss: 4.602859E+00 | loss scale: 8192.0 | grad norm: 7387.350 | num zeros: 0.0 | params norm: 529.080 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1147/    1571 | consumed samples:       318344 | consumed tokens:    651968512 | elapsed time per iteration (s): 78.82 | learning rate: 2.467E-05 | global batch size:   400 | lm loss: 4.607892E+00 | loss scale: 8192.0 | grad norm: 9164.673 | num zeros: 0.0 | params norm: 529.086 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.58 |
 iteration     1148/    1571 | consumed samples:       318744 | consumed tokens:    652787712 | elapsed time per iteration (s): 79.01 | learning rate: 2.457E-05 | global batch size:   400 | lm loss: 4.622137E+00 | loss scale: 8192.0 | grad norm: 6345.643 | num zeros: 0.0 | params norm: 529.094 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.062 | TFLOPs: 53.45 |
 iteration     1149/    1571 | consumed samples:       319144 | consumed tokens:    653606912 | elapsed time per iteration (s): 78.75 | learning rate: 2.447E-05 | global batch size:   400 | lm loss: 4.587119E+00 | loss scale: 8192.0 | grad norm: 6043.362 | num zeros: 0.0 | params norm: 529.101 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration     1150/    1571 | consumed samples:       319544 | consumed tokens:    654426112 | elapsed time per iteration (s): 78.81 | learning rate: 2.438E-05 | global batch size:   400 | lm loss: 4.596988E+00 | loss scale: 8192.0 | grad norm: 6120.903 | num zeros: 0.0 | params norm: 529.108 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.59 |
 iteration     1151/    1571 | consumed samples:       319944 | consumed tokens:    655245312 | elapsed time per iteration (s): 78.87 | learning rate: 2.428E-05 | global batch size:   400 | lm loss: 4.576136E+00 | loss scale: 8192.0 | grad norm: 5826.699 | num zeros: 0.0 | params norm: 529.115 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.55 |
 iteration     1152/    1571 | consumed samples:       320344 | consumed tokens:    656064512 | elapsed time per iteration (s): 78.77 | learning rate: 2.418E-05 | global batch size:   400 | lm loss: 4.584154E+00 | loss scale: 8192.0 | grad norm: 5755.184 | num zeros: 0.0 | params norm: 529.122 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration     1153/    1571 | consumed samples:       320744 | consumed tokens:    656883712 | elapsed time per iteration (s): 78.71 | learning rate: 2.408E-05 | global batch size:   400 | lm loss: 4.591916E+00 | loss scale: 8192.0 | grad norm: 5510.000 | num zeros: 0.0 | params norm: 529.129 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.66 |
 iteration     1154/    1571 | consumed samples:       321144 | consumed tokens:    657702912 | elapsed time per iteration (s): 78.89 | learning rate: 2.399E-05 | global batch size:   400 | lm loss: 4.591927E+00 | loss scale: 8192.0 | grad norm: 4983.597 | num zeros: 0.0 | params norm: 529.136 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.54 |
 iteration     1155/    1571 | consumed samples:       321544 | consumed tokens:    658522112 | elapsed time per iteration (s): 78.77 | learning rate: 2.389E-05 | global batch size:   400 | lm loss: 4.603884E+00 | loss scale: 8192.0 | grad norm: 4614.255 | num zeros: 0.0 | params norm: 529.143 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration     1156/    1571 | consumed samples:       321944 | consumed tokens:    659341312 | elapsed time per iteration (s): 78.83 | learning rate: 2.379E-05 | global batch size:   400 | lm loss: 4.583618E+00 | loss scale: 8192.0 | grad norm: 4803.296 | num zeros: 0.0 | params norm: 529.150 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration     1157/    1571 | consumed samples:       322344 | consumed tokens:    660160512 | elapsed time per iteration (s): 78.84 | learning rate: 2.370E-05 | global batch size:   400 | lm loss: 4.542686E+00 | loss scale: 16384.0 | grad norm: 5035.622 | num zeros: 0.0 | params norm: 529.156 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1158/    1571 | consumed samples:       322744 | consumed tokens:    660979712 | elapsed time per iteration (s): 78.91 | learning rate: 2.360E-05 | global batch size:   400 | lm loss: 4.588041E+00 | loss scale: 16384.0 | grad norm: 11017.791 | num zeros: 0.0 | params norm: 529.164 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.53 |
 iteration     1159/    1571 | consumed samples:       323144 | consumed tokens:    661798912 | elapsed time per iteration (s): 78.94 | learning rate: 2.350E-05 | global batch size:   400 | lm loss: 4.569036E+00 | loss scale: 16384.0 | grad norm: 16685.523 | num zeros: 0.0 | params norm: 529.172 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.51 |
 iteration     1160/    1571 | consumed samples:       323544 | consumed tokens:    662618112 | elapsed time per iteration (s): 79.01 | learning rate: 2.341E-05 | global batch size:   400 | lm loss: 4.589028E+00 | loss scale: 16384.0 | grad norm: 16326.271 | num zeros: 0.0 | params norm: 529.180 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.062 | TFLOPs: 53.45 |
 iteration     1161/    1571 | consumed samples:       323944 | consumed tokens:    663437312 | elapsed time per iteration (s): 78.82 | learning rate: 2.331E-05 | global batch size:   400 | lm loss: 4.630438E+00 | loss scale: 16384.0 | grad norm: 21255.912 | num zeros: 0.0 | params norm: 529.189 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration     1162/    1571 | consumed samples:       324344 | consumed tokens:    664256512 | elapsed time per iteration (s): 78.96 | learning rate: 2.322E-05 | global batch size:   400 | lm loss: 4.592025E+00 | loss scale: 16384.0 | grad norm: 19480.391 | num zeros: 0.0 | params norm: 529.197 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.49 |
 iteration     1163/    1571 | consumed samples:       324744 | consumed tokens:    665075712 | elapsed time per iteration (s): 78.89 | learning rate: 2.312E-05 | global batch size:   400 | lm loss: 4.580439E+00 | loss scale: 16384.0 | grad norm: 16263.850 | num zeros: 0.0 | params norm: 529.206 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.54 |
 iteration     1164/    1571 | consumed samples:       325144 | consumed tokens:    665894912 | elapsed time per iteration (s): 78.97 | learning rate: 2.303E-05 | global batch size:   400 | lm loss: 4.558084E+00 | loss scale: 16384.0 | grad norm: 17471.212 | num zeros: 0.0 | params norm: 529.214 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1165/    1571 | consumed samples:       325544 | consumed tokens:    666714112 | elapsed time per iteration (s): 78.91 | learning rate: 2.294E-05 | global batch size:   400 | lm loss: 4.598085E+00 | loss scale: 16384.0 | grad norm: 14628.010 | num zeros: 0.0 | params norm: 529.223 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.52 |
 iteration     1166/    1571 | consumed samples:       325944 | consumed tokens:    667533312 | elapsed time per iteration (s): 78.89 | learning rate: 2.284E-05 | global batch size:   400 | lm loss: 4.581292E+00 | loss scale: 16384.0 | grad norm: 12879.059 | num zeros: 0.0 | params norm: 529.232 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.54 |
 iteration     1167/    1571 | consumed samples:       326344 | consumed tokens:    668352512 | elapsed time per iteration (s): 78.79 | learning rate: 2.275E-05 | global batch size:   400 | lm loss: 4.543715E+00 | loss scale: 16384.0 | grad norm: 12753.920 | num zeros: 0.0 | params norm: 529.241 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration     1168/    1571 | consumed samples:       326744 | consumed tokens:    669171712 | elapsed time per iteration (s): 78.81 | learning rate: 2.266E-05 | global batch size:   400 | lm loss: 4.591131E+00 | loss scale: 16384.0 | grad norm: 10968.445 | num zeros: 0.0 | params norm: 529.250 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration     1169/    1571 | consumed samples:       327144 | consumed tokens:    669990912 | elapsed time per iteration (s): 78.83 | learning rate: 2.256E-05 | global batch size:   400 | lm loss: 4.544850E+00 | loss scale: 16384.0 | grad norm: 11518.945 | num zeros: 0.0 | params norm: 529.259 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration     1170/    1571 | consumed samples:       327544 | consumed tokens:    670810112 | elapsed time per iteration (s): 78.98 | learning rate: 2.247E-05 | global batch size:   400 | lm loss: 4.552762E+00 | loss scale: 16384.0 | grad norm: 11354.951 | num zeros: 0.0 | params norm: 529.269 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1171/    1571 | consumed samples:       327944 | consumed tokens:    671629312 | elapsed time per iteration (s): 78.81 | learning rate: 2.238E-05 | global batch size:   400 | lm loss: 4.552524E+00 | loss scale: 16384.0 | grad norm: 10521.799 | num zeros: 0.0 | params norm: 529.278 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.59 |
 iteration     1172/    1571 | consumed samples:       328344 | consumed tokens:    672448512 | elapsed time per iteration (s): 78.97 | learning rate: 2.229E-05 | global batch size:   400 | lm loss: 4.550193E+00 | loss scale: 16384.0 | grad norm: 11762.803 | num zeros: 0.0 | params norm: 529.287 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.49 |
 iteration     1173/    1571 | consumed samples:       328744 | consumed tokens:    673267712 | elapsed time per iteration (s): 78.85 | learning rate: 2.219E-05 | global batch size:   400 | lm loss: 4.573433E+00 | loss scale: 16384.0 | grad norm: 10635.172 | num zeros: 0.0 | params norm: 529.296 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.56 |
 iteration     1174/    1571 | consumed samples:       329144 | consumed tokens:    674086912 | elapsed time per iteration (s): 78.87 | learning rate: 2.210E-05 | global batch size:   400 | lm loss: 4.575320E+00 | loss scale: 16384.0 | grad norm: 12179.225 | num zeros: 0.0 | params norm: 529.306 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.55 |
 iteration     1175/    1571 | consumed samples:       329544 | consumed tokens:    674906112 | elapsed time per iteration (s): 78.88 | learning rate: 2.201E-05 | global batch size:   400 | lm loss: 4.560067E+00 | loss scale: 16384.0 | grad norm: 13019.672 | num zeros: 0.0 | params norm: 529.315 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1176/    1571 | consumed samples:       329944 | consumed tokens:    675725312 | elapsed time per iteration (s): 78.86 | learning rate: 2.192E-05 | global batch size:   400 | lm loss: 4.589766E+00 | loss scale: 16384.0 | grad norm: 13262.280 | num zeros: 0.0 | params norm: 529.324 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1177/    1571 | consumed samples:       330344 | consumed tokens:    676544512 | elapsed time per iteration (s): 78.86 | learning rate: 2.183E-05 | global batch size:   400 | lm loss: 4.566100E+00 | loss scale: 16384.0 | grad norm: 15557.698 | num zeros: 0.0 | params norm: 529.334 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1178/    1571 | consumed samples:       330744 | consumed tokens:    677363712 | elapsed time per iteration (s): 79.03 | learning rate: 2.174E-05 | global batch size:   400 | lm loss: 4.571276E+00 | loss scale: 16384.0 | grad norm: 14735.307 | num zeros: 0.0 | params norm: 529.343 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.061 | TFLOPs: 53.44 |
 iteration     1179/    1571 | consumed samples:       331144 | consumed tokens:    678182912 | elapsed time per iteration (s): 78.86 | learning rate: 2.165E-05 | global batch size:   400 | lm loss: 4.583618E+00 | loss scale: 16384.0 | grad norm: 12622.436 | num zeros: 0.0 | params norm: 529.352 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.56 |
 iteration     1180/    1571 | consumed samples:       331544 | consumed tokens:    679002112 | elapsed time per iteration (s): 78.99 | learning rate: 2.156E-05 | global batch size:   400 | lm loss: 4.562417E+00 | loss scale: 16384.0 | grad norm: 15309.405 | num zeros: 0.0 | params norm: 529.360 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.47 |
 iteration     1181/    1571 | consumed samples:       331944 | consumed tokens:    679821312 | elapsed time per iteration (s): 78.95 | learning rate: 2.147E-05 | global batch size:   400 | lm loss: 4.517116E+00 | loss scale: 16384.0 | grad norm: 15412.504 | num zeros: 0.0 | params norm: 529.369 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1182/    1571 | consumed samples:       332344 | consumed tokens:    680640512 | elapsed time per iteration (s): 78.99 | learning rate: 2.138E-05 | global batch size:   400 | lm loss: 4.519678E+00 | loss scale: 16384.0 | grad norm: 16626.748 | num zeros: 0.0 | params norm: 529.378 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.47 |
 iteration     1183/    1571 | consumed samples:       332744 | consumed tokens:    681459712 | elapsed time per iteration (s): 78.87 | learning rate: 2.129E-05 | global batch size:   400 | lm loss: 4.520089E+00 | loss scale: 16384.0 | grad norm: 16405.714 | num zeros: 0.0 | params norm: 529.387 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.55 |
 iteration     1184/    1571 | consumed samples:       333144 | consumed tokens:    682278912 | elapsed time per iteration (s): 78.94 | learning rate: 2.121E-05 | global batch size:   400 | lm loss: 4.519602E+00 | loss scale: 16384.0 | grad norm: 12871.234 | num zeros: 0.0 | params norm: 529.395 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1185/    1571 | consumed samples:       333544 | consumed tokens:    683098112 | elapsed time per iteration (s): 78.90 | learning rate: 2.112E-05 | global batch size:   400 | lm loss: 4.529277E+00 | loss scale: 16384.0 | grad norm: 13175.453 | num zeros: 0.0 | params norm: 529.404 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.53 |
 iteration     1186/    1571 | consumed samples:       333944 | consumed tokens:    683917312 | elapsed time per iteration (s): 79.00 | learning rate: 2.103E-05 | global batch size:   400 | lm loss: 4.552344E+00 | loss scale: 16384.0 | grad norm: 12210.937 | num zeros: 0.0 | params norm: 529.412 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.063 | TFLOPs: 53.47 |
 iteration     1187/    1571 | consumed samples:       334344 | consumed tokens:    684736512 | elapsed time per iteration (s): 78.81 | learning rate: 2.094E-05 | global batch size:   400 | lm loss: 4.542663E+00 | loss scale: 16384.0 | grad norm: 10862.835 | num zeros: 0.0 | params norm: 529.420 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.59 |
 iteration     1188/    1571 | consumed samples:       334744 | consumed tokens:    685555712 | elapsed time per iteration (s): 78.82 | learning rate: 2.085E-05 | global batch size:   400 | lm loss: 4.547692E+00 | loss scale: 16384.0 | grad norm: 11564.585 | num zeros: 0.0 | params norm: 529.428 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration     1189/    1571 | consumed samples:       335144 | consumed tokens:    686374912 | elapsed time per iteration (s): 78.79 | learning rate: 2.077E-05 | global batch size:   400 | lm loss: 4.528469E+00 | loss scale: 16384.0 | grad norm: 10913.509 | num zeros: 0.0 | params norm: 529.436 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration     1190/    1571 | consumed samples:       335544 | consumed tokens:    687194112 | elapsed time per iteration (s): 78.87 | learning rate: 2.068E-05 | global batch size:   400 | lm loss: 4.559326E+00 | loss scale: 16384.0 | grad norm: 10901.343 | num zeros: 0.0 | params norm: 529.445 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.55 |
 iteration     1191/    1571 | consumed samples:       335944 | consumed tokens:    688013312 | elapsed time per iteration (s): 78.88 | learning rate: 2.059E-05 | global batch size:   400 | lm loss: 4.537727E+00 | loss scale: 16384.0 | grad norm: 10659.887 | num zeros: 0.0 | params norm: 529.453 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1192/    1571 | consumed samples:       336344 | consumed tokens:    688832512 | elapsed time per iteration (s): 78.90 | learning rate: 2.051E-05 | global batch size:   400 | lm loss: 4.551839E+00 | loss scale: 16384.0 | grad norm: 10707.719 | num zeros: 0.0 | params norm: 529.461 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.53 |
 iteration     1193/    1571 | consumed samples:       336744 | consumed tokens:    689651712 | elapsed time per iteration (s): 78.81 | learning rate: 2.042E-05 | global batch size:   400 | lm loss: 4.514316E+00 | loss scale: 16384.0 | grad norm: 10976.311 | num zeros: 0.0 | params norm: 529.469 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration     1194/    1571 | consumed samples:       337144 | consumed tokens:    690470912 | elapsed time per iteration (s): 78.95 | learning rate: 2.034E-05 | global batch size:   400 | lm loss: 4.559632E+00 | loss scale: 16384.0 | grad norm: 13674.408 | num zeros: 0.0 | params norm: 529.476 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1195/    1571 | consumed samples:       337544 | consumed tokens:    691290112 | elapsed time per iteration (s): 78.93 | learning rate: 2.025E-05 | global batch size:   400 | lm loss: 4.555146E+00 | loss scale: 16384.0 | grad norm: 16379.067 | num zeros: 0.0 | params norm: 529.484 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1196/    1571 | consumed samples:       337944 | consumed tokens:    692109312 | elapsed time per iteration (s): 78.86 | learning rate: 2.017E-05 | global batch size:   400 | lm loss: 4.510751E+00 | loss scale: 16384.0 | grad norm: 15211.877 | num zeros: 0.0 | params norm: 529.492 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1197/    1571 | consumed samples:       338344 | consumed tokens:    692928512 | elapsed time per iteration (s): 78.91 | learning rate: 2.008E-05 | global batch size:   400 | lm loss: 4.513260E+00 | loss scale: 16384.0 | grad norm: 15282.196 | num zeros: 0.0 | params norm: 529.499 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.53 |
 iteration     1198/    1571 | consumed samples:       338744 | consumed tokens:    693747712 | elapsed time per iteration (s): 78.98 | learning rate: 2.000E-05 | global batch size:   400 | lm loss: 4.549457E+00 | loss scale: 16384.0 | grad norm: 16727.454 | num zeros: 0.0 | params norm: 529.507 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.47 |
 iteration     1199/    1571 | consumed samples:       339144 | consumed tokens:    694566912 | elapsed time per iteration (s): 78.91 | learning rate: 1.991E-05 | global batch size:   400 | lm loss: 4.525884E+00 | loss scale: 16384.0 | grad norm: 13794.600 | num zeros: 0.0 | params norm: 529.514 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.53 |
 iteration     1200/    1571 | consumed samples:       339544 | consumed tokens:    695386112 | elapsed time per iteration (s): 78.98 | learning rate: 1.983E-05 | global batch size:   400 | lm loss: 4.520538E+00 | loss scale: 16384.0 | grad norm: 10698.184 | num zeros: 0.0 | params norm: 529.522 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.48 |
 iteration     1201/    1571 | consumed samples:       339944 | consumed tokens:    696205312 | elapsed time per iteration (s): 78.85 | learning rate: 1.975E-05 | global batch size:   400 | lm loss: 4.555857E+00 | loss scale: 16384.0 | grad norm: 14125.717 | num zeros: 0.0 | params norm: 529.529 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.56 |
 iteration     1202/    1571 | consumed samples:       340344 | consumed tokens:    697024512 | elapsed time per iteration (s): 78.94 | learning rate: 1.966E-05 | global batch size:   400 | lm loss: 4.546921E+00 | loss scale: 16384.0 | grad norm: 10856.517 | num zeros: 0.0 | params norm: 529.537 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.51 |
 iteration     1203/    1571 | consumed samples:       340744 | consumed tokens:    697843712 | elapsed time per iteration (s): 78.94 | learning rate: 1.958E-05 | global batch size:   400 | lm loss: 4.535602E+00 | loss scale: 16384.0 | grad norm: 10310.835 | num zeros: 0.0 | params norm: 529.544 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.51 |
 iteration     1204/    1571 | consumed samples:       341144 | consumed tokens:    698662912 | elapsed time per iteration (s): 78.90 | learning rate: 1.950E-05 | global batch size:   400 | lm loss: 4.534298E+00 | loss scale: 16384.0 | grad norm: 11657.951 | num zeros: 0.0 | params norm: 529.551 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.53 |
 iteration     1205/    1571 | consumed samples:       341544 | consumed tokens:    699482112 | elapsed time per iteration (s): 78.93 | learning rate: 1.942E-05 | global batch size:   400 | lm loss: 4.518074E+00 | loss scale: 16384.0 | grad norm: 11087.459 | num zeros: 0.0 | params norm: 529.558 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1206/    1571 | consumed samples:       341944 | consumed tokens:    700301312 | elapsed time per iteration (s): 78.96 | learning rate: 1.934E-05 | global batch size:   400 | lm loss: 4.531348E+00 | loss scale: 16384.0 | grad norm: 9532.483 | num zeros: 0.0 | params norm: 529.565 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.49 |
 iteration     1207/    1571 | consumed samples:       342344 | consumed tokens:    701120512 | elapsed time per iteration (s): 78.84 | learning rate: 1.925E-05 | global batch size:   400 | lm loss: 4.481490E+00 | loss scale: 16384.0 | grad norm: 9735.866 | num zeros: 0.0 | params norm: 529.572 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1208/    1571 | consumed samples:       342744 | consumed tokens:    701939712 | elapsed time per iteration (s): 78.94 | learning rate: 1.917E-05 | global batch size:   400 | lm loss: 4.516712E+00 | loss scale: 16384.0 | grad norm: 10486.441 | num zeros: 0.0 | params norm: 529.579 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1209/    1571 | consumed samples:       343144 | consumed tokens:    702758912 | elapsed time per iteration (s): 78.89 | learning rate: 1.909E-05 | global batch size:   400 | lm loss: 4.493856E+00 | loss scale: 16384.0 | grad norm: 10086.805 | num zeros: 0.0 | params norm: 529.586 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.54 |
 iteration     1210/    1571 | consumed samples:       343544 | consumed tokens:    703578112 | elapsed time per iteration (s): 78.96 | learning rate: 1.901E-05 | global batch size:   400 | lm loss: 4.530830E+00 | loss scale: 16384.0 | grad norm: 11918.172 | num zeros: 0.0 | params norm: 529.594 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.49 |
 iteration     1211/    1571 | consumed samples:       343944 | consumed tokens:    704397312 | elapsed time per iteration (s): 78.87 | learning rate: 1.893E-05 | global batch size:   400 | lm loss: 4.484741E+00 | loss scale: 16384.0 | grad norm: 13530.160 | num zeros: 0.0 | params norm: 529.600 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1212/    1571 | consumed samples:       344344 | consumed tokens:    705216512 | elapsed time per iteration (s): 78.95 | learning rate: 1.885E-05 | global batch size:   400 | lm loss: 4.533102E+00 | loss scale: 16384.0 | grad norm: 11833.536 | num zeros: 0.0 | params norm: 529.607 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.49 |
 iteration     1213/    1571 | consumed samples:       344744 | consumed tokens:    706035712 | elapsed time per iteration (s): 78.91 | learning rate: 1.877E-05 | global batch size:   400 | lm loss: 4.517805E+00 | loss scale: 16384.0 | grad norm: 10588.068 | num zeros: 0.0 | params norm: 529.614 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.53 |
 iteration     1214/    1571 | consumed samples:       345144 | consumed tokens:    706854912 | elapsed time per iteration (s): 78.80 | learning rate: 1.869E-05 | global batch size:   400 | lm loss: 4.558874E+00 | loss scale: 16384.0 | grad norm: 9359.396 | num zeros: 0.0 | params norm: 529.621 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration     1215/    1571 | consumed samples:       345544 | consumed tokens:    707674112 | elapsed time per iteration (s): 78.72 | learning rate: 1.861E-05 | global batch size:   400 | lm loss: 4.504529E+00 | loss scale: 16384.0 | grad norm: 9457.800 | num zeros: 0.0 | params norm: 529.628 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.66 |
 iteration     1216/    1571 | consumed samples:       345944 | consumed tokens:    708493312 | elapsed time per iteration (s): 78.95 | learning rate: 1.854E-05 | global batch size:   400 | lm loss: 4.505379E+00 | loss scale: 16384.0 | grad norm: 9329.923 | num zeros: 0.0 | params norm: 529.635 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1217/    1571 | consumed samples:       346344 | consumed tokens:    709312512 | elapsed time per iteration (s): 78.97 | learning rate: 1.846E-05 | global batch size:   400 | lm loss: 4.537230E+00 | loss scale: 16384.0 | grad norm: 9501.724 | num zeros: 0.0 | params norm: 529.641 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1218/    1571 | consumed samples:       346744 | consumed tokens:    710131712 | elapsed time per iteration (s): 78.96 | learning rate: 1.838E-05 | global batch size:   400 | lm loss: 4.515034E+00 | loss scale: 16384.0 | grad norm: 9860.055 | num zeros: 0.0 | params norm: 529.648 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.49 |
 iteration     1219/    1571 | consumed samples:       347144 | consumed tokens:    710950912 | elapsed time per iteration (s): 78.96 | learning rate: 1.830E-05 | global batch size:   400 | lm loss: 4.481860E+00 | loss scale: 16384.0 | grad norm: 14427.274 | num zeros: 0.0 | params norm: 529.655 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.49 |
 iteration     1220/    1571 | consumed samples:       347544 | consumed tokens:    711770112 | elapsed time per iteration (s): 78.90 | learning rate: 1.823E-05 | global batch size:   400 | lm loss: 4.559935E+00 | loss scale: 16384.0 | grad norm: 27127.745 | num zeros: 0.0 | params norm: 529.661 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.53 |
 iteration     1221/    1571 | consumed samples:       347944 | consumed tokens:    712589312 | elapsed time per iteration (s): 78.89 | learning rate: 1.815E-05 | global batch size:   400 | lm loss: 4.532902E+00 | loss scale: 16384.0 | grad norm: 14142.445 | num zeros: 0.0 | params norm: 529.668 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1222/    1571 | consumed samples:       348344 | consumed tokens:    713408512 | elapsed time per iteration (s): 79.00 | learning rate: 1.807E-05 | global batch size:   400 | lm loss: 4.492936E+00 | loss scale: 16384.0 | grad norm: 18383.003 | num zeros: 0.0 | params norm: 529.674 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.063 | TFLOPs: 53.46 |
 iteration     1223/    1571 | consumed samples:       348744 | consumed tokens:    714227712 | elapsed time per iteration (s): 78.82 | learning rate: 1.800E-05 | global batch size:   400 | lm loss: 4.527492E+00 | loss scale: 16384.0 | grad norm: 13495.542 | num zeros: 0.0 | params norm: 529.680 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.58 |
 iteration     1224/    1571 | consumed samples:       349144 | consumed tokens:    715046912 | elapsed time per iteration (s): 78.94 | learning rate: 1.792E-05 | global batch size:   400 | lm loss: 4.473042E+00 | loss scale: 16384.0 | grad norm: 14308.571 | num zeros: 0.0 | params norm: 529.686 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1225/    1571 | consumed samples:       349544 | consumed tokens:    715866112 | elapsed time per iteration (s): 78.88 | learning rate: 1.784E-05 | global batch size:   400 | lm loss: 4.515243E+00 | loss scale: 16384.0 | grad norm: 12954.860 | num zeros: 0.0 | params norm: 529.692 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1226/    1571 | consumed samples:       349944 | consumed tokens:    716685312 | elapsed time per iteration (s): 79.00 | learning rate: 1.777E-05 | global batch size:   400 | lm loss: 4.501053E+00 | loss scale: 16384.0 | grad norm: 10899.679 | num zeros: 0.0 | params norm: 529.699 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.063 | TFLOPs: 53.46 |
 iteration     1227/    1571 | consumed samples:       350344 | consumed tokens:    717504512 | elapsed time per iteration (s): 78.77 | learning rate: 1.769E-05 | global batch size:   400 | lm loss: 4.509862E+00 | loss scale: 16384.0 | grad norm: 12806.644 | num zeros: 0.0 | params norm: 529.705 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration     1228/    1571 | consumed samples:       350744 | consumed tokens:    718323712 | elapsed time per iteration (s): 78.88 | learning rate: 1.762E-05 | global batch size:   400 | lm loss: 4.523419E+00 | loss scale: 16384.0 | grad norm: 11069.037 | num zeros: 0.0 | params norm: 529.711 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1229/    1571 | consumed samples:       351144 | consumed tokens:    719142912 | elapsed time per iteration (s): 78.98 | learning rate: 1.754E-05 | global batch size:   400 | lm loss: 4.506391E+00 | loss scale: 16384.0 | grad norm: 10306.821 | num zeros: 0.0 | params norm: 529.717 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1230/    1571 | consumed samples:       351544 | consumed tokens:    719962112 | elapsed time per iteration (s): 78.92 | learning rate: 1.747E-05 | global batch size:   400 | lm loss: 4.521328E+00 | loss scale: 16384.0 | grad norm: 10733.832 | num zeros: 0.0 | params norm: 529.723 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.52 |
 iteration     1231/    1571 | consumed samples:       351944 | consumed tokens:    720781312 | elapsed time per iteration (s): 78.88 | learning rate: 1.740E-05 | global batch size:   400 | lm loss: 4.493777E+00 | loss scale: 16384.0 | grad norm: 11478.446 | num zeros: 0.0 | params norm: 529.730 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1232/    1571 | consumed samples:       352344 | consumed tokens:    721600512 | elapsed time per iteration (s): 78.98 | learning rate: 1.732E-05 | global batch size:   400 | lm loss: 4.480909E+00 | loss scale: 16384.0 | grad norm: 11820.230 | num zeros: 0.0 | params norm: 529.736 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1233/    1571 | consumed samples:       352744 | consumed tokens:    722419712 | elapsed time per iteration (s): 78.94 | learning rate: 1.725E-05 | global batch size:   400 | lm loss: 4.525229E+00 | loss scale: 16384.0 | grad norm: 11712.441 | num zeros: 0.0 | params norm: 529.742 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.51 |
 iteration     1234/    1571 | consumed samples:       353144 | consumed tokens:    723238912 | elapsed time per iteration (s): 78.99 | learning rate: 1.718E-05 | global batch size:   400 | lm loss: 4.473280E+00 | loss scale: 16384.0 | grad norm: 10944.109 | num zeros: 0.0 | params norm: 529.748 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.47 |
 iteration     1235/    1571 | consumed samples:       353544 | consumed tokens:    724058112 | elapsed time per iteration (s): 78.93 | learning rate: 1.711E-05 | global batch size:   400 | lm loss: 4.492384E+00 | loss scale: 16384.0 | grad norm: 9229.801 | num zeros: 0.0 | params norm: 529.754 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1236/    1571 | consumed samples:       353944 | consumed tokens:    724877312 | elapsed time per iteration (s): 78.91 | learning rate: 1.703E-05 | global batch size:   400 | lm loss: 4.504841E+00 | loss scale: 16384.0 | grad norm: 10276.485 | num zeros: 0.0 | params norm: 529.760 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.52 |
 iteration     1237/    1571 | consumed samples:       354344 | consumed tokens:    725696512 | elapsed time per iteration (s): 78.91 | learning rate: 1.696E-05 | global batch size:   400 | lm loss: 4.445475E+00 | loss scale: 16384.0 | grad norm: 9953.185 | num zeros: 0.0 | params norm: 529.766 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.53 |
 iteration     1238/    1571 | consumed samples:       354744 | consumed tokens:    726515712 | elapsed time per iteration (s): 79.02 | learning rate: 1.689E-05 | global batch size:   400 | lm loss: 4.463243E+00 | loss scale: 16384.0 | grad norm: 9460.590 | num zeros: 0.0 | params norm: 529.772 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.062 | TFLOPs: 53.45 |
 iteration     1239/    1571 | consumed samples:       355144 | consumed tokens:    727334912 | elapsed time per iteration (s): 78.84 | learning rate: 1.682E-05 | global batch size:   400 | lm loss: 4.493493E+00 | loss scale: 16384.0 | grad norm: 10161.648 | num zeros: 0.0 | params norm: 529.778 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.57 |
 iteration     1240/    1571 | consumed samples:       355544 | consumed tokens:    728154112 | elapsed time per iteration (s): 79.03 | learning rate: 1.675E-05 | global batch size:   400 | lm loss: 4.489495E+00 | loss scale: 16384.0 | grad norm: 10651.259 | num zeros: 0.0 | params norm: 529.784 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.061 | TFLOPs: 53.44 |
 iteration     1241/    1571 | consumed samples:       355944 | consumed tokens:    728973312 | elapsed time per iteration (s): 78.99 | learning rate: 1.668E-05 | global batch size:   400 | lm loss: 4.455276E+00 | loss scale: 16384.0 | grad norm: 12229.358 | num zeros: 0.0 | params norm: 529.790 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.47 |
 iteration     1242/    1571 | consumed samples:       356344 | consumed tokens:    729792512 | elapsed time per iteration (s): 78.89 | learning rate: 1.661E-05 | global batch size:   400 | lm loss: 4.511468E+00 | loss scale: 16384.0 | grad norm: 12975.507 | num zeros: 0.0 | params norm: 529.796 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.54 |
 iteration     1243/    1571 | consumed samples:       356744 | consumed tokens:    730611712 | elapsed time per iteration (s): 78.93 | learning rate: 1.654E-05 | global batch size:   400 | lm loss: 4.472685E+00 | loss scale: 16384.0 | grad norm: 13963.071 | num zeros: 0.0 | params norm: 529.802 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1244/    1571 | consumed samples:       357144 | consumed tokens:    731430912 | elapsed time per iteration (s): 78.94 | learning rate: 1.647E-05 | global batch size:   400 | lm loss: 4.516339E+00 | loss scale: 16384.0 | grad norm: 14623.008 | num zeros: 0.0 | params norm: 529.807 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1245/    1571 | consumed samples:       357544 | consumed tokens:    732250112 | elapsed time per iteration (s): 78.94 | learning rate: 1.640E-05 | global batch size:   400 | lm loss: 4.520336E+00 | loss scale: 16384.0 | grad norm: 15918.561 | num zeros: 0.0 | params norm: 529.813 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.51 |
 iteration     1246/    1571 | consumed samples:       357944 | consumed tokens:    733069312 | elapsed time per iteration (s): 78.97 | learning rate: 1.633E-05 | global batch size:   400 | lm loss: 4.501231E+00 | loss scale: 16384.0 | grad norm: 14442.738 | num zeros: 0.0 | params norm: 529.819 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1247/    1571 | consumed samples:       358344 | consumed tokens:    733888512 | elapsed time per iteration (s): 78.88 | learning rate: 1.626E-05 | global batch size:   400 | lm loss: 4.459571E+00 | loss scale: 16384.0 | grad norm: 11065.999 | num zeros: 0.0 | params norm: 529.824 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1248/    1571 | consumed samples:       358744 | consumed tokens:    734707712 | elapsed time per iteration (s): 79.01 | learning rate: 1.620E-05 | global batch size:   400 | lm loss: 4.460100E+00 | loss scale: 16384.0 | grad norm: 9986.982 | num zeros: 0.0 | params norm: 529.830 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.063 | TFLOPs: 53.46 |
 iteration     1249/    1571 | consumed samples:       359144 | consumed tokens:    735526912 | elapsed time per iteration (s): 78.86 | learning rate: 1.613E-05 | global batch size:   400 | lm loss: 4.486667E+00 | loss scale: 16384.0 | grad norm: 11155.047 | num zeros: 0.0 | params norm: 529.836 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.56 |
 iteration     1250/    1571 | consumed samples:       359544 | consumed tokens:    736346112 | elapsed time per iteration (s): 78.99 | learning rate: 1.606E-05 | global batch size:   400 | lm loss: 4.508004E+00 | loss scale: 16384.0 | grad norm: 10095.663 | num zeros: 0.0 | params norm: 529.841 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.47 |
 iteration     1251/    1571 | consumed samples:       359944 | consumed tokens:    737165312 | elapsed time per iteration (s): 78.92 | learning rate: 1.600E-05 | global batch size:   400 | lm loss: 4.488613E+00 | loss scale: 16384.0 | grad norm: 9055.391 | num zeros: 0.0 | params norm: 529.847 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.52 |
 iteration     1252/    1571 | consumed samples:       360344 | consumed tokens:    737984512 | elapsed time per iteration (s): 78.89 | learning rate: 1.593E-05 | global batch size:   400 | lm loss: 4.511423E+00 | loss scale: 16384.0 | grad norm: 11167.587 | num zeros: 0.0 | params norm: 529.852 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.54 |
 iteration     1253/    1571 | consumed samples:       360744 | consumed tokens:    738803712 | elapsed time per iteration (s): 78.81 | learning rate: 1.586E-05 | global batch size:   400 | lm loss: 4.463797E+00 | loss scale: 16384.0 | grad norm: 14551.773 | num zeros: 0.0 | params norm: 529.858 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.59 |
 iteration     1254/    1571 | consumed samples:       361144 | consumed tokens:    739622912 | elapsed time per iteration (s): 78.89 | learning rate: 1.580E-05 | global batch size:   400 | lm loss: 4.485418E+00 | loss scale: 16384.0 | grad norm: 16856.634 | num zeros: 0.0 | params norm: 529.863 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1255/    1571 | consumed samples:       361544 | consumed tokens:    740442112 | elapsed time per iteration (s): 78.92 | learning rate: 1.573E-05 | global batch size:   400 | lm loss: 4.505092E+00 | loss scale: 16384.0 | grad norm: 14202.304 | num zeros: 0.0 | params norm: 529.869 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.52 |
 iteration     1256/    1571 | consumed samples:       361944 | consumed tokens:    741261312 | elapsed time per iteration (s): 79.00 | learning rate: 1.567E-05 | global batch size:   400 | lm loss: 4.510958E+00 | loss scale: 16384.0 | grad norm: 10980.049 | num zeros: 0.0 | params norm: 529.874 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.063 | TFLOPs: 53.46 |
 iteration     1257/    1571 | consumed samples:       362344 | consumed tokens:    742080512 | elapsed time per iteration (s): 78.87 | learning rate: 1.560E-05 | global batch size:   400 | lm loss: 4.503662E+00 | loss scale: 16384.0 | grad norm: 14441.742 | num zeros: 0.0 | params norm: 529.879 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.55 |
 iteration     1258/    1571 | consumed samples:       362744 | consumed tokens:    742899712 | elapsed time per iteration (s): 78.95 | learning rate: 1.554E-05 | global batch size:   400 | lm loss: 4.492548E+00 | loss scale: 16384.0 | grad norm: 14378.884 | num zeros: 0.0 | params norm: 529.884 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1259/    1571 | consumed samples:       363144 | consumed tokens:    743718912 | elapsed time per iteration (s): 78.93 | learning rate: 1.547E-05 | global batch size:   400 | lm loss: 4.489578E+00 | loss scale: 16384.0 | grad norm: 9853.736 | num zeros: 0.0 | params norm: 529.890 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1260/    1571 | consumed samples:       363544 | consumed tokens:    744538112 | elapsed time per iteration (s): 78.87 | learning rate: 1.541E-05 | global batch size:   400 | lm loss: 4.493742E+00 | loss scale: 16384.0 | grad norm: 10763.803 | num zeros: 0.0 | params norm: 529.895 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1261/    1571 | consumed samples:       363944 | consumed tokens:    745357312 | elapsed time per iteration (s): 78.86 | learning rate: 1.535E-05 | global batch size:   400 | lm loss: 4.495831E+00 | loss scale: 16384.0 | grad norm: 10650.636 | num zeros: 0.0 | params norm: 529.900 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1262/    1571 | consumed samples:       364344 | consumed tokens:    746176512 | elapsed time per iteration (s): 79.07 | learning rate: 1.528E-05 | global batch size:   400 | lm loss: 4.469724E+00 | loss scale: 16384.0 | grad norm: 9426.042 | num zeros: 0.0 | params norm: 529.906 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.059 | TFLOPs: 53.42 |
 iteration     1263/    1571 | consumed samples:       364744 | consumed tokens:    746995712 | elapsed time per iteration (s): 78.84 | learning rate: 1.522E-05 | global batch size:   400 | lm loss: 4.518357E+00 | loss scale: 16384.0 | grad norm: 9232.914 | num zeros: 0.0 | params norm: 529.911 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.57 |
 iteration     1264/    1571 | consumed samples:       365144 | consumed tokens:    747814912 | elapsed time per iteration (s): 78.86 | learning rate: 1.516E-05 | global batch size:   400 | lm loss: 4.477093E+00 | loss scale: 16384.0 | grad norm: 9138.537 | num zeros: 0.0 | params norm: 529.916 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1265/    1571 | consumed samples:       365544 | consumed tokens:    748634112 | elapsed time per iteration (s): 78.88 | learning rate: 1.510E-05 | global batch size:   400 | lm loss: 4.478343E+00 | loss scale: 16384.0 | grad norm: 10221.379 | num zeros: 0.0 | params norm: 529.921 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1266/    1571 | consumed samples:       365944 | consumed tokens:    749453312 | elapsed time per iteration (s): 78.97 | learning rate: 1.503E-05 | global batch size:   400 | lm loss: 4.477798E+00 | loss scale: 16384.0 | grad norm: 10400.620 | num zeros: 0.0 | params norm: 529.926 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1267/    1571 | consumed samples:       366344 | consumed tokens:    750272512 | elapsed time per iteration (s): 78.89 | learning rate: 1.497E-05 | global batch size:   400 | lm loss: 4.491005E+00 | loss scale: 16384.0 | grad norm: 12222.827 | num zeros: 0.0 | params norm: 529.932 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1268/    1571 | consumed samples:       366744 | consumed tokens:    751091712 | elapsed time per iteration (s): 78.96 | learning rate: 1.491E-05 | global batch size:   400 | lm loss: 4.490754E+00 | loss scale: 16384.0 | grad norm: 13211.343 | num zeros: 0.0 | params norm: 529.937 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.49 |
 iteration     1269/    1571 | consumed samples:       367144 | consumed tokens:    751910912 | elapsed time per iteration (s): 78.92 | learning rate: 1.485E-05 | global batch size:   400 | lm loss: 4.456343E+00 | loss scale: 16384.0 | grad norm: 13655.344 | num zeros: 0.0 | params norm: 529.942 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.52 |
 iteration     1270/    1571 | consumed samples:       367544 | consumed tokens:    752730112 | elapsed time per iteration (s): 78.97 | learning rate: 1.479E-05 | global batch size:   400 | lm loss: 4.469633E+00 | loss scale: 16384.0 | grad norm: 13157.720 | num zeros: 0.0 | params norm: 529.947 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1271/    1571 | consumed samples:       367944 | consumed tokens:    753549312 | elapsed time per iteration (s): 78.73 | learning rate: 1.473E-05 | global batch size:   400 | lm loss: 4.487971E+00 | loss scale: 16384.0 | grad norm: 11875.035 | num zeros: 0.0 | params norm: 529.952 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.65 |
 iteration     1272/    1571 | consumed samples:       368344 | consumed tokens:    754368512 | elapsed time per iteration (s): 78.94 | learning rate: 1.467E-05 | global batch size:   400 | lm loss: 4.462133E+00 | loss scale: 16384.0 | grad norm: 11996.342 | num zeros: 0.0 | params norm: 529.957 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.51 |
 iteration     1273/    1571 | consumed samples:       368744 | consumed tokens:    755187712 | elapsed time per iteration (s): 78.85 | learning rate: 1.461E-05 | global batch size:   400 | lm loss: 4.464824E+00 | loss scale: 16384.0 | grad norm: 14760.314 | num zeros: 0.0 | params norm: 529.962 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.56 |
 iteration     1274/    1571 | consumed samples:       369144 | consumed tokens:    756006912 | elapsed time per iteration (s): 78.93 | learning rate: 1.455E-05 | global batch size:   400 | lm loss: 4.438230E+00 | loss scale: 16384.0 | grad norm: 13523.896 | num zeros: 0.0 | params norm: 529.967 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1275/    1571 | consumed samples:       369544 | consumed tokens:    756826112 | elapsed time per iteration (s): 78.98 | learning rate: 1.449E-05 | global batch size:   400 | lm loss: 4.462424E+00 | loss scale: 16384.0 | grad norm: 9787.644 | num zeros: 0.0 | params norm: 529.972 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1276/    1571 | consumed samples:       369944 | consumed tokens:    757645312 | elapsed time per iteration (s): 78.81 | learning rate: 1.444E-05 | global batch size:   400 | lm loss: 4.480383E+00 | loss scale: 16384.0 | grad norm: 12469.196 | num zeros: 0.0 | params norm: 529.977 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration     1277/    1571 | consumed samples:       370344 | consumed tokens:    758464512 | elapsed time per iteration (s): 78.84 | learning rate: 1.438E-05 | global batch size:   400 | lm loss: 4.458478E+00 | loss scale: 16384.0 | grad norm: 13040.622 | num zeros: 0.0 | params norm: 529.981 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1278/    1571 | consumed samples:       370744 | consumed tokens:    759283712 | elapsed time per iteration (s): 79.02 | learning rate: 1.432E-05 | global batch size:   400 | lm loss: 4.486177E+00 | loss scale: 16384.0 | grad norm: 10079.897 | num zeros: 0.0 | params norm: 529.986 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.062 | TFLOPs: 53.45 |
 iteration     1279/    1571 | consumed samples:       371144 | consumed tokens:    760102912 | elapsed time per iteration (s): 78.89 | learning rate: 1.426E-05 | global batch size:   400 | lm loss: 4.448590E+00 | loss scale: 16384.0 | grad norm: 10995.090 | num zeros: 0.0 | params norm: 529.991 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.54 |
 iteration     1280/    1571 | consumed samples:       371544 | consumed tokens:    760922112 | elapsed time per iteration (s): 79.06 | learning rate: 1.421E-05 | global batch size:   400 | lm loss: 4.465342E+00 | loss scale: 16384.0 | grad norm: 11284.675 | num zeros: 0.0 | params norm: 529.996 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.059 | TFLOPs: 53.42 |
 iteration     1281/    1571 | consumed samples:       371944 | consumed tokens:    761741312 | elapsed time per iteration (s): 78.95 | learning rate: 1.415E-05 | global batch size:   400 | lm loss: 4.480306E+00 | loss scale: 16384.0 | grad norm: 10612.321 | num zeros: 0.0 | params norm: 530.001 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1282/    1571 | consumed samples:       372344 | consumed tokens:    762560512 | elapsed time per iteration (s): 79.01 | learning rate: 1.410E-05 | global batch size:   400 | lm loss: 4.494787E+00 | loss scale: 16384.0 | grad norm: 12843.384 | num zeros: 0.0 | params norm: 530.006 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.063 | TFLOPs: 53.46 |
 iteration     1283/    1571 | consumed samples:       372744 | consumed tokens:    763379712 | elapsed time per iteration (s): 78.80 | learning rate: 1.404E-05 | global batch size:   400 | lm loss: 4.506854E+00 | loss scale: 16384.0 | grad norm: 13591.869 | num zeros: 0.0 | params norm: 530.010 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration     1284/    1571 | consumed samples:       373144 | consumed tokens:    764198912 | elapsed time per iteration (s): 78.95 | learning rate: 1.398E-05 | global batch size:   400 | lm loss: 4.459136E+00 | loss scale: 16384.0 | grad norm: 13027.285 | num zeros: 0.0 | params norm: 530.015 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.50 |
 iteration     1285/    1571 | consumed samples:       373544 | consumed tokens:    765018112 | elapsed time per iteration (s): 78.90 | learning rate: 1.393E-05 | global batch size:   400 | lm loss: 4.456484E+00 | loss scale: 16384.0 | grad norm: 12584.736 | num zeros: 0.0 | params norm: 530.020 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.53 |
 iteration     1286/    1571 | consumed samples:       373944 | consumed tokens:    765837312 | elapsed time per iteration (s): 78.98 | learning rate: 1.388E-05 | global batch size:   400 | lm loss: 4.464048E+00 | loss scale: 16384.0 | grad norm: 12043.585 | num zeros: 0.0 | params norm: 530.025 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.48 |
 iteration     1287/    1571 | consumed samples:       374344 | consumed tokens:    766656512 | elapsed time per iteration (s): 78.88 | learning rate: 1.382E-05 | global batch size:   400 | lm loss: 4.449792E+00 | loss scale: 16384.0 | grad norm: 10548.345 | num zeros: 0.0 | params norm: 530.029 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1288/    1571 | consumed samples:       374744 | consumed tokens:    767475712 | elapsed time per iteration (s): 78.83 | learning rate: 1.377E-05 | global batch size:   400 | lm loss: 4.448981E+00 | loss scale: 16384.0 | grad norm: 12527.204 | num zeros: 0.0 | params norm: 530.034 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration     1289/    1571 | consumed samples:       375144 | consumed tokens:    768294912 | elapsed time per iteration (s): 78.74 | learning rate: 1.371E-05 | global batch size:   400 | lm loss: 4.466760E+00 | loss scale: 16384.0 | grad norm: 11912.160 | num zeros: 0.0 | params norm: 530.039 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration     1290/    1571 | consumed samples:       375544 | consumed tokens:    769114112 | elapsed time per iteration (s): 78.84 | learning rate: 1.366E-05 | global batch size:   400 | lm loss: 4.452422E+00 | loss scale: 16384.0 | grad norm: 10448.341 | num zeros: 0.0 | params norm: 530.043 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1291/    1571 | consumed samples:       375944 | consumed tokens:    769933312 | elapsed time per iteration (s): 78.88 | learning rate: 1.361E-05 | global batch size:   400 | lm loss: 4.473999E+00 | loss scale: 16384.0 | grad norm: 11250.122 | num zeros: 0.0 | params norm: 530.048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1292/    1571 | consumed samples:       376344 | consumed tokens:    770752512 | elapsed time per iteration (s): 78.94 | learning rate: 1.356E-05 | global batch size:   400 | lm loss: 4.445748E+00 | loss scale: 16384.0 | grad norm: 10019.998 | num zeros: 0.0 | params norm: 530.052 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.51 |
 iteration     1293/    1571 | consumed samples:       376744 | consumed tokens:    771571712 | elapsed time per iteration (s): 78.95 | learning rate: 1.350E-05 | global batch size:   400 | lm loss: 4.438752E+00 | loss scale: 16384.0 | grad norm: 9468.226 | num zeros: 0.0 | params norm: 530.057 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.50 |
 iteration     1294/    1571 | consumed samples:       377144 | consumed tokens:    772390912 | elapsed time per iteration (s): 78.86 | learning rate: 1.345E-05 | global batch size:   400 | lm loss: 4.434447E+00 | loss scale: 16384.0 | grad norm: 11124.369 | num zeros: 0.0 | params norm: 530.062 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1295/    1571 | consumed samples:       377544 | consumed tokens:    773210112 | elapsed time per iteration (s): 78.78 | learning rate: 1.340E-05 | global batch size:   400 | lm loss: 4.461659E+00 | loss scale: 16384.0 | grad norm: 11333.630 | num zeros: 0.0 | params norm: 530.066 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.078 | TFLOPs: 53.62 |
 iteration     1296/    1571 | consumed samples:       377944 | consumed tokens:    774029312 | elapsed time per iteration (s): 79.07 | learning rate: 1.335E-05 | global batch size:   400 | lm loss: 4.472359E+00 | loss scale: 16384.0 | grad norm: 13427.957 | num zeros: 0.0 | params norm: 530.071 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.059 | TFLOPs: 53.42 |
 iteration     1297/    1571 | consumed samples:       378344 | consumed tokens:    774848512 | elapsed time per iteration (s): 78.89 | learning rate: 1.330E-05 | global batch size:   400 | lm loss: 4.440953E+00 | loss scale: 16384.0 | grad norm: 15312.807 | num zeros: 0.0 | params norm: 530.075 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1298/    1571 | consumed samples:       378744 | consumed tokens:    775667712 | elapsed time per iteration (s): 79.05 | learning rate: 1.325E-05 | global batch size:   400 | lm loss: 4.491582E+00 | loss scale: 16384.0 | grad norm: 15535.781 | num zeros: 0.0 | params norm: 530.080 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.060 | TFLOPs: 53.43 |
 iteration     1299/    1571 | consumed samples:       379144 | consumed tokens:    776486912 | elapsed time per iteration (s): 78.95 | learning rate: 1.320E-05 | global batch size:   400 | lm loss: 4.458784E+00 | loss scale: 16384.0 | grad norm: 12772.849 | num zeros: 0.0 | params norm: 530.084 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1300/    1571 | consumed samples:       379544 | consumed tokens:    777306112 | elapsed time per iteration (s): 78.99 | learning rate: 1.315E-05 | global batch size:   400 | lm loss: 4.458411E+00 | loss scale: 16384.0 | grad norm: 10394.400 | num zeros: 0.0 | params norm: 530.089 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.47 |
 iteration     1301/    1571 | consumed samples:       379944 | consumed tokens:    778125312 | elapsed time per iteration (s): 78.98 | learning rate: 1.310E-05 | global batch size:   400 | lm loss: 4.480349E+00 | loss scale: 16384.0 | grad norm: 11253.137 | num zeros: 0.0 | params norm: 530.093 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.48 |
 iteration     1302/    1571 | consumed samples:       380344 | consumed tokens:    778944512 | elapsed time per iteration (s): 78.92 | learning rate: 1.305E-05 | global batch size:   400 | lm loss: 4.464630E+00 | loss scale: 16384.0 | grad norm: 12995.826 | num zeros: 0.0 | params norm: 530.098 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.52 |
 iteration     1303/    1571 | consumed samples:       380744 | consumed tokens:    779763712 | elapsed time per iteration (s): 78.89 | learning rate: 1.301E-05 | global batch size:   400 | lm loss: 4.442259E+00 | loss scale: 16384.0 | grad norm: 11314.750 | num zeros: 0.0 | params norm: 530.102 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.54 |
 iteration     1304/    1571 | consumed samples:       381144 | consumed tokens:    780582912 | elapsed time per iteration (s): 79.03 | learning rate: 1.296E-05 | global batch size:   400 | lm loss: 4.423011E+00 | loss scale: 16384.0 | grad norm: 9250.549 | num zeros: 0.0 | params norm: 530.107 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.061 | TFLOPs: 53.44 |
 iteration     1305/    1571 | consumed samples:       381544 | consumed tokens:    781402112 | elapsed time per iteration (s): 78.86 | learning rate: 1.291E-05 | global batch size:   400 | lm loss: 4.507995E+00 | loss scale: 16384.0 | grad norm: 10561.223 | num zeros: 0.0 | params norm: 530.111 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1306/    1571 | consumed samples:       381944 | consumed tokens:    782221312 | elapsed time per iteration (s): 78.98 | learning rate: 1.286E-05 | global batch size:   400 | lm loss: 4.484173E+00 | loss scale: 16384.0 | grad norm: 13216.884 | num zeros: 0.0 | params norm: 530.115 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1307/    1571 | consumed samples:       382344 | consumed tokens:    783040512 | elapsed time per iteration (s): 78.92 | learning rate: 1.282E-05 | global batch size:   400 | lm loss: 4.473540E+00 | loss scale: 16384.0 | grad norm: 15405.618 | num zeros: 0.0 | params norm: 530.120 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.52 |
 iteration     1308/    1571 | consumed samples:       382744 | consumed tokens:    783859712 | elapsed time per iteration (s): 78.95 | learning rate: 1.277E-05 | global batch size:   400 | lm loss: 4.424327E+00 | loss scale: 16384.0 | grad norm: 12147.603 | num zeros: 0.0 | params norm: 530.124 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.50 |
 iteration     1309/    1571 | consumed samples:       383144 | consumed tokens:    784678912 | elapsed time per iteration (s): 78.96 | learning rate: 1.272E-05 | global batch size:   400 | lm loss: 4.449677E+00 | loss scale: 16384.0 | grad norm: 11390.241 | num zeros: 0.0 | params norm: 530.128 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.49 |
 iteration     1310/    1571 | consumed samples:       383544 | consumed tokens:    785498112 | elapsed time per iteration (s): 78.86 | learning rate: 1.268E-05 | global batch size:   400 | lm loss: 4.438394E+00 | loss scale: 16384.0 | grad norm: 17399.920 | num zeros: 0.0 | params norm: 530.132 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1311/    1571 | consumed samples:       383944 | consumed tokens:    786317312 | elapsed time per iteration (s): 78.89 | learning rate: 1.263E-05 | global batch size:   400 | lm loss: 4.469955E+00 | loss scale: 16384.0 | grad norm: 11395.574 | num zeros: 0.0 | params norm: 530.137 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.54 |
 iteration     1312/    1571 | consumed samples:       384344 | consumed tokens:    787136512 | elapsed time per iteration (s): 79.03 | learning rate: 1.259E-05 | global batch size:   400 | lm loss: 4.404476E+00 | loss scale: 16384.0 | grad norm: 12561.872 | num zeros: 0.0 | params norm: 530.141 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.061 | TFLOPs: 53.44 |
 iteration     1313/    1571 | consumed samples:       384744 | consumed tokens:    787955712 | elapsed time per iteration (s): 78.92 | learning rate: 1.254E-05 | global batch size:   400 | lm loss: 4.438604E+00 | loss scale: 16384.0 | grad norm: 12019.391 | num zeros: 0.0 | params norm: 530.145 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.52 |
 iteration     1314/    1571 | consumed samples:       385144 | consumed tokens:    788774912 | elapsed time per iteration (s): 79.03 | learning rate: 1.250E-05 | global batch size:   400 | lm loss: 4.472775E+00 | loss scale: 16384.0 | grad norm: 9087.326 | num zeros: 0.0 | params norm: 530.149 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.061 | TFLOPs: 53.44 |
 iteration     1315/    1571 | consumed samples:       385544 | consumed tokens:    789594112 | elapsed time per iteration (s): 78.88 | learning rate: 1.246E-05 | global batch size:   400 | lm loss: 4.465037E+00 | loss scale: 16384.0 | grad norm: 11604.381 | num zeros: 0.0 | params norm: 530.154 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1316/    1571 | consumed samples:       385944 | consumed tokens:    790413312 | elapsed time per iteration (s): 79.00 | learning rate: 1.241E-05 | global batch size:   400 | lm loss: 4.471635E+00 | loss scale: 16384.0 | grad norm: 9879.293 | num zeros: 0.0 | params norm: 530.158 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.47 |
 iteration     1317/    1571 | consumed samples:       386344 | consumed tokens:    791232512 | elapsed time per iteration (s): 78.97 | learning rate: 1.237E-05 | global batch size:   400 | lm loss: 4.442195E+00 | loss scale: 16384.0 | grad norm: 11677.520 | num zeros: 0.0 | params norm: 530.162 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1318/    1571 | consumed samples:       386744 | consumed tokens:    792051712 | elapsed time per iteration (s): 78.85 | learning rate: 1.233E-05 | global batch size:   400 | lm loss: 4.439694E+00 | loss scale: 16384.0 | grad norm: 9369.681 | num zeros: 0.0 | params norm: 530.166 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1319/    1571 | consumed samples:       387144 | consumed tokens:    792870912 | elapsed time per iteration (s): 78.80 | learning rate: 1.228E-05 | global batch size:   400 | lm loss: 4.415473E+00 | loss scale: 16384.0 | grad norm: 9543.224 | num zeros: 0.0 | params norm: 530.170 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration     1320/    1571 | consumed samples:       387544 | consumed tokens:    793690112 | elapsed time per iteration (s): 79.03 | learning rate: 1.224E-05 | global batch size:   400 | lm loss: 4.472357E+00 | loss scale: 16384.0 | grad norm: 11386.046 | num zeros: 0.0 | params norm: 530.174 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.062 | TFLOPs: 53.45 |
 iteration     1321/    1571 | consumed samples:       387944 | consumed tokens:    794509312 | elapsed time per iteration (s): 78.93 | learning rate: 1.220E-05 | global batch size:   400 | lm loss: 4.463382E+00 | loss scale: 16384.0 | grad norm: 9364.567 | num zeros: 0.0 | params norm: 530.178 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1322/    1571 | consumed samples:       388344 | consumed tokens:    795328512 | elapsed time per iteration (s): 78.99 | learning rate: 1.216E-05 | global batch size:   400 | lm loss: 4.486349E+00 | loss scale: 16384.0 | grad norm: 9255.269 | num zeros: 0.0 | params norm: 530.182 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.47 |
 iteration     1323/    1571 | consumed samples:       388744 | consumed tokens:    796147712 | elapsed time per iteration (s): 78.99 | learning rate: 1.212E-05 | global batch size:   400 | lm loss: 4.452721E+00 | loss scale: 16384.0 | grad norm: 9731.473 | num zeros: 0.0 | params norm: 530.186 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.47 |
 iteration     1324/    1571 | consumed samples:       389144 | consumed tokens:    796966912 | elapsed time per iteration (s): 78.92 | learning rate: 1.208E-05 | global batch size:   400 | lm loss: 4.426919E+00 | loss scale: 16384.0 | grad norm: 10651.612 | num zeros: 0.0 | params norm: 530.190 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.52 |
 iteration     1325/    1571 | consumed samples:       389544 | consumed tokens:    797786112 | elapsed time per iteration (s): 78.95 | learning rate: 1.204E-05 | global batch size:   400 | lm loss: 4.434303E+00 | loss scale: 16384.0 | grad norm: 8812.882 | num zeros: 0.0 | params norm: 530.194 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.50 |
 iteration     1326/    1571 | consumed samples:       389944 | consumed tokens:    798605312 | elapsed time per iteration (s): 78.95 | learning rate: 1.200E-05 | global batch size:   400 | lm loss: 4.458379E+00 | loss scale: 16384.0 | grad norm: 8924.340 | num zeros: 0.0 | params norm: 530.198 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1327/    1571 | consumed samples:       390344 | consumed tokens:    799424512 | elapsed time per iteration (s): 78.97 | learning rate: 1.196E-05 | global batch size:   400 | lm loss: 4.461218E+00 | loss scale: 16384.0 | grad norm: 10724.289 | num zeros: 0.0 | params norm: 530.202 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.49 |
 iteration     1328/    1571 | consumed samples:       390744 | consumed tokens:    800243712 | elapsed time per iteration (s): 79.05 | learning rate: 1.192E-05 | global batch size:   400 | lm loss: 4.386871E+00 | loss scale: 16384.0 | grad norm: 11565.751 | num zeros: 0.0 | params norm: 530.206 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.060 | TFLOPs: 53.43 |
 iteration     1329/    1571 | consumed samples:       391144 | consumed tokens:    801062912 | elapsed time per iteration (s): 78.83 | learning rate: 1.188E-05 | global batch size:   400 | lm loss: 4.428331E+00 | loss scale: 16384.0 | grad norm: 10920.193 | num zeros: 0.0 | params norm: 530.210 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration     1330/    1571 | consumed samples:       391544 | consumed tokens:    801882112 | elapsed time per iteration (s): 78.87 | learning rate: 1.184E-05 | global batch size:   400 | lm loss: 4.414557E+00 | loss scale: 16384.0 | grad norm: 12607.696 | num zeros: 0.0 | params norm: 530.214 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.55 |
 iteration     1331/    1571 | consumed samples:       391944 | consumed tokens:    802701312 | elapsed time per iteration (s): 78.99 | learning rate: 1.181E-05 | global batch size:   400 | lm loss: 4.400502E+00 | loss scale: 16384.0 | grad norm: 13448.034 | num zeros: 0.0 | params norm: 530.218 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.47 |
 iteration     1332/    1571 | consumed samples:       392344 | consumed tokens:    803520512 | elapsed time per iteration (s): 78.84 | learning rate: 1.177E-05 | global batch size:   400 | lm loss: 4.469429E+00 | loss scale: 16384.0 | grad norm: 12300.896 | num zeros: 0.0 | params norm: 530.222 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.57 |
 iteration     1333/    1571 | consumed samples:       392744 | consumed tokens:    804339712 | elapsed time per iteration (s): 78.88 | learning rate: 1.173E-05 | global batch size:   400 | lm loss: 4.449582E+00 | loss scale: 16384.0 | grad norm: 10471.983 | num zeros: 0.0 | params norm: 530.226 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1334/    1571 | consumed samples:       393144 | consumed tokens:    805158912 | elapsed time per iteration (s): 78.93 | learning rate: 1.170E-05 | global batch size:   400 | lm loss: 4.453003E+00 | loss scale: 16384.0 | grad norm: 10507.539 | num zeros: 0.0 | params norm: 530.230 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.51 |
 iteration     1335/    1571 | consumed samples:       393544 | consumed tokens:    805978112 | elapsed time per iteration (s): 79.00 | learning rate: 1.166E-05 | global batch size:   400 | lm loss: 4.420432E+00 | loss scale: 16384.0 | grad norm: 12270.716 | num zeros: 0.0 | params norm: 530.234 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.063 | TFLOPs: 53.46 |
 iteration     1336/    1571 | consumed samples:       393944 | consumed tokens:    806797312 | elapsed time per iteration (s): 79.02 | learning rate: 1.162E-05 | global batch size:   400 | lm loss: 4.453651E+00 | loss scale: 16384.0 | grad norm: 15451.934 | num zeros: 0.0 | params norm: 530.238 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.062 | TFLOPs: 53.45 |
 iteration     1337/    1571 | consumed samples:       394344 | consumed tokens:    807616512 | elapsed time per iteration (s): 79.00 | learning rate: 1.159E-05 | global batch size:   400 | lm loss: 4.487004E+00 | loss scale: 16384.0 | grad norm: 15986.186 | num zeros: 0.0 | params norm: 530.242 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.063 | TFLOPs: 53.46 |
 iteration     1338/    1571 | consumed samples:       394744 | consumed tokens:    808435712 | elapsed time per iteration (s): 78.96 | learning rate: 1.155E-05 | global batch size:   400 | lm loss: 4.436084E+00 | loss scale: 16384.0 | grad norm: 13262.096 | num zeros: 0.0 | params norm: 530.246 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.49 |
 iteration     1339/    1571 | consumed samples:       395144 | consumed tokens:    809254912 | elapsed time per iteration (s): 79.00 | learning rate: 1.152E-05 | global batch size:   400 | lm loss: 4.456683E+00 | loss scale: 16384.0 | grad norm: 10465.075 | num zeros: 0.0 | params norm: 530.250 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.063 | TFLOPs: 53.46 |
 iteration     1340/    1571 | consumed samples:       395544 | consumed tokens:    810074112 | elapsed time per iteration (s): 78.85 | learning rate: 1.148E-05 | global batch size:   400 | lm loss: 4.398019E+00 | loss scale: 16384.0 | grad norm: 12516.388 | num zeros: 0.0 | params norm: 530.253 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1341/    1571 | consumed samples:       395944 | consumed tokens:    810893312 | elapsed time per iteration (s): 78.87 | learning rate: 1.145E-05 | global batch size:   400 | lm loss: 4.450966E+00 | loss scale: 16384.0 | grad norm: 13156.636 | num zeros: 0.0 | params norm: 530.257 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1342/    1571 | consumed samples:       396344 | consumed tokens:    811712512 | elapsed time per iteration (s): 79.08 | learning rate: 1.142E-05 | global batch size:   400 | lm loss: 4.451432E+00 | loss scale: 16384.0 | grad norm: 10636.319 | num zeros: 0.0 | params norm: 530.261 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.058 | TFLOPs: 53.41 |
 iteration     1343/    1571 | consumed samples:       396744 | consumed tokens:    812531712 | elapsed time per iteration (s): 78.76 | learning rate: 1.138E-05 | global batch size:   400 | lm loss: 4.424575E+00 | loss scale: 16384.0 | grad norm: 13408.806 | num zeros: 0.0 | params norm: 530.265 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration     1344/    1571 | consumed samples:       397144 | consumed tokens:    813350912 | elapsed time per iteration (s): 78.80 | learning rate: 1.135E-05 | global batch size:   400 | lm loss: 4.401429E+00 | loss scale: 16384.0 | grad norm: 15602.794 | num zeros: 0.0 | params norm: 530.269 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration     1345/    1571 | consumed samples:       397544 | consumed tokens:    814170112 | elapsed time per iteration (s): 78.96 | learning rate: 1.132E-05 | global batch size:   400 | lm loss: 4.440670E+00 | loss scale: 16384.0 | grad norm: 9377.411 | num zeros: 0.0 | params norm: 530.272 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.49 |
 iteration     1346/    1571 | consumed samples:       397944 | consumed tokens:    814989312 | elapsed time per iteration (s): 78.91 | learning rate: 1.129E-05 | global batch size:   400 | lm loss: 4.417230E+00 | loss scale: 16384.0 | grad norm: 15222.026 | num zeros: 0.0 | params norm: 530.276 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.52 |
 iteration     1347/    1571 | consumed samples:       398344 | consumed tokens:    815808512 | elapsed time per iteration (s): 78.87 | learning rate: 1.126E-05 | global batch size:   400 | lm loss: 4.474377E+00 | loss scale: 16384.0 | grad norm: 12489.346 | num zeros: 0.0 | params norm: 530.280 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1348/    1571 | consumed samples:       398744 | consumed tokens:    816627712 | elapsed time per iteration (s): 79.05 | learning rate: 1.122E-05 | global batch size:   400 | lm loss: 4.419160E+00 | loss scale: 16384.0 | grad norm: 14832.296 | num zeros: 0.0 | params norm: 530.283 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.060 | TFLOPs: 53.43 |
 iteration     1349/    1571 | consumed samples:       399144 | consumed tokens:    817446912 | elapsed time per iteration (s): 78.84 | learning rate: 1.119E-05 | global batch size:   400 | lm loss: 4.444683E+00 | loss scale: 16384.0 | grad norm: 13935.535 | num zeros: 0.0 | params norm: 530.287 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1350/    1571 | consumed samples:       399544 | consumed tokens:    818266112 | elapsed time per iteration (s): 78.88 | learning rate: 1.116E-05 | global batch size:   400 | lm loss: 4.440204E+00 | loss scale: 16384.0 | grad norm: 8639.340 | num zeros: 0.0 | params norm: 530.291 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1351/    1571 | consumed samples:       399944 | consumed tokens:    819085312 | elapsed time per iteration (s): 78.96 | learning rate: 1.113E-05 | global batch size:   400 | lm loss: 4.435968E+00 | loss scale: 16384.0 | grad norm: 13566.620 | num zeros: 0.0 | params norm: 530.295 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.49 |
 iteration     1352/    1571 | consumed samples:       400344 | consumed tokens:    819904512 | elapsed time per iteration (s): 78.93 | learning rate: 1.110E-05 | global batch size:   400 | lm loss: 4.411942E+00 | loss scale: 16384.0 | grad norm: 9847.048 | num zeros: 0.0 | params norm: 530.298 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1353/    1571 | consumed samples:       400744 | consumed tokens:    820723712 | elapsed time per iteration (s): 78.94 | learning rate: 1.107E-05 | global batch size:   400 | lm loss: 4.462273E+00 | loss scale: 16384.0 | grad norm: 12835.741 | num zeros: 0.0 | params norm: 530.302 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1354/    1571 | consumed samples:       401144 | consumed tokens:    821542912 | elapsed time per iteration (s): 78.89 | learning rate: 1.105E-05 | global batch size:   400 | lm loss: 4.432972E+00 | loss scale: 16384.0 | grad norm: 10364.347 | num zeros: 0.0 | params norm: 530.306 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1355/    1571 | consumed samples:       401544 | consumed tokens:    822362112 | elapsed time per iteration (s): 78.88 | learning rate: 1.102E-05 | global batch size:   400 | lm loss: 4.437315E+00 | loss scale: 16384.0 | grad norm: 11440.089 | num zeros: 0.0 | params norm: 530.310 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1356/    1571 | consumed samples:       401944 | consumed tokens:    823181312 | elapsed time per iteration (s): 79.02 | learning rate: 1.099E-05 | global batch size:   400 | lm loss: 4.447072E+00 | loss scale: 16384.0 | grad norm: 12003.393 | num zeros: 0.0 | params norm: 530.313 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.062 | TFLOPs: 53.45 |
 iteration     1357/    1571 | consumed samples:       402344 | consumed tokens:    824000512 | elapsed time per iteration (s): 78.86 | learning rate: 1.096E-05 | global batch size:   400 | lm loss: 4.380535E+00 | loss scale: 16384.0 | grad norm: 8904.354 | num zeros: 0.0 | params norm: 530.317 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1358/    1571 | consumed samples:       402744 | consumed tokens:    824819712 | elapsed time per iteration (s): 78.95 | learning rate: 1.093E-05 | global batch size:   400 | lm loss: 4.437647E+00 | loss scale: 16384.0 | grad norm: 13550.059 | num zeros: 0.0 | params norm: 530.321 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.50 |
 iteration     1359/    1571 | consumed samples:       403144 | consumed tokens:    825638912 | elapsed time per iteration (s): 78.94 | learning rate: 1.091E-05 | global batch size:   400 | lm loss: 4.442242E+00 | loss scale: 16384.0 | grad norm: 14546.327 | num zeros: 0.0 | params norm: 530.324 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.51 |
 iteration     1360/    1571 | consumed samples:       403544 | consumed tokens:    826458112 | elapsed time per iteration (s): 79.09 | learning rate: 1.088E-05 | global batch size:   400 | lm loss: 4.429070E+00 | loss scale: 16384.0 | grad norm: 13098.876 | num zeros: 0.0 | params norm: 530.328 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.058 | TFLOPs: 53.41 |
 iteration     1361/    1571 | consumed samples:       403944 | consumed tokens:    827277312 | elapsed time per iteration (s): 78.85 | learning rate: 1.085E-05 | global batch size:   400 | lm loss: 4.423426E+00 | loss scale: 16384.0 | grad norm: 12106.742 | num zeros: 0.0 | params norm: 530.331 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1362/    1571 | consumed samples:       404344 | consumed tokens:    828096512 | elapsed time per iteration (s): 78.96 | learning rate: 1.083E-05 | global batch size:   400 | lm loss: 4.443967E+00 | loss scale: 16384.0 | grad norm: 13235.181 | num zeros: 0.0 | params norm: 530.335 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.49 |
 iteration     1363/    1571 | consumed samples:       404744 | consumed tokens:    828915712 | elapsed time per iteration (s): 79.00 | learning rate: 1.080E-05 | global batch size:   400 | lm loss: 4.417290E+00 | loss scale: 16384.0 | grad norm: 12338.815 | num zeros: 0.0 | params norm: 530.338 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.063 | TFLOPs: 53.47 |
 iteration     1364/    1571 | consumed samples:       405144 | consumed tokens:    829734912 | elapsed time per iteration (s): 78.87 | learning rate: 1.078E-05 | global batch size:   400 | lm loss: 4.385770E+00 | loss scale: 16384.0 | grad norm: 11163.398 | num zeros: 0.0 | params norm: 530.342 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.55 |
 iteration     1365/    1571 | consumed samples:       405544 | consumed tokens:    830554112 | elapsed time per iteration (s): 78.93 | learning rate: 1.075E-05 | global batch size:   400 | lm loss: 4.451113E+00 | loss scale: 16384.0 | grad norm: 12024.661 | num zeros: 0.0 | params norm: 530.345 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1366/    1571 | consumed samples:       405944 | consumed tokens:    831373312 | elapsed time per iteration (s): 78.93 | learning rate: 1.073E-05 | global batch size:   400 | lm loss: 4.456007E+00 | loss scale: 16384.0 | grad norm: 13720.598 | num zeros: 0.0 | params norm: 530.349 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1367/    1571 | consumed samples:       406344 | consumed tokens:    832192512 | elapsed time per iteration (s): 79.04 | learning rate: 1.071E-05 | global batch size:   400 | lm loss: 4.423727E+00 | loss scale: 16384.0 | grad norm: 10144.211 | num zeros: 0.0 | params norm: 530.352 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.061 | TFLOPs: 53.44 |
 iteration     1368/    1571 | consumed samples:       406744 | consumed tokens:    833011712 | elapsed time per iteration (s): 79.00 | learning rate: 1.068E-05 | global batch size:   400 | lm loss: 4.460752E+00 | loss scale: 16384.0 | grad norm: 11031.904 | num zeros: 0.0 | params norm: 530.356 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.063 | TFLOPs: 53.47 |
 iteration     1369/    1571 | consumed samples:       407144 | consumed tokens:    833830912 | elapsed time per iteration (s): 78.91 | learning rate: 1.066E-05 | global batch size:   400 | lm loss: 4.443300E+00 | loss scale: 16384.0 | grad norm: 8524.005 | num zeros: 0.0 | params norm: 530.359 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.53 |
 iteration     1370/    1571 | consumed samples:       407544 | consumed tokens:    834650112 | elapsed time per iteration (s): 78.97 | learning rate: 1.064E-05 | global batch size:   400 | lm loss: 4.436791E+00 | loss scale: 16384.0 | grad norm: 10072.957 | num zeros: 0.0 | params norm: 530.363 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1371/    1571 | consumed samples:       407944 | consumed tokens:    835469312 | elapsed time per iteration (s): 78.95 | learning rate: 1.061E-05 | global batch size:   400 | lm loss: 4.440665E+00 | loss scale: 16384.0 | grad norm: 11266.680 | num zeros: 0.0 | params norm: 530.366 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1372/    1571 | consumed samples:       408344 | consumed tokens:    836288512 | elapsed time per iteration (s): 78.83 | learning rate: 1.059E-05 | global batch size:   400 | lm loss: 4.458820E+00 | loss scale: 16384.0 | grad norm: 12388.493 | num zeros: 0.0 | params norm: 530.370 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration     1373/    1571 | consumed samples:       408744 | consumed tokens:    837107712 | elapsed time per iteration (s): 78.79 | learning rate: 1.057E-05 | global batch size:   400 | lm loss: 4.408885E+00 | loss scale: 16384.0 | grad norm: 10716.316 | num zeros: 0.0 | params norm: 530.373 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration     1374/    1571 | consumed samples:       409144 | consumed tokens:    837926912 | elapsed time per iteration (s): 78.93 | learning rate: 1.055E-05 | global batch size:   400 | lm loss: 4.414341E+00 | loss scale: 16384.0 | grad norm: 9875.598 | num zeros: 0.0 | params norm: 530.377 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1375/    1571 | consumed samples:       409544 | consumed tokens:    838746112 | elapsed time per iteration (s): 78.85 | learning rate: 1.053E-05 | global batch size:   400 | lm loss: 4.423319E+00 | loss scale: 16384.0 | grad norm: 9652.899 | num zeros: 0.0 | params norm: 530.380 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1376/    1571 | consumed samples:       409944 | consumed tokens:    839565312 | elapsed time per iteration (s): 78.88 | learning rate: 1.051E-05 | global batch size:   400 | lm loss: 4.420093E+00 | loss scale: 16384.0 | grad norm: 10710.319 | num zeros: 0.0 | params norm: 530.384 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1377/    1571 | consumed samples:       410344 | consumed tokens:    840384512 | elapsed time per iteration (s): 78.86 | learning rate: 1.049E-05 | global batch size:   400 | lm loss: 4.420538E+00 | loss scale: 16384.0 | grad norm: 11965.406 | num zeros: 0.0 | params norm: 530.387 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1378/    1571 | consumed samples:       410744 | consumed tokens:    841203712 | elapsed time per iteration (s): 79.03 | learning rate: 1.047E-05 | global batch size:   400 | lm loss: 4.408093E+00 | loss scale: 16384.0 | grad norm: 9831.975 | num zeros: 0.0 | params norm: 530.390 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.061 | TFLOPs: 53.44 |
 iteration     1379/    1571 | consumed samples:       411144 | consumed tokens:    842022912 | elapsed time per iteration (s): 78.93 | learning rate: 1.045E-05 | global batch size:   400 | lm loss: 4.404617E+00 | loss scale: 16384.0 | grad norm: 9305.929 | num zeros: 0.0 | params norm: 530.394 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1380/    1571 | consumed samples:       411544 | consumed tokens:    842842112 | elapsed time per iteration (s): 79.01 | learning rate: 1.043E-05 | global batch size:   400 | lm loss: 4.439007E+00 | loss scale: 16384.0 | grad norm: 11616.102 | num zeros: 0.0 | params norm: 530.397 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.063 | TFLOPs: 53.46 |
 iteration     1381/    1571 | consumed samples:       411944 | consumed tokens:    843661312 | elapsed time per iteration (s): 78.84 | learning rate: 1.041E-05 | global batch size:   400 | lm loss: 4.419385E+00 | loss scale: 16384.0 | grad norm: 11974.801 | num zeros: 0.0 | params norm: 530.401 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration     1382/    1571 | consumed samples:       412344 | consumed tokens:    844480512 | elapsed time per iteration (s): 78.93 | learning rate: 1.040E-05 | global batch size:   400 | lm loss: 4.447360E+00 | loss scale: 16384.0 | grad norm: 8857.852 | num zeros: 0.0 | params norm: 530.404 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.51 |
 iteration     1383/    1571 | consumed samples:       412744 | consumed tokens:    845299712 | elapsed time per iteration (s): 78.98 | learning rate: 1.038E-05 | global batch size:   400 | lm loss: 4.422437E+00 | loss scale: 16384.0 | grad norm: 11069.399 | num zeros: 0.0 | params norm: 530.407 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1384/    1571 | consumed samples:       413144 | consumed tokens:    846118912 | elapsed time per iteration (s): 78.93 | learning rate: 1.036E-05 | global batch size:   400 | lm loss: 4.416137E+00 | loss scale: 16384.0 | grad norm: 13607.370 | num zeros: 0.0 | params norm: 530.411 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1385/    1571 | consumed samples:       413544 | consumed tokens:    846938112 | elapsed time per iteration (s): 78.89 | learning rate: 1.034E-05 | global batch size:   400 | lm loss: 4.369559E+00 | loss scale: 16384.0 | grad norm: 14150.256 | num zeros: 0.0 | params norm: 530.414 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1386/    1571 | consumed samples:       413944 | consumed tokens:    847757312 | elapsed time per iteration (s): 78.97 | learning rate: 1.033E-05 | global batch size:   400 | lm loss: 4.410801E+00 | loss scale: 16384.0 | grad norm: 11483.840 | num zeros: 0.0 | params norm: 530.417 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.49 |
 iteration     1387/    1571 | consumed samples:       414344 | consumed tokens:    848576512 | elapsed time per iteration (s): 78.93 | learning rate: 1.031E-05 | global batch size:   400 | lm loss: 4.402488E+00 | loss scale: 16384.0 | grad norm: 12734.351 | num zeros: 0.0 | params norm: 530.421 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1388/    1571 | consumed samples:       414744 | consumed tokens:    849395712 | elapsed time per iteration (s): 79.01 | learning rate: 1.030E-05 | global batch size:   400 | lm loss: 4.421913E+00 | loss scale: 16384.0 | grad norm: 14922.302 | num zeros: 0.0 | params norm: 530.424 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.062 | TFLOPs: 53.46 |
 iteration     1389/    1571 | consumed samples:       415144 | consumed tokens:    850214912 | elapsed time per iteration (s): 78.91 | learning rate: 1.028E-05 | global batch size:   400 | lm loss: 4.451514E+00 | loss scale: 16384.0 | grad norm: 14559.096 | num zeros: 0.0 | params norm: 530.427 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.52 |
 iteration     1390/    1571 | consumed samples:       415544 | consumed tokens:    851034112 | elapsed time per iteration (s): 78.95 | learning rate: 1.027E-05 | global batch size:   400 | lm loss: 4.422902E+00 | loss scale: 16384.0 | grad norm: 13534.416 | num zeros: 0.0 | params norm: 530.431 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1391/    1571 | consumed samples:       415944 | consumed tokens:    851853312 | elapsed time per iteration (s): 78.90 | learning rate: 1.025E-05 | global batch size:   400 | lm loss: 4.409944E+00 | loss scale: 16384.0 | grad norm: 17315.067 | num zeros: 0.0 | params norm: 530.434 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.53 |
 iteration     1392/    1571 | consumed samples:       416344 | consumed tokens:    852672512 | elapsed time per iteration (s): 78.88 | learning rate: 1.024E-05 | global batch size:   400 | lm loss: 4.454571E+00 | loss scale: 16384.0 | grad norm: 16647.800 | num zeros: 0.0 | params norm: 530.437 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1393/    1571 | consumed samples:       416744 | consumed tokens:    853491712 | elapsed time per iteration (s): 78.89 | learning rate: 1.023E-05 | global batch size:   400 | lm loss: 4.411524E+00 | loss scale: 16384.0 | grad norm: 13926.929 | num zeros: 0.0 | params norm: 530.440 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.54 |
 iteration     1394/    1571 | consumed samples:       417144 | consumed tokens:    854310912 | elapsed time per iteration (s): 79.00 | learning rate: 1.021E-05 | global batch size:   400 | lm loss: 4.379745E+00 | loss scale: 16384.0 | grad norm: 13641.478 | num zeros: 0.0 | params norm: 530.444 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.063 | TFLOPs: 53.46 |
 iteration     1395/    1571 | consumed samples:       417544 | consumed tokens:    855130112 | elapsed time per iteration (s): 78.86 | learning rate: 1.020E-05 | global batch size:   400 | lm loss: 4.464333E+00 | loss scale: 16384.0 | grad norm: 12861.066 | num zeros: 0.0 | params norm: 530.447 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1396/    1571 | consumed samples:       417944 | consumed tokens:    855949312 | elapsed time per iteration (s): 78.96 | learning rate: 1.019E-05 | global batch size:   400 | lm loss: 4.410491E+00 | loss scale: 16384.0 | grad norm: 11966.464 | num zeros: 0.0 | params norm: 530.450 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.49 |
 iteration     1397/    1571 | consumed samples:       418344 | consumed tokens:    856768512 | elapsed time per iteration (s): 78.96 | learning rate: 1.017E-05 | global batch size:   400 | lm loss: 4.391114E+00 | loss scale: 16384.0 | grad norm: 12336.253 | num zeros: 0.0 | params norm: 530.453 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.49 |
 iteration     1398/    1571 | consumed samples:       418744 | consumed tokens:    857587712 | elapsed time per iteration (s): 78.93 | learning rate: 1.016E-05 | global batch size:   400 | lm loss: 4.424308E+00 | loss scale: 16384.0 | grad norm: 11341.202 | num zeros: 0.0 | params norm: 530.457 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.51 |
 iteration     1399/    1571 | consumed samples:       419144 | consumed tokens:    858406912 | elapsed time per iteration (s): 78.98 | learning rate: 1.015E-05 | global batch size:   400 | lm loss: 4.387054E+00 | loss scale: 16384.0 | grad norm: 12362.772 | num zeros: 0.0 | params norm: 530.460 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.48 |
 iteration     1400/    1571 | consumed samples:       419544 | consumed tokens:    859226112 | elapsed time per iteration (s): 78.90 | learning rate: 1.014E-05 | global batch size:   400 | lm loss: 4.403585E+00 | loss scale: 16384.0 | grad norm: 9571.204 | num zeros: 0.0 | params norm: 530.463 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.53 |
 iteration     1401/    1571 | consumed samples:       419944 | consumed tokens:    860045312 | elapsed time per iteration (s): 78.86 | learning rate: 1.013E-05 | global batch size:   400 | lm loss: 4.438986E+00 | loss scale: 16384.0 | grad norm: 11009.774 | num zeros: 0.0 | params norm: 530.466 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1402/    1571 | consumed samples:       420344 | consumed tokens:    860864512 | elapsed time per iteration (s): 78.99 | learning rate: 1.012E-05 | global batch size:   400 | lm loss: 4.420092E+00 | loss scale: 16384.0 | grad norm: 9711.289 | num zeros: 0.0 | params norm: 530.470 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.47 |
 iteration     1403/    1571 | consumed samples:       420744 | consumed tokens:    861683712 | elapsed time per iteration (s): 78.89 | learning rate: 1.011E-05 | global batch size:   400 | lm loss: 4.375963E+00 | loss scale: 16384.0 | grad norm: 9446.098 | num zeros: 0.0 | params norm: 530.473 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.54 |
 iteration     1404/    1571 | consumed samples:       421144 | consumed tokens:    862502912 | elapsed time per iteration (s): 79.02 | learning rate: 1.010E-05 | global batch size:   400 | lm loss: 4.399832E+00 | loss scale: 16384.0 | grad norm: 9632.377 | num zeros: 0.0 | params norm: 530.476 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.062 | TFLOPs: 53.45 |
 iteration     1405/    1571 | consumed samples:       421544 | consumed tokens:    863322112 | elapsed time per iteration (s): 78.89 | learning rate: 1.009E-05 | global batch size:   400 | lm loss: 4.421572E+00 | loss scale: 16384.0 | grad norm: 8798.503 | num zeros: 0.0 | params norm: 530.480 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1406/    1571 | consumed samples:       421944 | consumed tokens:    864141312 | elapsed time per iteration (s): 79.02 | learning rate: 1.008E-05 | global batch size:   400 | lm loss: 4.381391E+00 | loss scale: 16384.0 | grad norm: 10082.657 | num zeros: 0.0 | params norm: 530.483 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.062 | TFLOPs: 53.45 |
 iteration     1407/    1571 | consumed samples:       422344 | consumed tokens:    864960512 | elapsed time per iteration (s): 78.85 | learning rate: 1.008E-05 | global batch size:   400 | lm loss: 4.366509E+00 | loss scale: 16384.0 | grad norm: 10214.780 | num zeros: 0.0 | params norm: 530.486 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1408/    1571 | consumed samples:       422744 | consumed tokens:    865779712 | elapsed time per iteration (s): 78.97 | learning rate: 1.007E-05 | global batch size:   400 | lm loss: 4.398623E+00 | loss scale: 16384.0 | grad norm: 10831.134 | num zeros: 0.0 | params norm: 530.489 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.49 |
 iteration     1409/    1571 | consumed samples:       423144 | consumed tokens:    866598912 | elapsed time per iteration (s): 78.94 | learning rate: 1.006E-05 | global batch size:   400 | lm loss: 4.393250E+00 | loss scale: 16384.0 | grad norm: 11323.256 | num zeros: 0.0 | params norm: 530.492 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1410/    1571 | consumed samples:       423544 | consumed tokens:    867418112 | elapsed time per iteration (s): 79.01 | learning rate: 1.006E-05 | global batch size:   400 | lm loss: 4.418096E+00 | loss scale: 16384.0 | grad norm: 9713.552 | num zeros: 0.0 | params norm: 530.496 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.062 | TFLOPs: 53.46 |
 iteration     1411/    1571 | consumed samples:       423944 | consumed tokens:    868237312 | elapsed time per iteration (s): 78.95 | learning rate: 1.005E-05 | global batch size:   400 | lm loss: 4.421723E+00 | loss scale: 16384.0 | grad norm: 9355.501 | num zeros: 0.0 | params norm: 530.499 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.50 |
 iteration     1412/    1571 | consumed samples:       424344 | consumed tokens:    869056512 | elapsed time per iteration (s): 78.93 | learning rate: 1.004E-05 | global batch size:   400 | lm loss: 4.382607E+00 | loss scale: 16384.0 | grad norm: 11434.685 | num zeros: 0.0 | params norm: 530.502 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1413/    1571 | consumed samples:       424744 | consumed tokens:    869875712 | elapsed time per iteration (s): 78.93 | learning rate: 1.004E-05 | global batch size:   400 | lm loss: 4.406296E+00 | loss scale: 16384.0 | grad norm: 13116.226 | num zeros: 0.0 | params norm: 530.506 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1414/    1571 | consumed samples:       425144 | consumed tokens:    870694912 | elapsed time per iteration (s): 78.94 | learning rate: 1.003E-05 | global batch size:   400 | lm loss: 4.394122E+00 | loss scale: 16384.0 | grad norm: 13255.437 | num zeros: 0.0 | params norm: 530.509 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.51 |
 iteration     1415/    1571 | consumed samples:       425544 | consumed tokens:    871514112 | elapsed time per iteration (s): 78.90 | learning rate: 1.003E-05 | global batch size:   400 | lm loss: 4.409123E+00 | loss scale: 16384.0 | grad norm: 13793.096 | num zeros: 0.0 | params norm: 530.512 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.53 |
 iteration     1416/    1571 | consumed samples:       425944 | consumed tokens:    872333312 | elapsed time per iteration (s): 78.98 | learning rate: 1.002E-05 | global batch size:   400 | lm loss: 4.349932E+00 | loss scale: 16384.0 | grad norm: 12083.010 | num zeros: 0.0 | params norm: 530.515 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1417/    1571 | consumed samples:       426344 | consumed tokens:    873152512 | elapsed time per iteration (s): 78.98 | learning rate: 1.002E-05 | global batch size:   400 | lm loss: 4.412984E+00 | loss scale: 16384.0 | grad norm: 12532.348 | num zeros: 0.0 | params norm: 530.519 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.47 |
 iteration     1418/    1571 | consumed samples:       426744 | consumed tokens:    873971712 | elapsed time per iteration (s): 78.96 | learning rate: 1.001E-05 | global batch size:   400 | lm loss: 4.424537E+00 | loss scale: 16384.0 | grad norm: 14543.322 | num zeros: 0.0 | params norm: 530.522 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.49 |
 iteration     1419/    1571 | consumed samples:       427144 | consumed tokens:    874790912 | elapsed time per iteration (s): 78.92 | learning rate: 1.001E-05 | global batch size:   400 | lm loss: 4.422692E+00 | loss scale: 16384.0 | grad norm: 12313.263 | num zeros: 0.0 | params norm: 530.525 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.52 |
 iteration     1420/    1571 | consumed samples:       427544 | consumed tokens:    875610112 | elapsed time per iteration (s): 78.99 | learning rate: 1.001E-05 | global batch size:   400 | lm loss: 4.387070E+00 | loss scale: 16384.0 | grad norm: 11435.682 | num zeros: 0.0 | params norm: 530.528 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.47 |
 iteration     1421/    1571 | consumed samples:       427944 | consumed tokens:    876429312 | elapsed time per iteration (s): 78.89 | learning rate: 1.001E-05 | global batch size:   400 | lm loss: 4.393900E+00 | loss scale: 16384.0 | grad norm: 11274.531 | num zeros: 0.0 | params norm: 530.531 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1422/    1571 | consumed samples:       428344 | consumed tokens:    877248512 | elapsed time per iteration (s): 78.98 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.397714E+00 | loss scale: 16384.0 | grad norm: 10644.409 | num zeros: 0.0 | params norm: 530.535 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1423/    1571 | consumed samples:       428744 | consumed tokens:    878067712 | elapsed time per iteration (s): 78.89 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.419256E+00 | loss scale: 16384.0 | grad norm: 10658.185 | num zeros: 0.0 | params norm: 530.538 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.54 |
 iteration     1424/    1571 | consumed samples:       429144 | consumed tokens:    878886912 | elapsed time per iteration (s): 79.01 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.380181E+00 | loss scale: 16384.0 | grad norm: 9904.239 | num zeros: 0.0 | params norm: 530.541 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.063 | TFLOPs: 53.46 |
 iteration     1425/    1571 | consumed samples:       429544 | consumed tokens:    879706112 | elapsed time per iteration (s): 78.98 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.400345E+00 | loss scale: 16384.0 | grad norm: 9972.044 | num zeros: 0.0 | params norm: 530.544 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1426/    1571 | consumed samples:       429944 | consumed tokens:    880525312 | elapsed time per iteration (s): 78.92 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.417380E+00 | loss scale: 16384.0 | grad norm: 11239.943 | num zeros: 0.0 | params norm: 530.547 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.52 |
 iteration     1427/    1571 | consumed samples:       430344 | consumed tokens:    881344512 | elapsed time per iteration (s): 78.93 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.410444E+00 | loss scale: 16384.0 | grad norm: 10871.285 | num zeros: 0.0 | params norm: 530.551 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1428/    1571 | consumed samples:       430744 | consumed tokens:    882163712 | elapsed time per iteration (s): 78.97 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.373409E+00 | loss scale: 16384.0 | grad norm: 10175.335 | num zeros: 0.0 | params norm: 530.554 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1429/    1571 | consumed samples:       431144 | consumed tokens:    882982912 | elapsed time per iteration (s): 78.92 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.401476E+00 | loss scale: 16384.0 | grad norm: 9168.844 | num zeros: 0.0 | params norm: 530.557 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.52 |
 iteration     1430/    1571 | consumed samples:       431544 | consumed tokens:    883802112 | elapsed time per iteration (s): 78.96 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.395391E+00 | loss scale: 16384.0 | grad norm: 10695.068 | num zeros: 0.0 | params norm: 530.560 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.49 |
 iteration     1431/    1571 | consumed samples:       431944 | consumed tokens:    884621312 | elapsed time per iteration (s): 78.95 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.402176E+00 | loss scale: 16384.0 | grad norm: 10048.824 | num zeros: 0.0 | params norm: 530.564 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.50 |
 iteration     1432/    1571 | consumed samples:       432344 | consumed tokens:    885440512 | elapsed time per iteration (s): 78.95 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.373086E+00 | loss scale: 16384.0 | grad norm: 10693.288 | num zeros: 0.0 | params norm: 530.567 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1433/    1571 | consumed samples:       432744 | consumed tokens:    886259712 | elapsed time per iteration (s): 78.93 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.371860E+00 | loss scale: 16384.0 | grad norm: 11769.682 | num zeros: 0.0 | params norm: 530.570 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1434/    1571 | consumed samples:       433144 | consumed tokens:    887078912 | elapsed time per iteration (s): 78.97 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.410323E+00 | loss scale: 16384.0 | grad norm: 14246.428 | num zeros: 0.0 | params norm: 530.573 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.49 |
 iteration     1435/    1571 | consumed samples:       433544 | consumed tokens:    887898112 | elapsed time per iteration (s): 78.97 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.404079E+00 | loss scale: 16384.0 | grad norm: 16166.053 | num zeros: 0.0 | params norm: 530.577 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.49 |
 iteration     1436/    1571 | consumed samples:       433944 | consumed tokens:    888717312 | elapsed time per iteration (s): 79.02 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.407069E+00 | loss scale: 16384.0 | grad norm: 16030.662 | num zeros: 0.0 | params norm: 530.580 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.062 | TFLOPs: 53.45 |
 iteration     1437/    1571 | consumed samples:       434344 | consumed tokens:    889536512 | elapsed time per iteration (s): 78.90 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.354524E+00 | loss scale: 16384.0 | grad norm: 16846.491 | num zeros: 0.0 | params norm: 530.583 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.53 |
 iteration     1438/    1571 | consumed samples:       434744 | consumed tokens:    890355712 | elapsed time per iteration (s): 78.92 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.380182E+00 | loss scale: 16384.0 | grad norm: 13828.291 | num zeros: 0.0 | params norm: 530.586 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.52 |
 iteration     1439/    1571 | consumed samples:       435144 | consumed tokens:    891174912 | elapsed time per iteration (s): 78.93 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.380473E+00 | loss scale: 16384.0 | grad norm: 10345.480 | num zeros: 0.0 | params norm: 530.589 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1440/    1571 | consumed samples:       435544 | consumed tokens:    891994112 | elapsed time per iteration (s): 78.95 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.374293E+00 | loss scale: 16384.0 | grad norm: 13433.669 | num zeros: 0.0 | params norm: 530.592 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1441/    1571 | consumed samples:       435944 | consumed tokens:    892813312 | elapsed time per iteration (s): 78.96 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.402944E+00 | loss scale: 16384.0 | grad norm: 14104.679 | num zeros: 0.0 | params norm: 530.596 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.49 |
 iteration     1442/    1571 | consumed samples:       436344 | consumed tokens:    893632512 | elapsed time per iteration (s): 78.90 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.393779E+00 | loss scale: 16384.0 | grad norm: 10091.518 | num zeros: 0.0 | params norm: 530.599 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.53 |
 iteration     1443/    1571 | consumed samples:       436744 | consumed tokens:    894451712 | elapsed time per iteration (s): 78.90 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.440882E+00 | loss scale: 16384.0 | grad norm: 11492.906 | num zeros: 0.0 | params norm: 530.602 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.53 |
 iteration     1444/    1571 | consumed samples:       437144 | consumed tokens:    895270912 | elapsed time per iteration (s): 79.08 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.394413E+00 | loss scale: 16384.0 | grad norm: 13163.451 | num zeros: 0.0 | params norm: 530.605 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.058 | TFLOPs: 53.41 |
 iteration     1445/    1571 | consumed samples:       437544 | consumed tokens:    896090112 | elapsed time per iteration (s): 78.89 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.397554E+00 | loss scale: 16384.0 | grad norm: 13433.149 | num zeros: 0.0 | params norm: 530.608 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.54 |
 iteration     1446/    1571 | consumed samples:       437944 | consumed tokens:    896909312 | elapsed time per iteration (s): 79.04 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.347411E+00 | loss scale: 16384.0 | grad norm: 11050.959 | num zeros: 0.0 | params norm: 530.612 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.061 | TFLOPs: 53.44 |
 iteration     1447/    1571 | consumed samples:       438344 | consumed tokens:    897728512 | elapsed time per iteration (s): 78.86 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.394149E+00 | loss scale: 16384.0 | grad norm: 10454.110 | num zeros: 0.0 | params norm: 530.615 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.56 |
 iteration     1448/    1571 | consumed samples:       438744 | consumed tokens:    898547712 | elapsed time per iteration (s): 78.99 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.385957E+00 | loss scale: 16384.0 | grad norm: 11632.697 | num zeros: 0.0 | params norm: 530.618 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.47 |
 iteration     1449/    1571 | consumed samples:       439144 | consumed tokens:    899366912 | elapsed time per iteration (s): 78.95 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.390774E+00 | loss scale: 16384.0 | grad norm: 15090.639 | num zeros: 0.0 | params norm: 530.621 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.50 |
 iteration     1450/    1571 | consumed samples:       439544 | consumed tokens:    900186112 | elapsed time per iteration (s): 78.95 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.395712E+00 | loss scale: 16384.0 | grad norm: 15009.654 | num zeros: 0.0 | params norm: 530.624 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1451/    1571 | consumed samples:       439944 | consumed tokens:    901005312 | elapsed time per iteration (s): 78.88 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.367683E+00 | loss scale: 16384.0 | grad norm: 12494.766 | num zeros: 0.0 | params norm: 530.628 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1452/    1571 | consumed samples:       440344 | consumed tokens:    901824512 | elapsed time per iteration (s): 78.87 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.405293E+00 | loss scale: 16384.0 | grad norm: 11905.040 | num zeros: 0.0 | params norm: 530.631 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1453/    1571 | consumed samples:       440744 | consumed tokens:    902643712 | elapsed time per iteration (s): 78.79 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.371006E+00 | loss scale: 16384.0 | grad norm: 11425.873 | num zeros: 0.0 | params norm: 530.634 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration     1454/    1571 | consumed samples:       441144 | consumed tokens:    903462912 | elapsed time per iteration (s): 78.88 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.376841E+00 | loss scale: 16384.0 | grad norm: 9651.916 | num zeros: 0.0 | params norm: 530.637 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1455/    1571 | consumed samples:       441544 | consumed tokens:    904282112 | elapsed time per iteration (s): 78.89 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.393400E+00 | loss scale: 16384.0 | grad norm: 13249.223 | num zeros: 0.0 | params norm: 530.640 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1456/    1571 | consumed samples:       441944 | consumed tokens:    905101312 | elapsed time per iteration (s): 78.94 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.379546E+00 | loss scale: 16384.0 | grad norm: 12524.941 | num zeros: 0.0 | params norm: 530.643 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1457/    1571 | consumed samples:       442344 | consumed tokens:    905920512 | elapsed time per iteration (s): 78.89 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.368582E+00 | loss scale: 16384.0 | grad norm: 12336.395 | num zeros: 0.0 | params norm: 530.646 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.54 |
 iteration     1458/    1571 | consumed samples:       442744 | consumed tokens:    906739712 | elapsed time per iteration (s): 78.98 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.397682E+00 | loss scale: 16384.0 | grad norm: 13906.165 | num zeros: 0.0 | params norm: 530.650 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1459/    1571 | consumed samples:       443144 | consumed tokens:    907558912 | elapsed time per iteration (s): 78.83 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.399203E+00 | loss scale: 16384.0 | grad norm: 12205.555 | num zeros: 0.0 | params norm: 530.653 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.58 |
 iteration     1460/    1571 | consumed samples:       443544 | consumed tokens:    908378112 | elapsed time per iteration (s): 78.91 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.351748E+00 | loss scale: 16384.0 | grad norm: 11331.287 | num zeros: 0.0 | params norm: 530.656 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.52 |
 iteration     1461/    1571 | consumed samples:       443944 | consumed tokens:    909197312 | elapsed time per iteration (s): 79.00 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.389881E+00 | loss scale: 16384.0 | grad norm: 10560.164 | num zeros: 0.0 | params norm: 530.659 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.063 | TFLOPs: 53.46 |
 iteration     1462/    1571 | consumed samples:       444344 | consumed tokens:    910016512 | elapsed time per iteration (s): 78.93 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.373833E+00 | loss scale: 16384.0 | grad norm: 12619.823 | num zeros: 0.0 | params norm: 530.662 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1463/    1571 | consumed samples:       444744 | consumed tokens:    910835712 | elapsed time per iteration (s): 78.87 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.406847E+00 | loss scale: 16384.0 | grad norm: 13027.861 | num zeros: 0.0 | params norm: 530.665 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.55 |
 iteration     1464/    1571 | consumed samples:       445144 | consumed tokens:    911654912 | elapsed time per iteration (s): 78.98 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.422709E+00 | loss scale: 16384.0 | grad norm: 14402.214 | num zeros: 0.0 | params norm: 530.669 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1465/    1571 | consumed samples:       445544 | consumed tokens:    912474112 | elapsed time per iteration (s): 78.78 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.343369E+00 | loss scale: 16384.0 | grad norm: 11009.694 | num zeros: 0.0 | params norm: 530.672 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.077 | TFLOPs: 53.61 |
 iteration     1466/    1571 | consumed samples:       445944 | consumed tokens:    913293312 | elapsed time per iteration (s): 79.00 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.395694E+00 | loss scale: 16384.0 | grad norm: 11179.159 | num zeros: 0.0 | params norm: 530.675 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.47 |
 iteration     1467/    1571 | consumed samples:       446344 | consumed tokens:    914112512 | elapsed time per iteration (s): 78.75 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.389584E+00 | loss scale: 16384.0 | grad norm: 10874.692 | num zeros: 0.0 | params norm: 530.678 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration     1468/    1571 | consumed samples:       446744 | consumed tokens:    914931712 | elapsed time per iteration (s): 78.86 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.340224E+00 | loss scale: 16384.0 | grad norm: 10918.191 | num zeros: 0.0 | params norm: 530.681 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1469/    1571 | consumed samples:       447144 | consumed tokens:    915750912 | elapsed time per iteration (s): 78.98 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.385413E+00 | loss scale: 16384.0 | grad norm: 10033.991 | num zeros: 0.0 | params norm: 530.684 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1470/    1571 | consumed samples:       447544 | consumed tokens:    916570112 | elapsed time per iteration (s): 78.82 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.368457E+00 | loss scale: 16384.0 | grad norm: 12988.431 | num zeros: 0.0 | params norm: 530.687 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration     1471/    1571 | consumed samples:       447944 | consumed tokens:    917389312 | elapsed time per iteration (s): 78.98 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.396898E+00 | loss scale: 16384.0 | grad norm: 12748.508 | num zeros: 0.0 | params norm: 530.691 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1472/    1571 | consumed samples:       448344 | consumed tokens:    918208512 | elapsed time per iteration (s): 78.81 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.360110E+00 | loss scale: 16384.0 | grad norm: 14946.123 | num zeros: 0.0 | params norm: 530.694 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration     1473/    1571 | consumed samples:       448744 | consumed tokens:    919027712 | elapsed time per iteration (s): 78.95 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.347041E+00 | loss scale: 16384.0 | grad norm: 15007.566 | num zeros: 0.0 | params norm: 530.697 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1474/    1571 | consumed samples:       449144 | consumed tokens:    919846912 | elapsed time per iteration (s): 79.05 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.393476E+00 | loss scale: 16384.0 | grad norm: 16423.652 | num zeros: 0.0 | params norm: 530.700 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.060 | TFLOPs: 53.43 |
 iteration     1475/    1571 | consumed samples:       449544 | consumed tokens:    920666112 | elapsed time per iteration (s): 78.82 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.397150E+00 | loss scale: 16384.0 | grad norm: 16572.075 | num zeros: 0.0 | params norm: 530.703 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration     1476/    1571 | consumed samples:       449944 | consumed tokens:    921485312 | elapsed time per iteration (s): 78.99 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.328828E+00 | loss scale: 16384.0 | grad norm: 11429.359 | num zeros: 0.0 | params norm: 530.706 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.47 |
 iteration     1477/    1571 | consumed samples:       450344 | consumed tokens:    922304512 | elapsed time per iteration (s): 78.88 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.383795E+00 | loss scale: 16384.0 | grad norm: 12586.255 | num zeros: 0.0 | params norm: 530.710 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1478/    1571 | consumed samples:       450744 | consumed tokens:    923123712 | elapsed time per iteration (s): 79.03 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.373139E+00 | loss scale: 16384.0 | grad norm: 13645.577 | num zeros: 0.0 | params norm: 530.713 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.061 | TFLOPs: 53.44 |
 iteration     1479/    1571 | consumed samples:       451144 | consumed tokens:    923942912 | elapsed time per iteration (s): 78.95 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.367490E+00 | loss scale: 16384.0 | grad norm: 11282.669 | num zeros: 0.0 | params norm: 530.716 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1480/    1571 | consumed samples:       451544 | consumed tokens:    924762112 | elapsed time per iteration (s): 78.99 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.402376E+00 | loss scale: 16384.0 | grad norm: 10950.610 | num zeros: 0.0 | params norm: 530.719 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.47 |
 iteration     1481/    1571 | consumed samples:       451944 | consumed tokens:    925581312 | elapsed time per iteration (s): 78.93 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.380351E+00 | loss scale: 16384.0 | grad norm: 11047.030 | num zeros: 0.0 | params norm: 530.722 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1482/    1571 | consumed samples:       452344 | consumed tokens:    926400512 | elapsed time per iteration (s): 79.07 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.364865E+00 | loss scale: 16384.0 | grad norm: 14463.463 | num zeros: 0.0 | params norm: 530.725 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.059 | TFLOPs: 53.42 |
 iteration     1483/    1571 | consumed samples:       452744 | consumed tokens:    927219712 | elapsed time per iteration (s): 78.92 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.403700E+00 | loss scale: 16384.0 | grad norm: 16510.369 | num zeros: 0.0 | params norm: 530.728 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.52 |
 iteration     1484/    1571 | consumed samples:       453144 | consumed tokens:    928038912 | elapsed time per iteration (s): 78.91 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.382118E+00 | loss scale: 16384.0 | grad norm: 14053.268 | num zeros: 0.0 | params norm: 530.731 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.53 |
 iteration     1485/    1571 | consumed samples:       453544 | consumed tokens:    928858112 | elapsed time per iteration (s): 78.98 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.374901E+00 | loss scale: 16384.0 | grad norm: 12307.919 | num zeros: 0.0 | params norm: 530.735 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.48 |
 iteration     1486/    1571 | consumed samples:       453944 | consumed tokens:    929677312 | elapsed time per iteration (s): 78.84 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.367324E+00 | loss scale: 16384.0 | grad norm: 12917.067 | num zeros: 0.0 | params norm: 530.738 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.57 |
 iteration     1487/    1571 | consumed samples:       454344 | consumed tokens:    930496512 | elapsed time per iteration (s): 78.85 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.386738E+00 | loss scale: 16384.0 | grad norm: 15173.573 | num zeros: 0.0 | params norm: 530.741 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1488/    1571 | consumed samples:       454744 | consumed tokens:    931315712 | elapsed time per iteration (s): 79.07 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.355194E+00 | loss scale: 16384.0 | grad norm: 12547.702 | num zeros: 0.0 | params norm: 530.744 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.059 | TFLOPs: 53.42 |
 iteration     1489/    1571 | consumed samples:       455144 | consumed tokens:    932134912 | elapsed time per iteration (s): 78.82 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.413926E+00 | loss scale: 16384.0 | grad norm: 10497.837 | num zeros: 0.0 | params norm: 530.747 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration     1490/    1571 | consumed samples:       455544 | consumed tokens:    932954112 | elapsed time per iteration (s): 78.99 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.345026E+00 | loss scale: 16384.0 | grad norm: 14080.132 | num zeros: 0.0 | params norm: 530.750 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.47 |
 iteration     1491/    1571 | consumed samples:       455944 | consumed tokens:    933773312 | elapsed time per iteration (s): 78.71 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.358927E+00 | loss scale: 16384.0 | grad norm: 13061.991 | num zeros: 0.0 | params norm: 530.754 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.66 |
 iteration     1492/    1571 | consumed samples:       456344 | consumed tokens:    934592512 | elapsed time per iteration (s): 78.88 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.351240E+00 | loss scale: 16384.0 | grad norm: 10149.711 | num zeros: 0.0 | params norm: 530.757 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1493/    1571 | consumed samples:       456744 | consumed tokens:    935411712 | elapsed time per iteration (s): 78.86 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.391212E+00 | loss scale: 16384.0 | grad norm: 9468.514 | num zeros: 0.0 | params norm: 530.760 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1494/    1571 | consumed samples:       457144 | consumed tokens:    936230912 | elapsed time per iteration (s): 78.84 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.333218E+00 | loss scale: 16384.0 | grad norm: 11855.364 | num zeros: 0.0 | params norm: 530.763 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration     1495/    1571 | consumed samples:       457544 | consumed tokens:    937050112 | elapsed time per iteration (s): 78.85 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.391807E+00 | loss scale: 16384.0 | grad norm: 14257.346 | num zeros: 0.0 | params norm: 530.766 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.56 |
 iteration     1496/    1571 | consumed samples:       457944 | consumed tokens:    937869312 | elapsed time per iteration (s): 78.91 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.372584E+00 | loss scale: 16384.0 | grad norm: 11819.598 | num zeros: 0.0 | params norm: 530.769 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.53 |
 iteration     1497/    1571 | consumed samples:       458344 | consumed tokens:    938688512 | elapsed time per iteration (s): 78.85 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.432793E+00 | loss scale: 16384.0 | grad norm: 12050.329 | num zeros: 0.0 | params norm: 530.772 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1498/    1571 | consumed samples:       458744 | consumed tokens:    939507712 | elapsed time per iteration (s): 78.94 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.366321E+00 | loss scale: 16384.0 | grad norm: 12451.869 | num zeros: 0.0 | params norm: 530.775 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1499/    1571 | consumed samples:       459144 | consumed tokens:    940326912 | elapsed time per iteration (s): 78.75 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.396265E+00 | loss scale: 16384.0 | grad norm: 10462.278 | num zeros: 0.0 | params norm: 530.778 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration     1500/    1571 | consumed samples:       459544 | consumed tokens:    941146112 | elapsed time per iteration (s): 78.94 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.399770E+00 | loss scale: 16384.0 | grad norm: 9164.064 | num zeros: 0.0 | params norm: 530.782 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1501/    1571 | consumed samples:       459944 | consumed tokens:    941965312 | elapsed time per iteration (s): 662.15 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.369219E+00 | loss scale: 16384.0 | grad norm: 12432.199 | num zeros: 0.0 | params norm: 530.785 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 0.604 | TFLOPs: 6.38 |
 iteration     1502/    1571 | consumed samples:       460344 | consumed tokens:    942784512 | elapsed time per iteration (s): 79.12 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.334992E+00 | loss scale: 16384.0 | grad norm: 15069.015 | num zeros: 0.0 | params norm: 530.788 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.056 | TFLOPs: 53.39 |
 iteration     1503/    1571 | consumed samples:       460744 | consumed tokens:    943603712 | elapsed time per iteration (s): 78.41 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.327075E+00 | loss scale: 16384.0 | grad norm: 18400.600 | num zeros: 0.0 | params norm: 530.791 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.101 | TFLOPs: 53.86 |
 iteration     1504/    1571 | consumed samples:       461144 | consumed tokens:    944422912 | elapsed time per iteration (s): 79.10 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.372486E+00 | loss scale: 16384.0 | grad norm: 15860.433 | num zeros: 0.0 | params norm: 530.794 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.057 | TFLOPs: 53.39 |
 iteration     1505/    1571 | consumed samples:       461544 | consumed tokens:    945242112 | elapsed time per iteration (s): 78.74 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.361686E+00 | loss scale: 16384.0 | grad norm: 16627.951 | num zeros: 0.0 | params norm: 530.797 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.080 | TFLOPs: 53.64 |
 iteration     1506/    1571 | consumed samples:       461944 | consumed tokens:    946061312 | elapsed time per iteration (s): 78.88 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.363086E+00 | loss scale: 16384.0 | grad norm: 14157.708 | num zeros: 0.0 | params norm: 530.800 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1507/    1571 | consumed samples:       462344 | consumed tokens:    946880512 | elapsed time per iteration (s): 78.94 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.338544E+00 | loss scale: 16384.0 | grad norm: 16303.448 | num zeros: 0.0 | params norm: 530.803 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1508/    1571 | consumed samples:       462744 | consumed tokens:    947699712 | elapsed time per iteration (s): 78.97 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.379259E+00 | loss scale: 16384.0 | grad norm: 18319.878 | num zeros: 0.0 | params norm: 530.807 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1509/    1571 | consumed samples:       463144 | consumed tokens:    948518912 | elapsed time per iteration (s): 78.95 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.372306E+00 | loss scale: 16384.0 | grad norm: 11950.129 | num zeros: 0.0 | params norm: 530.810 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.50 |
 iteration     1510/    1571 | consumed samples:       463544 | consumed tokens:    949338112 | elapsed time per iteration (s): 78.86 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.411887E+00 | loss scale: 16384.0 | grad norm: 15028.507 | num zeros: 0.0 | params norm: 530.813 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1511/    1571 | consumed samples:       463944 | consumed tokens:    950157312 | elapsed time per iteration (s): 78.88 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.340668E+00 | loss scale: 16384.0 | grad norm: 17232.202 | num zeros: 0.0 | params norm: 530.816 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1512/    1571 | consumed samples:       464344 | consumed tokens:    950976512 | elapsed time per iteration (s): 78.88 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.355084E+00 | loss scale: 16384.0 | grad norm: 16026.487 | num zeros: 0.0 | params norm: 530.819 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1513/    1571 | consumed samples:       464744 | consumed tokens:    951795712 | elapsed time per iteration (s): 78.93 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.366892E+00 | loss scale: 16384.0 | grad norm: 14283.427 | num zeros: 0.0 | params norm: 530.822 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1514/    1571 | consumed samples:       465144 | consumed tokens:    952614912 | elapsed time per iteration (s): 78.85 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.387017E+00 | loss scale: 16384.0 | grad norm: 12761.032 | num zeros: 0.0 | params norm: 530.825 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1515/    1571 | consumed samples:       465544 | consumed tokens:    953434112 | elapsed time per iteration (s): 79.03 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.359903E+00 | loss scale: 16384.0 | grad norm: 13203.460 | num zeros: 0.0 | params norm: 530.828 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.061 | TFLOPs: 53.44 |
 iteration     1516/    1571 | consumed samples:       465944 | consumed tokens:    954253312 | elapsed time per iteration (s): 78.85 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.380959E+00 | loss scale: 16384.0 | grad norm: 13440.653 | num zeros: 0.0 | params norm: 530.831 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1517/    1571 | consumed samples:       466344 | consumed tokens:    955072512 | elapsed time per iteration (s): 78.90 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.329407E+00 | loss scale: 16384.0 | grad norm: 14064.197 | num zeros: 0.0 | params norm: 530.834 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.53 |
 iteration     1518/    1571 | consumed samples:       466744 | consumed tokens:    955891712 | elapsed time per iteration (s): 78.86 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.344676E+00 | loss scale: 16384.0 | grad norm: 9835.454 | num zeros: 0.0 | params norm: 530.837 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1519/    1571 | consumed samples:       467144 | consumed tokens:    956710912 | elapsed time per iteration (s): 78.72 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.399302E+00 | loss scale: 16384.0 | grad norm: 11855.223 | num zeros: 0.0 | params norm: 530.840 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.082 | TFLOPs: 53.66 |
 iteration     1520/    1571 | consumed samples:       467544 | consumed tokens:    957530112 | elapsed time per iteration (s): 78.84 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.357237E+00 | loss scale: 16384.0 | grad norm: 10441.847 | num zeros: 0.0 | params norm: 530.843 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.57 |
 iteration     1521/    1571 | consumed samples:       467944 | consumed tokens:    958349312 | elapsed time per iteration (s): 78.96 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.368070E+00 | loss scale: 16384.0 | grad norm: 11695.062 | num zeros: 0.0 | params norm: 530.846 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.066 | TFLOPs: 53.49 |
 iteration     1522/    1571 | consumed samples:       468344 | consumed tokens:    959168512 | elapsed time per iteration (s): 78.85 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.305213E+00 | loss scale: 16384.0 | grad norm: 10937.166 | num zeros: 0.0 | params norm: 530.850 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.56 |
 iteration     1523/    1571 | consumed samples:       468744 | consumed tokens:    959987712 | elapsed time per iteration (s): 78.84 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.331312E+00 | loss scale: 16384.0 | grad norm: 10325.111 | num zeros: 0.0 | params norm: 530.853 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1524/    1571 | consumed samples:       469144 | consumed tokens:    960806912 | elapsed time per iteration (s): 79.15 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.336115E+00 | loss scale: 16384.0 | grad norm: 10213.731 | num zeros: 0.0 | params norm: 530.856 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.054 | TFLOPs: 53.36 |
 iteration     1525/    1571 | consumed samples:       469544 | consumed tokens:    961626112 | elapsed time per iteration (s): 78.85 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.317902E+00 | loss scale: 16384.0 | grad norm: 10787.557 | num zeros: 0.0 | params norm: 530.859 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1526/    1571 | consumed samples:       469944 | consumed tokens:    962445312 | elapsed time per iteration (s): 78.94 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.346358E+00 | loss scale: 16384.0 | grad norm: 10854.813 | num zeros: 0.0 | params norm: 530.862 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1527/    1571 | consumed samples:       470344 | consumed tokens:    963264512 | elapsed time per iteration (s): 79.10 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.376941E+00 | loss scale: 16384.0 | grad norm: 13389.282 | num zeros: 0.0 | params norm: 530.865 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.057 | TFLOPs: 53.40 |
 iteration     1528/    1571 | consumed samples:       470744 | consumed tokens:    964083712 | elapsed time per iteration (s): 78.90 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.348147E+00 | loss scale: 16384.0 | grad norm: 16089.881 | num zeros: 0.0 | params norm: 530.868 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.53 |
 iteration     1529/    1571 | consumed samples:       471144 | consumed tokens:    964902912 | elapsed time per iteration (s): 78.82 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.379421E+00 | loss scale: 16384.0 | grad norm: 18977.888 | num zeros: 0.0 | params norm: 530.871 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration     1530/    1571 | consumed samples:       471544 | consumed tokens:    965722112 | elapsed time per iteration (s): 78.93 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.349637E+00 | loss scale: 16384.0 | grad norm: 14526.776 | num zeros: 0.0 | params norm: 530.874 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1531/    1571 | consumed samples:       471944 | consumed tokens:    966541312 | elapsed time per iteration (s): 78.94 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.394522E+00 | loss scale: 16384.0 | grad norm: 12278.144 | num zeros: 0.0 | params norm: 530.878 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.51 |
 iteration     1532/    1571 | consumed samples:       472344 | consumed tokens:    967360512 | elapsed time per iteration (s): 78.94 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.370426E+00 | loss scale: 16384.0 | grad norm: 13281.696 | num zeros: 0.0 | params norm: 530.881 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1533/    1571 | consumed samples:       472744 | consumed tokens:    968179712 | elapsed time per iteration (s): 78.91 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.325500E+00 | loss scale: 16384.0 | grad norm: 13834.030 | num zeros: 0.0 | params norm: 530.884 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.53 |
 iteration     1534/    1571 | consumed samples:       473144 | consumed tokens:    968998912 | elapsed time per iteration (s): 78.97 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.352828E+00 | loss scale: 16384.0 | grad norm: 13804.492 | num zeros: 0.0 | params norm: 530.887 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1535/    1571 | consumed samples:       473544 | consumed tokens:    969818112 | elapsed time per iteration (s): 78.92 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.381890E+00 | loss scale: 16384.0 | grad norm: 13128.933 | num zeros: 0.0 | params norm: 530.890 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.52 |
 iteration     1536/    1571 | consumed samples:       473944 | consumed tokens:    970637312 | elapsed time per iteration (s): 78.88 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.344244E+00 | loss scale: 16384.0 | grad norm: 12531.325 | num zeros: 0.0 | params norm: 530.893 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1537/    1571 | consumed samples:       474344 | consumed tokens:    971456512 | elapsed time per iteration (s): 78.93 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.381539E+00 | loss scale: 16384.0 | grad norm: 11476.609 | num zeros: 0.0 | params norm: 530.896 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1538/    1571 | consumed samples:       474744 | consumed tokens:    972275712 | elapsed time per iteration (s): 78.82 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.360731E+00 | loss scale: 16384.0 | grad norm: 11961.811 | num zeros: 0.0 | params norm: 530.899 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.075 | TFLOPs: 53.59 |
 iteration     1539/    1571 | consumed samples:       475144 | consumed tokens:    973094912 | elapsed time per iteration (s): 78.91 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.384796E+00 | loss scale: 16384.0 | grad norm: 15253.167 | num zeros: 0.0 | params norm: 530.902 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.53 |
 iteration     1540/    1571 | consumed samples:       475544 | consumed tokens:    973914112 | elapsed time per iteration (s): 79.11 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.346145E+00 | loss scale: 16384.0 | grad norm: 20517.448 | num zeros: 0.0 | params norm: 530.905 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.056 | TFLOPs: 53.39 |
 iteration     1541/    1571 | consumed samples:       475944 | consumed tokens:    974733312 | elapsed time per iteration (s): 78.76 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.348571E+00 | loss scale: 16384.0 | grad norm: 12899.032 | num zeros: 0.0 | params norm: 530.909 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration     1542/    1571 | consumed samples:       476344 | consumed tokens:    975552512 | elapsed time per iteration (s): 78.92 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.374023E+00 | loss scale: 16384.0 | grad norm: 20522.283 | num zeros: 0.0 | params norm: 530.912 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.52 |
 iteration     1543/    1571 | consumed samples:       476744 | consumed tokens:    976371712 | elapsed time per iteration (s): 78.87 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.412037E+00 | loss scale: 16384.0 | grad norm: 21525.438 | num zeros: 0.0 | params norm: 530.915 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1544/    1571 | consumed samples:       477144 | consumed tokens:    977190912 | elapsed time per iteration (s): 79.03 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.364997E+00 | loss scale: 16384.0 | grad norm: 19074.338 | num zeros: 0.0 | params norm: 530.918 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.062 | TFLOPs: 53.45 |
 iteration     1545/    1571 | consumed samples:       477544 | consumed tokens:    978010112 | elapsed time per iteration (s): 78.83 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.314756E+00 | loss scale: 16384.0 | grad norm: 22613.701 | num zeros: 0.0 | params norm: 530.921 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration     1546/    1571 | consumed samples:       477944 | consumed tokens:    978829312 | elapsed time per iteration (s): 79.13 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.359465E+00 | loss scale: 16384.0 | grad norm: 19629.155 | num zeros: 0.0 | params norm: 530.923 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.055 | TFLOPs: 53.38 |
 iteration     1547/    1571 | consumed samples:       478344 | consumed tokens:    979648512 | elapsed time per iteration (s): 78.83 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.347814E+00 | loss scale: 16384.0 | grad norm: 14962.109 | num zeros: 0.0 | params norm: 530.926 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration     1548/    1571 | consumed samples:       478744 | consumed tokens:    980467712 | elapsed time per iteration (s): 79.04 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.339745E+00 | loss scale: 16384.0 | grad norm: 14630.301 | num zeros: 0.0 | params norm: 530.929 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.061 | TFLOPs: 53.44 |
 iteration     1549/    1571 | consumed samples:       479144 | consumed tokens:    981286912 | elapsed time per iteration (s): 78.93 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.339020E+00 | loss scale: 16384.0 | grad norm: 17706.034 | num zeros: 0.0 | params norm: 530.932 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
 iteration     1550/    1571 | consumed samples:       479544 | consumed tokens:    982106112 | elapsed time per iteration (s): 78.99 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.368590E+00 | loss scale: 16384.0 | grad norm: 12778.133 | num zeros: 0.0 | params norm: 530.935 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.064 | TFLOPs: 53.47 |
 iteration     1551/    1571 | consumed samples:       479944 | consumed tokens:    982925312 | elapsed time per iteration (s): 78.98 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.322790E+00 | loss scale: 16384.0 | grad norm: 15985.829 | num zeros: 0.0 | params norm: 530.938 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.48 |
 iteration     1552/    1571 | consumed samples:       480344 | consumed tokens:    983744512 | elapsed time per iteration (s): 79.01 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.364981E+00 | loss scale: 16384.0 | grad norm: 13561.614 | num zeros: 0.0 | params norm: 530.941 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.063 | TFLOPs: 53.46 |
 iteration     1553/    1571 | consumed samples:       480744 | consumed tokens:    984563712 | elapsed time per iteration (s): 78.73 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.332807E+00 | loss scale: 16384.0 | grad norm: 12912.857 | num zeros: 0.0 | params norm: 530.944 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.081 | TFLOPs: 53.65 |
 iteration     1554/    1571 | consumed samples:       481144 | consumed tokens:    985382912 | elapsed time per iteration (s): 78.80 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.372735E+00 | loss scale: 16384.0 | grad norm: 14835.264 | num zeros: 0.0 | params norm: 530.947 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.076 | TFLOPs: 53.60 |
 iteration     1555/    1571 | consumed samples:       481544 | consumed tokens:    986202112 | elapsed time per iteration (s): 78.88 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.331776E+00 | loss scale: 16384.0 | grad norm: 16760.937 | num zeros: 0.0 | params norm: 530.950 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1556/    1571 | consumed samples:       481944 | consumed tokens:    987021312 | elapsed time per iteration (s): 78.84 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.340758E+00 | loss scale: 16384.0 | grad norm: 12879.952 | num zeros: 0.0 | params norm: 530.953 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.073 | TFLOPs: 53.57 |
 iteration     1557/    1571 | consumed samples:       482344 | consumed tokens:    987840512 | elapsed time per iteration (s): 78.75 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.322405E+00 | loss scale: 16384.0 | grad norm: 12369.548 | num zeros: 0.0 | params norm: 530.956 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.079 | TFLOPs: 53.63 |
 iteration     1558/    1571 | consumed samples:       482744 | consumed tokens:    988659712 | elapsed time per iteration (s): 78.83 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.398570E+00 | loss scale: 16384.0 | grad norm: 14819.786 | num zeros: 0.0 | params norm: 530.959 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.074 | TFLOPs: 53.58 |
 iteration     1559/    1571 | consumed samples:       483144 | consumed tokens:    989478912 | elapsed time per iteration (s): 78.90 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.355603E+00 | loss scale: 16384.0 | grad norm: 14586.123 | num zeros: 0.0 | params norm: 530.962 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.53 |
 iteration     1560/    1571 | consumed samples:       483544 | consumed tokens:    990298112 | elapsed time per iteration (s): 78.88 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.368897E+00 | loss scale: 16384.0 | grad norm: 16197.270 | num zeros: 0.0 | params norm: 530.965 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.54 |
 iteration     1561/    1571 | consumed samples:       483944 | consumed tokens:    991117312 | elapsed time per iteration (s): 78.89 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.368537E+00 | loss scale: 16384.0 | grad norm: 16291.438 | num zeros: 0.0 | params norm: 530.968 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.070 | TFLOPs: 53.54 |
 iteration     1562/    1571 | consumed samples:       484344 | consumed tokens:    991936512 | elapsed time per iteration (s): 78.87 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.355411E+00 | loss scale: 16384.0 | grad norm: 17213.665 | num zeros: 0.0 | params norm: 530.971 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1563/    1571 | consumed samples:       484744 | consumed tokens:    992755712 | elapsed time per iteration (s): 78.91 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.319265E+00 | loss scale: 16384.0 | grad norm: 14330.534 | num zeros: 0.0 | params norm: 530.974 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.53 |
 iteration     1564/    1571 | consumed samples:       485144 | consumed tokens:    993574912 | elapsed time per iteration (s): 78.94 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.321981E+00 | loss scale: 16384.0 | grad norm: 11021.176 | num zeros: 0.0 | params norm: 530.977 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1565/    1571 | consumed samples:       485544 | consumed tokens:    994394112 | elapsed time per iteration (s): 78.88 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.374366E+00 | loss scale: 16384.0 | grad norm: 14338.050 | num zeros: 0.0 | params norm: 530.980 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.071 | TFLOPs: 53.55 |
 iteration     1566/    1571 | consumed samples:       485944 | consumed tokens:    995213312 | elapsed time per iteration (s): 78.94 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.340626E+00 | loss scale: 16384.0 | grad norm: 14704.287 | num zeros: 0.0 | params norm: 530.983 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.067 | TFLOPs: 53.50 |
 iteration     1567/    1571 | consumed samples:       486344 | consumed tokens:    996032512 | elapsed time per iteration (s): 78.92 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.338197E+00 | loss scale: 16384.0 | grad norm: 12514.379 | num zeros: 0.0 | params norm: 530.986 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.069 | TFLOPs: 53.52 |
 iteration     1568/    1571 | consumed samples:       486744 | consumed tokens:    996851712 | elapsed time per iteration (s): 79.01 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.369910E+00 | loss scale: 16384.0 | grad norm: 10612.128 | num zeros: 0.0 | params norm: 530.989 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.063 | TFLOPs: 53.46 |
 iteration     1569/    1571 | consumed samples:       487144 | consumed tokens:    997670912 | elapsed time per iteration (s): 78.87 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.364497E+00 | loss scale: 16384.0 | grad norm: 12193.701 | num zeros: 0.0 | params norm: 530.992 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.072 | TFLOPs: 53.56 |
 iteration     1570/    1571 | consumed samples:       487544 | consumed tokens:    998490112 | elapsed time per iteration (s): 78.97 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.327671E+00 | loss scale: 16384.0 | grad norm: 10909.923 | num zeros: 0.0 | params norm: 530.995 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.065 | TFLOPs: 53.49 |
 iteration     1571/    1571 | consumed samples:       487944 | consumed tokens:    999309312 | elapsed time per iteration (s): 78.93 | learning rate: 1.000E-05 | global batch size:   400 | lm loss: 4.352100E+00 | loss scale: 16384.0 | grad norm: 11036.636 | num zeros: 0.0 | params norm: 530.998 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 5.068 | TFLOPs: 53.51 |
[after training is done] datetime: 2022-03-04 04:44:52 