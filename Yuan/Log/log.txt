------------------------ arguments ------------------------
  abort_on_unmet_fused_kernel_constraints ......... False
  accumulate_allreduce_grads_in_fp32 .............. False
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.95
  adam_eps ........................................ 1e-08
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  bert_binary_head ................................ True
  bert_load ....................................... None
  bf16 ............................................ False
  bias_dropout_fusion ............................. True
  bias_gelu_fusion ................................ True
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  checkpoint_activations .......................... True
  checkpoint_in_cpu ............................... False
  checkpoint_num_layers ........................... 1
  clip_grad ....................................... 1.0
  codecarbon_dir .................................. None
  consumed_train_samples .......................... 0
  consumed_train_tokens ........................... 0
  consumed_valid_samples .......................... 0
  contigious_checkpointing ........................ False
  cpu_optimizer ................................... False
  cpu_torch_adam .................................. False
  curriculum_learning ............................. False
  data_impl ....................................... infer
  data_parallel_size .............................. 2
  data_path ....................................... ['1', '/home/hustcsuser/YuanData/processed_yuan/001.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/002.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/003.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/004.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/005.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/006.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/007.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/008.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/009.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/010.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/011.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/012.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/013.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/014.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/015.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/016.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/017.txt_sentence_context', '1', '/home/hustcsuser/YuanData/processed_yuan/018.txt_sentence_context']
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_seq_length .............................. None
  deepscale ....................................... False
  deepscale_config ................................ None
  deepspeed ....................................... True
  deepspeed_activation_checkpointing .............. True
  deepspeed_config ................................ config.json
  deepspeed_mpi ................................... False
  distribute_checkpointed_activations ............. False
  distributed_backend ............................. nccl
  embed_layernorm ................................. False
  embedding_path .................................. None
  encoder_seq_length .............................. 2048
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... -1
  eval_only ....................................... None
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  ffn_hidden_size ................................. 12288
  finetune ........................................ False
  fp16 ............................................ True
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  gigaflos_no_embeds .............................. 0
  global_batch_size ............................... 400
  glu_activation .................................. None
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 3072
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_dim ......................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  init_method_std ................................. 0.002
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  kill_switch_path ................................ None
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ ./checkpoints/gpt2_encdec_4.7B_final_testdate_22-03-03_time_00-57-41/
  local_rank ...................................... 0
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 1
  log_learning_rate_to_tensorboard ................ True
  log_level ....................................... None
  log_level_replica ............................... None
  log_loss_scale_to_tensorboard ................... True
  log_num_zeros_in_grad ........................... True
  log_params_norm ................................. True
  log_path ........................................ log.txt
  log_path_detail ................................. detail.txt
  log_start_end_param ............................. None
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  loss_on_targets_only ............................ False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.0001
  lr_decay_iters .................................. None
  lr_decay_samples ................................ 430000
  lr_decay_style .................................. cosine
  lr_decay_tokens ................................. None
  lr_warmup_fraction .............................. None
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 7200
  make_vocab_size_divisible_by .................... 128
  mask_prob ....................................... 0.15
  masked_softmax_fusion ........................... True
  max_position_embeddings ......................... 2048
  memory_centric_tiled_linear ..................... False
  merge_file ...................................... None
  micro_batch_size ................................ 4
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 24
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 16
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  override_lr_scheduler ........................... False
  params_dtype .................................... torch.float16
  partition_activations ........................... False
  patch_dim ....................................... 16
  pipeline_model_parallel_size .................... 4
  position_embedding_type ......................... PositionEmbeddingType.absolute
  profile_backward ................................ False
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... ['8', '8', '39200']
  rank ............................................ 0
  remote_device ................................... none
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  reweight_loss_based_on_position_frequency ....... False
  sample_rate ..................................... 1.0
  save ............................................ ./checkpoints/gpt2_encdec_4.7B_final_testdate_22-03-03_time_00-57-41/
  save_interval ................................... 500
  scatter_gather_tensors_in_pipeline .............. True
  scattered_embeddings ............................ False
  seed ............................................ 1234
  seq_length ...................................... 2048
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  skip_train_iteration_range ...................... None
  split ........................................... 100,0,0
  split_transformers .............................. False
  synchronize_each_layer .......................... False
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. ./tensorboard/gpt2_encdec_4.7B_final_test/date_22-03-03_time_00-57-41
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_weighted_split_names ....................... None
  test_weighted_split_paths ....................... None
  test_weighted_split_splits ...................... None
  test_weighted_split_weights ..................... None
  tile_factor ..................................... 1
  titles_data_path ................................ None
  tokenizer_name_or_path .......................... None
  tokenizer_type .................................. EncDecTokenizer
  train_iters ..................................... None
  train_samples ................................... 488322
  train_tokens .................................... None
  train_weighted_split_paths ...................... None
  use_bnb_optimizer ............................... False
  use_checkpoint_lr_scheduler ..................... False
  use_contiguous_buffers_in_ddp ................... False
  use_cpu_initialization .......................... None
  use_one_sent_docs ............................... False
  use_pin_memory .................................. False
  valid_weighted_split_names ...................... None
  valid_weighted_split_paths ...................... None
  valid_weighted_split_splits ..................... None
  valid_weighted_split_weights .................... None
  virtual_pipeline_model_parallel_size ............ None
  vocab_extra_ids ................................. 0
  vocab_file ...................................... vocab.txt
  weight_decay .................................... 0.01
  world_size ...................................... 8
  zero_allgather_bucket_size ...................... 0.0
  zero_contigious_gradients ....................... False
  zero_reduce_bucket_size ......................... 0.0
  zero_reduce_scatter ............................. False
  zero_stage ...................................... 1.0
-------------------- end of arguments ---------------------
[before the start of training step] datetime: 2022-03-03 00:58:38
[after training is done] datetime: 2022-03-04 04:44:52 